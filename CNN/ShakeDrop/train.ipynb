{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Copyright\n",
    "## https://github.com/owruby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from models import ShakePyramidNet\n",
    "from utils import Bar,Logger, AverageMeter, accuracy, mkdir_p, savefig\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device 0,1,2: True\n"
     ]
    }
   ],
   "source": [
    "# GPU Device\n",
    "gpu_id = '0,1,2'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"GPU device %s:\" %(gpu_id), use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained = ''\n",
    "resume = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "manual_seed = 7\n",
    "random.seed(manual_seed)\n",
    "torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "# train params\n",
    "epochs = 1800\n",
    "batch_size = 1800\n",
    "init_lr = 0.5\n",
    "weight_decay = 1e-5\n",
    "labels = 10\n",
    "momentum = 0.9\n",
    "\n",
    "# ShakeDrop params\n",
    "depth = 110\n",
    "alpha = 270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_dataset(10, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = './log/' # dir\n",
    "if not os.path.isdir(checkpoint):\n",
    "    os.mkdir(checkpoint)\n",
    "num_workers = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ShakePyramidNet(depth=depth, alpha=alpha, label=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Total params: 28.49M\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "cudnn.benchmark = True\n",
    "print('    Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume\n",
    "if resume:\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    checkpoint = os.path.dirname(resume)\n",
    "#     checkpoint = torch.load(resume)\n",
    "    resume = torch.load(resume)\n",
    "    best_acc = resume['best_acc']\n",
    "    start_epoch = resume['epoch']\n",
    "    model.load_state_dict(resume['state_dict'])\n",
    "    optimizer.load_state_dict(resume['optimizer'])\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'), resume=True)\n",
    "else:\n",
    "    logger = Logger(os.path.join(checkpoint, 'log.txt'))\n",
    "    logger.set_names(['Learning Rate', 'Train Loss', 'Valid Loss', 'Train Acc.', 'Valid Acc.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=init_lr, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "step_lr = torch.optim.lr_scheduler.StepLR(optimizer, 400, gamma=0.1, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.27s/it]                                                               "
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, train_top1 = AverageMeter(), AverageMeter()\n",
    "    bar = tqdm(total=len(train_loader), leave=False)\n",
    "    for x, t in train_loader:\n",
    "        x, t = Variable(x.cuda()), Variable(t.cuda())\n",
    "        y = model(x)\n",
    "        loss = loss_func(y, t)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        err1 = accuracy(y.data, t, topk=(1,))\n",
    "        train_loss.update(float(loss.data), x.size(0))\n",
    "        train_top1.update(float(err1[0]), x.size(0))\n",
    "        bar.set_description(\"Epoch: {:d} / {:d}, LR:{:.6f}, Loss: {:.6f}, Top1E: {:.2f}\".format(e, epochs, \n",
    "            optimizer.param_groups[0][\"lr\"], train_loss.avg, train_top1.avg), refresh=True)\n",
    "        bar.update()\n",
    "    bar.close()\n",
    "    scheduler.step()\n",
    "    step_lr.step()\n",
    "    model.eval()jj\n",
    "    test_loss, test_top1 = AverageMeter(), AverageMeter()\n",
    "    for x, t in tqdm(test_loader, total=len(test_loader), leave=False):\n",
    "        with torch.no_grad():\n",
    "            x, t = Variable(x.cuda()), Variable(t.cuda())\n",
    "            y = model(x)\n",
    "            loss = loss_func(y, t)\n",
    "            err1 = accuracy(y.data, t, topk=(1,))\n",
    "            test_loss.update(float(loss.data), x.size(0))\n",
    "            test_top1.update(float(err1[0]), x.size(0))\n",
    "\n",
    "    if (e + 1) % 100 == 0:\n",
    "        torch.save({\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict()\n",
    "        }, os.path.join(checkpoint, \"{}.tar\".format(e + 1)))\n",
    "\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    logger.append([lr, train_loss.avg, test_loss.avg, train_top1.avg, test_top1.avg])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
