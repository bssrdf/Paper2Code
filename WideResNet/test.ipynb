{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.backends import cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from wrn import WideResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = 'WRN28@10_cifar10.pth'\n",
    "device = 'cuda:1'\n",
    "start_epoch = 1\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "optim_type = 'SGD'\n",
    "num_classes = 10\n",
    "root_dir = '../data/cifar10'\n",
    "d = 28 #\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = (0.4914, 0.4822, 0.4465)\n",
    "std = (0.2023, 0.1994, 0.2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only for cifar-10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learning_rate(init, epoch):\n",
    "    optim_factor = 0\n",
    "    if(epoch > 160):\n",
    "        optim_factor = 3\n",
    "    elif(epoch > 120):\n",
    "        optim_factor = 2\n",
    "    elif(epoch > 60):\n",
    "        optim_factor = 1\n",
    "\n",
    "    return init*math.pow(0.2, optim_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hms(seconds):\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "\n",
    "    return h, m, s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.RandomCrop(size=32, padding=4),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=mean, std=std),])\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=mean, std=std),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(root=root_dir, train=True, download=True, transform=transform_train)\n",
    "testset = CIFAR10(root=root_dir, train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 28x10\n"
     ]
    }
   ],
   "source": [
    "net = WideResNet(depth=d, widen_factor=k)\n",
    "file_name = 'wide-resnet-'+str(d)+'x'+str(k)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=> Training Epoch #1, LR=0.1000\n",
      "| Epoch [  1/200] Iter [  1/391]\t\tLoss: 2.3166 Acc@1: 8.000%\n",
      "| Epoch [  1/200] Iter [ 26/391]\t\tLoss: 1.9582 Acc@1: 21.000%\n",
      "| Epoch [  1/200] Iter [ 51/391]\t\tLoss: 1.7600 Acc@1: 25.000%\n",
      "| Epoch [  1/200] Iter [ 76/391]\t\tLoss: 1.5144 Acc@1: 29.000%\n",
      "| Epoch [  1/200] Iter [101/391]\t\tLoss: 1.6807 Acc@1: 31.000%\n",
      "| Epoch [  1/200] Iter [126/391]\t\tLoss: 1.2663 Acc@1: 34.000%\n",
      "| Epoch [  1/200] Iter [151/391]\t\tLoss: 1.3094 Acc@1: 36.000%\n",
      "| Epoch [  1/200] Iter [176/391]\t\tLoss: 1.3931 Acc@1: 38.000%\n",
      "| Epoch [  1/200] Iter [201/391]\t\tLoss: 1.3363 Acc@1: 39.000%\n",
      "| Epoch [  1/200] Iter [226/391]\t\tLoss: 1.1014 Acc@1: 41.000%\n",
      "| Epoch [  1/200] Iter [251/391]\t\tLoss: 1.2203 Acc@1: 43.000%\n",
      "| Epoch [  1/200] Iter [276/391]\t\tLoss: 1.0440 Acc@1: 44.000%\n",
      "| Epoch [  1/200] Iter [301/391]\t\tLoss: 1.2405 Acc@1: 45.000%\n",
      "| Epoch [  1/200] Iter [326/391]\t\tLoss: 1.0841 Acc@1: 46.000%\n",
      "| Epoch [  1/200] Iter [351/391]\t\tLoss: 1.1966 Acc@1: 47.000%\n",
      "| Epoch [  1/200] Iter [376/391]\t\tLoss: 1.0234 Acc@1: 48.000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Validation Epoch #1\t\t\tLoss: 1.9873 Acc@1: 55.00%\n",
      "| Saving Best model...\t\t\tTop1 = 55.00%\n",
      "\n",
      "=> Training Epoch #2, LR=0.1000\n",
      "| Epoch [  2/200] Iter [  1/391]\t\tLoss: 0.8834 Acc@1: 64.000%\n",
      "| Epoch [  2/200] Iter [ 26/391]\t\tLoss: 1.0821 Acc@1: 64.000%\n",
      "| Epoch [  2/200] Iter [ 51/391]\t\tLoss: 0.8829 Acc@1: 64.000%\n",
      "| Epoch [  2/200] Iter [ 76/391]\t\tLoss: 0.9673 Acc@1: 64.000%\n",
      "| Epoch [  2/200] Iter [101/391]\t\tLoss: 0.9550 Acc@1: 65.000%\n",
      "| Epoch [  2/200] Iter [126/391]\t\tLoss: 0.8953 Acc@1: 65.000%\n",
      "| Epoch [  2/200] Iter [151/391]\t\tLoss: 0.9676 Acc@1: 65.000%\n",
      "| Epoch [  2/200] Iter [176/391]\t\tLoss: 0.9150 Acc@1: 65.000%\n",
      "| Epoch [  2/200] Iter [201/391]\t\tLoss: 0.9251 Acc@1: 65.000%\n",
      "| Epoch [  2/200] Iter [226/391]\t\tLoss: 0.9824 Acc@1: 65.000%\n",
      "| Epoch [  2/200] Iter [251/391]\t\tLoss: 0.8517 Acc@1: 66.000%\n",
      "| Epoch [  2/200] Iter [276/391]\t\tLoss: 0.8937 Acc@1: 66.000%\n",
      "| Epoch [  2/200] Iter [301/391]\t\tLoss: 0.7505 Acc@1: 66.000%\n",
      "| Epoch [  2/200] Iter [326/391]\t\tLoss: 0.9191 Acc@1: 66.000%\n",
      "| Epoch [  2/200] Iter [351/391]\t\tLoss: 0.9896 Acc@1: 66.000%\n",
      "| Epoch [  2/200] Iter [376/391]\t\tLoss: 0.9703 Acc@1: 67.000%\n",
      "\n",
      "| Validation Epoch #2\t\t\tLoss: 1.9720 Acc@1: 54.00%\n",
      "\n",
      "=> Training Epoch #3, LR=0.1000\n",
      "| Epoch [  3/200] Iter [  1/391]\t\tLoss: 1.0259 Acc@1: 60.000%\n",
      "| Epoch [  3/200] Iter [ 26/391]\t\tLoss: 0.7210 Acc@1: 72.000%\n",
      "| Epoch [  3/200] Iter [ 51/391]\t\tLoss: 0.8323 Acc@1: 72.000%\n",
      "| Epoch [  3/200] Iter [ 76/391]\t\tLoss: 0.9102 Acc@1: 72.000%\n",
      "| Epoch [  3/200] Iter [101/391]\t\tLoss: 0.8952 Acc@1: 72.000%\n",
      "| Epoch [  3/200] Iter [126/391]\t\tLoss: 0.7132 Acc@1: 72.000%\n",
      "| Epoch [  3/200] Iter [151/391]\t\tLoss: 0.9337 Acc@1: 72.000%\n",
      "| Epoch [  3/200] Iter [176/391]\t\tLoss: 0.6311 Acc@1: 72.000%\n",
      "| Epoch [  3/200] Iter [201/391]\t\tLoss: 0.7130 Acc@1: 72.000%\n",
      "| Epoch [  3/200] Iter [226/391]\t\tLoss: 0.8131 Acc@1: 72.000%\n",
      "| Epoch [  3/200] Iter [251/391]\t\tLoss: 0.6751 Acc@1: 73.000%\n",
      "| Epoch [  3/200] Iter [276/391]\t\tLoss: 0.7007 Acc@1: 73.000%\n",
      "| Epoch [  3/200] Iter [301/391]\t\tLoss: 0.5323 Acc@1: 73.000%\n",
      "| Epoch [  3/200] Iter [326/391]\t\tLoss: 0.8287 Acc@1: 73.000%\n",
      "| Epoch [  3/200] Iter [351/391]\t\tLoss: 0.7125 Acc@1: 73.000%\n",
      "| Epoch [  3/200] Iter [376/391]\t\tLoss: 0.6357 Acc@1: 73.000%\n",
      "\n",
      "| Validation Epoch #3\t\t\tLoss: 1.0226 Acc@1: 67.00%\n",
      "| Saving Best model...\t\t\tTop1 = 67.00%\n",
      "\n",
      "=> Training Epoch #4, LR=0.1000\n",
      "| Epoch [  4/200] Iter [  1/391]\t\tLoss: 0.5877 Acc@1: 80.000%\n",
      "| Epoch [  4/200] Iter [ 26/391]\t\tLoss: 0.5911 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [ 51/391]\t\tLoss: 0.7764 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [ 76/391]\t\tLoss: 0.7588 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [101/391]\t\tLoss: 0.5538 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [126/391]\t\tLoss: 0.6922 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [151/391]\t\tLoss: 0.6430 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [176/391]\t\tLoss: 0.6291 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [201/391]\t\tLoss: 0.7323 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [226/391]\t\tLoss: 0.5780 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [251/391]\t\tLoss: 0.6751 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [276/391]\t\tLoss: 0.6210 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [301/391]\t\tLoss: 0.5080 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [326/391]\t\tLoss: 0.6377 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [351/391]\t\tLoss: 0.4499 Acc@1: 77.000%\n",
      "| Epoch [  4/200] Iter [376/391]\t\tLoss: 0.5649 Acc@1: 77.000%\n",
      "\n",
      "| Validation Epoch #4\t\t\tLoss: 0.8781 Acc@1: 70.00%\n",
      "| Saving Best model...\t\t\tTop1 = 70.00%\n",
      "\n",
      "=> Training Epoch #5, LR=0.1000\n",
      "| Epoch [  5/200] Iter [  1/391]\t\tLoss: 0.6244 Acc@1: 77.000%\n",
      "| Epoch [  5/200] Iter [ 26/391]\t\tLoss: 0.5179 Acc@1: 80.000%\n",
      "| Epoch [  5/200] Iter [ 51/391]\t\tLoss: 0.6264 Acc@1: 80.000%\n",
      "| Epoch [  5/200] Iter [ 76/391]\t\tLoss: 0.7247 Acc@1: 80.000%\n",
      "| Epoch [  5/200] Iter [101/391]\t\tLoss: 0.5120 Acc@1: 80.000%\n",
      "| Epoch [  5/200] Iter [126/391]\t\tLoss: 0.4743 Acc@1: 79.000%\n",
      "| Epoch [  5/200] Iter [151/391]\t\tLoss: 0.6177 Acc@1: 80.000%\n",
      "| Epoch [  5/200] Iter [176/391]\t\tLoss: 0.6990 Acc@1: 80.000%\n",
      "| Epoch [  5/200] Iter [201/391]\t\tLoss: 0.5762 Acc@1: 79.000%\n",
      "| Epoch [  5/200] Iter [226/391]\t\tLoss: 0.5392 Acc@1: 79.000%\n",
      "| Epoch [  5/200] Iter [251/391]\t\tLoss: 0.5840 Acc@1: 79.000%\n",
      "| Epoch [  5/200] Iter [276/391]\t\tLoss: 0.5518 Acc@1: 79.000%\n",
      "| Epoch [  5/200] Iter [301/391]\t\tLoss: 0.7709 Acc@1: 79.000%\n",
      "| Epoch [  5/200] Iter [326/391]\t\tLoss: 0.5927 Acc@1: 79.000%\n",
      "| Epoch [  5/200] Iter [351/391]\t\tLoss: 0.4901 Acc@1: 79.000%\n",
      "| Epoch [  5/200] Iter [376/391]\t\tLoss: 0.4966 Acc@1: 79.000%\n",
      "\n",
      "| Validation Epoch #5\t\t\tLoss: 1.4545 Acc@1: 66.00%\n",
      "\n",
      "=> Training Epoch #6, LR=0.1000\n",
      "| Epoch [  6/200] Iter [  1/391]\t\tLoss: 0.5317 Acc@1: 83.000%\n",
      "| Epoch [  6/200] Iter [ 26/391]\t\tLoss: 0.6752 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [ 51/391]\t\tLoss: 0.5882 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [ 76/391]\t\tLoss: 0.6204 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [101/391]\t\tLoss: 0.7001 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [126/391]\t\tLoss: 0.5090 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [151/391]\t\tLoss: 0.4528 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [176/391]\t\tLoss: 0.4067 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [201/391]\t\tLoss: 0.4809 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [226/391]\t\tLoss: 0.4775 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [251/391]\t\tLoss: 0.5270 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [276/391]\t\tLoss: 0.5244 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [301/391]\t\tLoss: 0.4767 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [326/391]\t\tLoss: 0.5738 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [351/391]\t\tLoss: 0.5506 Acc@1: 81.000%\n",
      "| Epoch [  6/200] Iter [376/391]\t\tLoss: 0.6693 Acc@1: 81.000%\n",
      "\n",
      "| Validation Epoch #6\t\t\tLoss: 0.4855 Acc@1: 77.00%\n",
      "| Saving Best model...\t\t\tTop1 = 77.00%\n",
      "\n",
      "=> Training Epoch #7, LR=0.1000\n",
      "| Epoch [  7/200] Iter [  1/391]\t\tLoss: 0.4162 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [ 26/391]\t\tLoss: 0.4546 Acc@1: 84.000%\n",
      "| Epoch [  7/200] Iter [ 51/391]\t\tLoss: 0.5235 Acc@1: 83.000%\n",
      "| Epoch [  7/200] Iter [ 76/391]\t\tLoss: 0.5462 Acc@1: 83.000%\n",
      "| Epoch [  7/200] Iter [101/391]\t\tLoss: 0.4719 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [126/391]\t\tLoss: 0.6211 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [151/391]\t\tLoss: 0.3685 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [176/391]\t\tLoss: 0.5250 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [201/391]\t\tLoss: 0.5356 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [226/391]\t\tLoss: 0.4795 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [251/391]\t\tLoss: 0.5481 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [276/391]\t\tLoss: 0.4518 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [301/391]\t\tLoss: 0.4732 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [326/391]\t\tLoss: 0.6262 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [351/391]\t\tLoss: 0.5280 Acc@1: 82.000%\n",
      "| Epoch [  7/200] Iter [376/391]\t\tLoss: 0.5226 Acc@1: 82.000%\n",
      "\n",
      "| Validation Epoch #7\t\t\tLoss: 0.7688 Acc@1: 78.00%\n",
      "| Saving Best model...\t\t\tTop1 = 78.00%\n",
      "\n",
      "=> Training Epoch #8, LR=0.1000\n",
      "| Epoch [  8/200] Iter [  1/391]\t\tLoss: 0.5046 Acc@1: 81.000%\n",
      "| Epoch [  8/200] Iter [ 26/391]\t\tLoss: 0.4862 Acc@1: 84.000%\n",
      "| Epoch [  8/200] Iter [ 51/391]\t\tLoss: 0.4307 Acc@1: 84.000%\n",
      "| Epoch [  8/200] Iter [ 76/391]\t\tLoss: 0.4664 Acc@1: 84.000%\n",
      "| Epoch [  8/200] Iter [101/391]\t\tLoss: 0.4705 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [126/391]\t\tLoss: 0.5601 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [151/391]\t\tLoss: 0.6050 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [176/391]\t\tLoss: 0.4899 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [201/391]\t\tLoss: 0.6247 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [226/391]\t\tLoss: 0.5337 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [251/391]\t\tLoss: 0.3584 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [276/391]\t\tLoss: 0.4427 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [301/391]\t\tLoss: 0.6154 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [326/391]\t\tLoss: 0.3768 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [351/391]\t\tLoss: 0.4870 Acc@1: 83.000%\n",
      "| Epoch [  8/200] Iter [376/391]\t\tLoss: 0.5491 Acc@1: 83.000%\n",
      "\n",
      "| Validation Epoch #8\t\t\tLoss: 0.5727 Acc@1: 79.00%\n",
      "| Saving Best model...\t\t\tTop1 = 79.00%\n",
      "\n",
      "=> Training Epoch #9, LR=0.1000\n",
      "| Epoch [  9/200] Iter [  1/391]\t\tLoss: 0.5821 Acc@1: 83.000%\n",
      "| Epoch [  9/200] Iter [ 26/391]\t\tLoss: 0.5814 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [ 51/391]\t\tLoss: 0.3392 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [ 76/391]\t\tLoss: 0.5513 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [101/391]\t\tLoss: 0.4303 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [126/391]\t\tLoss: 0.4547 Acc@1: 84.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [  9/200] Iter [151/391]\t\tLoss: 0.5255 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [176/391]\t\tLoss: 0.5556 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [201/391]\t\tLoss: 0.5049 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [226/391]\t\tLoss: 0.4705 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [251/391]\t\tLoss: 0.4567 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [276/391]\t\tLoss: 0.5377 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [301/391]\t\tLoss: 0.5712 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [326/391]\t\tLoss: 0.4975 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [351/391]\t\tLoss: 0.5223 Acc@1: 84.000%\n",
      "| Epoch [  9/200] Iter [376/391]\t\tLoss: 0.3130 Acc@1: 84.000%\n",
      "\n",
      "| Validation Epoch #9\t\t\tLoss: 0.8416 Acc@1: 77.00%\n",
      "\n",
      "=> Training Epoch #10, LR=0.1000\n",
      "| Epoch [ 10/200] Iter [  1/391]\t\tLoss: 0.4047 Acc@1: 85.000%\n",
      "| Epoch [ 10/200] Iter [ 26/391]\t\tLoss: 0.3140 Acc@1: 87.000%\n",
      "| Epoch [ 10/200] Iter [ 51/391]\t\tLoss: 0.6204 Acc@1: 85.000%\n",
      "| Epoch [ 10/200] Iter [ 76/391]\t\tLoss: 0.4065 Acc@1: 85.000%\n",
      "| Epoch [ 10/200] Iter [101/391]\t\tLoss: 0.3419 Acc@1: 84.000%\n",
      "| Epoch [ 10/200] Iter [126/391]\t\tLoss: 0.3583 Acc@1: 85.000%\n",
      "| Epoch [ 10/200] Iter [151/391]\t\tLoss: 0.4291 Acc@1: 85.000%\n",
      "| Epoch [ 10/200] Iter [176/391]\t\tLoss: 0.5112 Acc@1: 84.000%\n",
      "| Epoch [ 10/200] Iter [201/391]\t\tLoss: 0.3645 Acc@1: 85.000%\n",
      "| Epoch [ 10/200] Iter [226/391]\t\tLoss: 0.4627 Acc@1: 84.000%\n",
      "| Epoch [ 10/200] Iter [251/391]\t\tLoss: 0.3802 Acc@1: 84.000%\n",
      "| Epoch [ 10/200] Iter [276/391]\t\tLoss: 0.3585 Acc@1: 85.000%\n",
      "| Epoch [ 10/200] Iter [301/391]\t\tLoss: 0.4461 Acc@1: 84.000%\n",
      "| Epoch [ 10/200] Iter [326/391]\t\tLoss: 0.4959 Acc@1: 84.000%\n",
      "| Epoch [ 10/200] Iter [351/391]\t\tLoss: 0.6822 Acc@1: 84.000%\n",
      "| Epoch [ 10/200] Iter [376/391]\t\tLoss: 0.3511 Acc@1: 84.000%\n",
      "\n",
      "| Validation Epoch #10\t\t\tLoss: 0.9296 Acc@1: 72.00%\n",
      "\n",
      "=> Training Epoch #11, LR=0.1000\n",
      "| Epoch [ 11/200] Iter [  1/391]\t\tLoss: 0.3394 Acc@1: 89.000%\n",
      "| Epoch [ 11/200] Iter [ 26/391]\t\tLoss: 0.3780 Acc@1: 86.000%\n",
      "| Epoch [ 11/200] Iter [ 51/391]\t\tLoss: 0.3933 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [ 76/391]\t\tLoss: 0.5986 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [101/391]\t\tLoss: 0.4013 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [126/391]\t\tLoss: 0.4303 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [151/391]\t\tLoss: 0.5037 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [176/391]\t\tLoss: 0.3539 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [201/391]\t\tLoss: 0.4685 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [226/391]\t\tLoss: 0.3924 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [251/391]\t\tLoss: 0.3529 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [276/391]\t\tLoss: 0.5275 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [301/391]\t\tLoss: 0.3082 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [326/391]\t\tLoss: 0.4041 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [351/391]\t\tLoss: 0.4391 Acc@1: 85.000%\n",
      "| Epoch [ 11/200] Iter [376/391]\t\tLoss: 0.3753 Acc@1: 85.000%\n",
      "\n",
      "| Validation Epoch #11\t\t\tLoss: 0.5363 Acc@1: 81.00%\n",
      "| Saving Best model...\t\t\tTop1 = 81.00%\n",
      "\n",
      "=> Training Epoch #12, LR=0.1000\n",
      "| Epoch [ 12/200] Iter [  1/391]\t\tLoss: 0.3119 Acc@1: 91.000%\n",
      "| Epoch [ 12/200] Iter [ 26/391]\t\tLoss: 0.5135 Acc@1: 86.000%\n",
      "| Epoch [ 12/200] Iter [ 51/391]\t\tLoss: 0.3482 Acc@1: 86.000%\n",
      "| Epoch [ 12/200] Iter [ 76/391]\t\tLoss: 0.4559 Acc@1: 86.000%\n",
      "| Epoch [ 12/200] Iter [101/391]\t\tLoss: 0.4023 Acc@1: 86.000%\n",
      "| Epoch [ 12/200] Iter [126/391]\t\tLoss: 0.3364 Acc@1: 86.000%\n",
      "| Epoch [ 12/200] Iter [151/391]\t\tLoss: 0.5274 Acc@1: 85.000%\n",
      "| Epoch [ 12/200] Iter [176/391]\t\tLoss: 0.4589 Acc@1: 85.000%\n",
      "| Epoch [ 12/200] Iter [201/391]\t\tLoss: 0.5176 Acc@1: 85.000%\n",
      "| Epoch [ 12/200] Iter [226/391]\t\tLoss: 0.3836 Acc@1: 85.000%\n",
      "| Epoch [ 12/200] Iter [251/391]\t\tLoss: 0.4497 Acc@1: 85.000%\n",
      "| Epoch [ 12/200] Iter [276/391]\t\tLoss: 0.5963 Acc@1: 85.000%\n",
      "| Epoch [ 12/200] Iter [301/391]\t\tLoss: 0.4167 Acc@1: 85.000%\n",
      "| Epoch [ 12/200] Iter [326/391]\t\tLoss: 0.3470 Acc@1: 85.000%\n",
      "| Epoch [ 12/200] Iter [351/391]\t\tLoss: 0.2508 Acc@1: 85.000%\n",
      "| Epoch [ 12/200] Iter [376/391]\t\tLoss: 0.3987 Acc@1: 85.000%\n",
      "\n",
      "| Validation Epoch #12\t\t\tLoss: 0.8722 Acc@1: 77.00%\n",
      "\n",
      "=> Training Epoch #13, LR=0.1000\n",
      "| Epoch [ 13/200] Iter [  1/391]\t\tLoss: 0.3109 Acc@1: 89.000%\n",
      "| Epoch [ 13/200] Iter [ 26/391]\t\tLoss: 0.4705 Acc@1: 86.000%\n",
      "| Epoch [ 13/200] Iter [ 51/391]\t\tLoss: 0.4189 Acc@1: 86.000%\n",
      "| Epoch [ 13/200] Iter [ 76/391]\t\tLoss: 0.3872 Acc@1: 86.000%\n",
      "| Epoch [ 13/200] Iter [101/391]\t\tLoss: 0.4227 Acc@1: 86.000%\n",
      "| Epoch [ 13/200] Iter [126/391]\t\tLoss: 0.3690 Acc@1: 86.000%\n",
      "| Epoch [ 13/200] Iter [151/391]\t\tLoss: 0.4039 Acc@1: 85.000%\n",
      "| Epoch [ 13/200] Iter [176/391]\t\tLoss: 0.4123 Acc@1: 85.000%\n",
      "| Epoch [ 13/200] Iter [201/391]\t\tLoss: 0.5487 Acc@1: 85.000%\n",
      "| Epoch [ 13/200] Iter [226/391]\t\tLoss: 0.6275 Acc@1: 85.000%\n",
      "| Epoch [ 13/200] Iter [251/391]\t\tLoss: 0.3823 Acc@1: 85.000%\n",
      "| Epoch [ 13/200] Iter [276/391]\t\tLoss: 0.5366 Acc@1: 85.000%\n",
      "| Epoch [ 13/200] Iter [301/391]\t\tLoss: 0.3523 Acc@1: 85.000%\n",
      "| Epoch [ 13/200] Iter [326/391]\t\tLoss: 0.4664 Acc@1: 85.000%\n",
      "| Epoch [ 13/200] Iter [351/391]\t\tLoss: 0.4336 Acc@1: 85.000%\n",
      "| Epoch [ 13/200] Iter [376/391]\t\tLoss: 0.5605 Acc@1: 85.000%\n",
      "\n",
      "| Validation Epoch #13\t\t\tLoss: 0.6390 Acc@1: 79.00%\n",
      "\n",
      "=> Training Epoch #14, LR=0.1000\n",
      "| Epoch [ 14/200] Iter [  1/391]\t\tLoss: 0.3651 Acc@1: 87.000%\n",
      "| Epoch [ 14/200] Iter [ 26/391]\t\tLoss: 0.2916 Acc@1: 88.000%\n",
      "| Epoch [ 14/200] Iter [ 51/391]\t\tLoss: 0.3225 Acc@1: 87.000%\n",
      "| Epoch [ 14/200] Iter [ 76/391]\t\tLoss: 0.5023 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [101/391]\t\tLoss: 0.3008 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [126/391]\t\tLoss: 0.4896 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [151/391]\t\tLoss: 0.4166 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [176/391]\t\tLoss: 0.3577 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [201/391]\t\tLoss: 0.5158 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [226/391]\t\tLoss: 0.4255 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [251/391]\t\tLoss: 0.4550 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [276/391]\t\tLoss: 0.5394 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [301/391]\t\tLoss: 0.4315 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [326/391]\t\tLoss: 0.2403 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [351/391]\t\tLoss: 0.4230 Acc@1: 86.000%\n",
      "| Epoch [ 14/200] Iter [376/391]\t\tLoss: 0.4429 Acc@1: 86.000%\n",
      "\n",
      "| Validation Epoch #14\t\t\tLoss: 0.4784 Acc@1: 81.00%\n",
      "\n",
      "=> Training Epoch #15, LR=0.1000\n",
      "| Epoch [ 15/200] Iter [  1/391]\t\tLoss: 0.3392 Acc@1: 89.000%\n",
      "| Epoch [ 15/200] Iter [ 26/391]\t\tLoss: 0.4051 Acc@1: 88.000%\n",
      "| Epoch [ 15/200] Iter [ 51/391]\t\tLoss: 0.3049 Acc@1: 88.000%\n",
      "| Epoch [ 15/200] Iter [ 76/391]\t\tLoss: 0.3987 Acc@1: 87.000%\n",
      "| Epoch [ 15/200] Iter [101/391]\t\tLoss: 0.3567 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [126/391]\t\tLoss: 0.3082 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [151/391]\t\tLoss: 0.3429 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [176/391]\t\tLoss: 0.5442 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [201/391]\t\tLoss: 0.4053 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [226/391]\t\tLoss: 0.4700 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [251/391]\t\tLoss: 0.4279 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [276/391]\t\tLoss: 0.3442 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [301/391]\t\tLoss: 0.3613 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [326/391]\t\tLoss: 0.3862 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [351/391]\t\tLoss: 0.3667 Acc@1: 86.000%\n",
      "| Epoch [ 15/200] Iter [376/391]\t\tLoss: 0.4367 Acc@1: 86.000%\n",
      "\n",
      "| Validation Epoch #15\t\t\tLoss: 0.4396 Acc@1: 81.00%\n",
      "\n",
      "=> Training Epoch #16, LR=0.1000\n",
      "| Epoch [ 16/200] Iter [  1/391]\t\tLoss: 0.3505 Acc@1: 89.000%\n",
      "| Epoch [ 16/200] Iter [ 26/391]\t\tLoss: 0.3620 Acc@1: 87.000%\n",
      "| Epoch [ 16/200] Iter [ 51/391]\t\tLoss: 0.3621 Acc@1: 87.000%\n",
      "| Epoch [ 16/200] Iter [ 76/391]\t\tLoss: 0.4846 Acc@1: 87.000%\n",
      "| Epoch [ 16/200] Iter [101/391]\t\tLoss: 0.4764 Acc@1: 87.000%\n",
      "| Epoch [ 16/200] Iter [126/391]\t\tLoss: 0.3754 Acc@1: 87.000%\n",
      "| Epoch [ 16/200] Iter [151/391]\t\tLoss: 0.3892 Acc@1: 87.000%\n",
      "| Epoch [ 16/200] Iter [176/391]\t\tLoss: 0.3140 Acc@1: 87.000%\n",
      "| Epoch [ 16/200] Iter [201/391]\t\tLoss: 0.5270 Acc@1: 87.000%\n",
      "| Epoch [ 16/200] Iter [226/391]\t\tLoss: 0.3587 Acc@1: 86.000%\n",
      "| Epoch [ 16/200] Iter [251/391]\t\tLoss: 0.5364 Acc@1: 87.000%\n",
      "| Epoch [ 16/200] Iter [276/391]\t\tLoss: 0.4347 Acc@1: 86.000%\n",
      "| Epoch [ 16/200] Iter [301/391]\t\tLoss: 0.2074 Acc@1: 86.000%\n",
      "| Epoch [ 16/200] Iter [326/391]\t\tLoss: 0.3154 Acc@1: 86.000%\n",
      "| Epoch [ 16/200] Iter [351/391]\t\tLoss: 0.4551 Acc@1: 86.000%\n",
      "| Epoch [ 16/200] Iter [376/391]\t\tLoss: 0.4984 Acc@1: 86.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Validation Epoch #16\t\t\tLoss: 0.6309 Acc@1: 78.00%\n",
      "\n",
      "=> Training Epoch #17, LR=0.1000\n",
      "| Epoch [ 17/200] Iter [  1/391]\t\tLoss: 0.3848 Acc@1: 85.000%\n",
      "| Epoch [ 17/200] Iter [ 26/391]\t\tLoss: 0.2369 Acc@1: 88.000%\n",
      "| Epoch [ 17/200] Iter [ 51/391]\t\tLoss: 0.2857 Acc@1: 87.000%\n",
      "| Epoch [ 17/200] Iter [ 76/391]\t\tLoss: 0.3571 Acc@1: 87.000%\n",
      "| Epoch [ 17/200] Iter [101/391]\t\tLoss: 0.3434 Acc@1: 86.000%\n",
      "| Epoch [ 17/200] Iter [126/391]\t\tLoss: 0.4298 Acc@1: 87.000%\n",
      "| Epoch [ 17/200] Iter [151/391]\t\tLoss: 0.4789 Acc@1: 86.000%\n",
      "| Epoch [ 17/200] Iter [176/391]\t\tLoss: 0.3867 Acc@1: 86.000%\n",
      "| Epoch [ 17/200] Iter [201/391]\t\tLoss: 0.3064 Acc@1: 87.000%\n",
      "| Epoch [ 17/200] Iter [226/391]\t\tLoss: 0.3709 Acc@1: 87.000%\n",
      "| Epoch [ 17/200] Iter [251/391]\t\tLoss: 0.3327 Acc@1: 87.000%\n",
      "| Epoch [ 17/200] Iter [276/391]\t\tLoss: 0.4379 Acc@1: 87.000%\n",
      "| Epoch [ 17/200] Iter [301/391]\t\tLoss: 0.4029 Acc@1: 87.000%\n",
      "| Epoch [ 17/200] Iter [326/391]\t\tLoss: 0.2755 Acc@1: 86.000%\n",
      "| Epoch [ 17/200] Iter [351/391]\t\tLoss: 0.4051 Acc@1: 86.000%\n",
      "| Epoch [ 17/200] Iter [376/391]\t\tLoss: 0.3902 Acc@1: 86.000%\n",
      "\n",
      "| Validation Epoch #17\t\t\tLoss: 0.7039 Acc@1: 77.00%\n",
      "\n",
      "=> Training Epoch #18, LR=0.1000\n",
      "| Epoch [ 18/200] Iter [  1/391]\t\tLoss: 0.3884 Acc@1: 86.000%\n",
      "| Epoch [ 18/200] Iter [ 26/391]\t\tLoss: 0.3383 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [ 51/391]\t\tLoss: 0.5570 Acc@1: 88.000%\n",
      "| Epoch [ 18/200] Iter [ 76/391]\t\tLoss: 0.2705 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [101/391]\t\tLoss: 0.3848 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [126/391]\t\tLoss: 0.4943 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [151/391]\t\tLoss: 0.3993 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [176/391]\t\tLoss: 0.2561 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [201/391]\t\tLoss: 0.3249 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [226/391]\t\tLoss: 0.4337 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [251/391]\t\tLoss: 0.4316 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [276/391]\t\tLoss: 0.3755 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [301/391]\t\tLoss: 0.3609 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [326/391]\t\tLoss: 0.4571 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [351/391]\t\tLoss: 0.3907 Acc@1: 87.000%\n",
      "| Epoch [ 18/200] Iter [376/391]\t\tLoss: 0.2558 Acc@1: 87.000%\n",
      "\n",
      "| Validation Epoch #18\t\t\tLoss: 0.5807 Acc@1: 78.00%\n",
      "\n",
      "=> Training Epoch #19, LR=0.1000\n",
      "| Epoch [ 19/200] Iter [  1/391]\t\tLoss: 0.3308 Acc@1: 89.000%\n",
      "| Epoch [ 19/200] Iter [ 26/391]\t\tLoss: 0.4755 Acc@1: 88.000%\n",
      "| Epoch [ 19/200] Iter [ 51/391]\t\tLoss: 0.3769 Acc@1: 88.000%\n",
      "| Epoch [ 19/200] Iter [ 76/391]\t\tLoss: 0.2949 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [101/391]\t\tLoss: 0.4778 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [126/391]\t\tLoss: 0.2850 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [151/391]\t\tLoss: 0.3965 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [176/391]\t\tLoss: 0.5702 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [201/391]\t\tLoss: 0.3373 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [226/391]\t\tLoss: 0.4521 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [251/391]\t\tLoss: 0.2747 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [276/391]\t\tLoss: 0.4734 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [301/391]\t\tLoss: 0.3354 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [326/391]\t\tLoss: 0.4189 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [351/391]\t\tLoss: 0.3057 Acc@1: 87.000%\n",
      "| Epoch [ 19/200] Iter [376/391]\t\tLoss: 0.3961 Acc@1: 87.000%\n",
      "\n",
      "| Validation Epoch #19\t\t\tLoss: 1.0072 Acc@1: 74.00%\n",
      "\n",
      "=> Training Epoch #20, LR=0.1000\n",
      "| Epoch [ 20/200] Iter [  1/391]\t\tLoss: 0.4706 Acc@1: 82.000%\n",
      "| Epoch [ 20/200] Iter [ 26/391]\t\tLoss: 0.3449 Acc@1: 88.000%\n",
      "| Epoch [ 20/200] Iter [ 51/391]\t\tLoss: 0.3309 Acc@1: 88.000%\n",
      "| Epoch [ 20/200] Iter [ 76/391]\t\tLoss: 0.3959 Acc@1: 88.000%\n",
      "| Epoch [ 20/200] Iter [101/391]\t\tLoss: 0.3989 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [126/391]\t\tLoss: 0.4114 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [151/391]\t\tLoss: 0.3314 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [176/391]\t\tLoss: 0.4185 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [201/391]\t\tLoss: 0.2618 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [226/391]\t\tLoss: 0.2861 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [251/391]\t\tLoss: 0.4279 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [276/391]\t\tLoss: 0.5148 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [301/391]\t\tLoss: 0.3574 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [326/391]\t\tLoss: 0.3045 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [351/391]\t\tLoss: 0.4513 Acc@1: 87.000%\n",
      "| Epoch [ 20/200] Iter [376/391]\t\tLoss: 0.3262 Acc@1: 87.000%\n",
      "\n",
      "| Validation Epoch #20\t\t\tLoss: 0.4089 Acc@1: 84.00%\n",
      "| Saving Best model...\t\t\tTop1 = 84.00%\n",
      "\n",
      "=> Training Epoch #21, LR=0.1000\n",
      "| Epoch [ 21/200] Iter [  1/391]\t\tLoss: 0.3155 Acc@1: 89.000%\n",
      "| Epoch [ 21/200] Iter [ 26/391]\t\tLoss: 0.2589 Acc@1: 89.000%\n",
      "| Epoch [ 21/200] Iter [ 51/391]\t\tLoss: 0.3993 Acc@1: 89.000%\n",
      "| Epoch [ 21/200] Iter [ 76/391]\t\tLoss: 0.3363 Acc@1: 88.000%\n",
      "| Epoch [ 21/200] Iter [101/391]\t\tLoss: 0.4490 Acc@1: 88.000%\n",
      "| Epoch [ 21/200] Iter [126/391]\t\tLoss: 0.4069 Acc@1: 88.000%\n",
      "| Epoch [ 21/200] Iter [151/391]\t\tLoss: 0.4877 Acc@1: 88.000%\n",
      "| Epoch [ 21/200] Iter [176/391]\t\tLoss: 0.3743 Acc@1: 87.000%\n",
      "| Epoch [ 21/200] Iter [201/391]\t\tLoss: 0.2865 Acc@1: 87.000%\n",
      "| Epoch [ 21/200] Iter [226/391]\t\tLoss: 0.3246 Acc@1: 87.000%\n",
      "| Epoch [ 21/200] Iter [251/391]\t\tLoss: 0.3301 Acc@1: 87.000%\n",
      "| Epoch [ 21/200] Iter [276/391]\t\tLoss: 0.3122 Acc@1: 87.000%\n",
      "| Epoch [ 21/200] Iter [301/391]\t\tLoss: 0.4141 Acc@1: 87.000%\n",
      "| Epoch [ 21/200] Iter [326/391]\t\tLoss: 0.3837 Acc@1: 87.000%\n",
      "| Epoch [ 21/200] Iter [351/391]\t\tLoss: 0.3852 Acc@1: 87.000%\n",
      "| Epoch [ 21/200] Iter [376/391]\t\tLoss: 0.3580 Acc@1: 87.000%\n",
      "\n",
      "| Validation Epoch #21\t\t\tLoss: 0.6126 Acc@1: 80.00%\n",
      "\n",
      "=> Training Epoch #22, LR=0.1000\n",
      "| Epoch [ 22/200] Iter [  1/391]\t\tLoss: 0.3803 Acc@1: 85.000%\n",
      "| Epoch [ 22/200] Iter [ 26/391]\t\tLoss: 0.2743 Acc@1: 90.000%\n",
      "| Epoch [ 22/200] Iter [ 51/391]\t\tLoss: 0.2778 Acc@1: 89.000%\n",
      "| Epoch [ 22/200] Iter [ 76/391]\t\tLoss: 0.3464 Acc@1: 88.000%\n",
      "| Epoch [ 22/200] Iter [101/391]\t\tLoss: 0.3128 Acc@1: 88.000%\n",
      "| Epoch [ 22/200] Iter [126/391]\t\tLoss: 0.2778 Acc@1: 88.000%\n",
      "| Epoch [ 22/200] Iter [151/391]\t\tLoss: 0.2901 Acc@1: 88.000%\n",
      "| Epoch [ 22/200] Iter [176/391]\t\tLoss: 0.2747 Acc@1: 88.000%\n",
      "| Epoch [ 22/200] Iter [201/391]\t\tLoss: 0.3674 Acc@1: 88.000%\n",
      "| Epoch [ 22/200] Iter [226/391]\t\tLoss: 0.3961 Acc@1: 87.000%\n",
      "| Epoch [ 22/200] Iter [251/391]\t\tLoss: 0.3114 Acc@1: 87.000%\n",
      "| Epoch [ 22/200] Iter [276/391]\t\tLoss: 0.4958 Acc@1: 87.000%\n",
      "| Epoch [ 22/200] Iter [301/391]\t\tLoss: 0.3423 Acc@1: 87.000%\n",
      "| Epoch [ 22/200] Iter [326/391]\t\tLoss: 0.2670 Acc@1: 87.000%\n",
      "| Epoch [ 22/200] Iter [351/391]\t\tLoss: 0.2234 Acc@1: 87.000%\n",
      "| Epoch [ 22/200] Iter [376/391]\t\tLoss: 0.2329 Acc@1: 87.000%\n",
      "\n",
      "| Validation Epoch #22\t\t\tLoss: 0.4894 Acc@1: 81.00%\n",
      "\n",
      "=> Training Epoch #23, LR=0.1000\n",
      "| Epoch [ 23/200] Iter [  1/391]\t\tLoss: 0.2799 Acc@1: 92.000%\n",
      "| Epoch [ 23/200] Iter [ 26/391]\t\tLoss: 0.3118 Acc@1: 89.000%\n",
      "| Epoch [ 23/200] Iter [ 51/391]\t\tLoss: 0.2696 Acc@1: 89.000%\n",
      "| Epoch [ 23/200] Iter [ 76/391]\t\tLoss: 0.3018 Acc@1: 89.000%\n",
      "| Epoch [ 23/200] Iter [101/391]\t\tLoss: 0.4354 Acc@1: 89.000%\n",
      "| Epoch [ 23/200] Iter [126/391]\t\tLoss: 0.3347 Acc@1: 88.000%\n",
      "| Epoch [ 23/200] Iter [151/391]\t\tLoss: 0.4071 Acc@1: 88.000%\n",
      "| Epoch [ 23/200] Iter [176/391]\t\tLoss: 0.3917 Acc@1: 88.000%\n",
      "| Epoch [ 23/200] Iter [201/391]\t\tLoss: 0.4667 Acc@1: 88.000%\n",
      "| Epoch [ 23/200] Iter [226/391]\t\tLoss: 0.4577 Acc@1: 88.000%\n",
      "| Epoch [ 23/200] Iter [251/391]\t\tLoss: 0.3233 Acc@1: 88.000%\n",
      "| Epoch [ 23/200] Iter [276/391]\t\tLoss: 0.4589 Acc@1: 88.000%\n",
      "| Epoch [ 23/200] Iter [301/391]\t\tLoss: 0.3873 Acc@1: 87.000%\n",
      "| Epoch [ 23/200] Iter [326/391]\t\tLoss: 0.4479 Acc@1: 87.000%\n",
      "| Epoch [ 23/200] Iter [351/391]\t\tLoss: 0.4380 Acc@1: 87.000%\n",
      "| Epoch [ 23/200] Iter [376/391]\t\tLoss: 0.3227 Acc@1: 87.000%\n",
      "\n",
      "| Validation Epoch #23\t\t\tLoss: 0.3546 Acc@1: 84.00%\n",
      "\n",
      "=> Training Epoch #24, LR=0.1000\n",
      "| Epoch [ 24/200] Iter [  1/391]\t\tLoss: 0.3371 Acc@1: 86.000%\n",
      "| Epoch [ 24/200] Iter [ 26/391]\t\tLoss: 0.3285 Acc@1: 89.000%\n",
      "| Epoch [ 24/200] Iter [ 51/391]\t\tLoss: 0.2906 Acc@1: 89.000%\n",
      "| Epoch [ 24/200] Iter [ 76/391]\t\tLoss: 0.3278 Acc@1: 89.000%\n",
      "| Epoch [ 24/200] Iter [101/391]\t\tLoss: 0.3218 Acc@1: 88.000%\n",
      "| Epoch [ 24/200] Iter [126/391]\t\tLoss: 0.3169 Acc@1: 88.000%\n",
      "| Epoch [ 24/200] Iter [151/391]\t\tLoss: 0.3103 Acc@1: 88.000%\n",
      "| Epoch [ 24/200] Iter [176/391]\t\tLoss: 0.2604 Acc@1: 88.000%\n",
      "| Epoch [ 24/200] Iter [201/391]\t\tLoss: 0.2510 Acc@1: 88.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 24/200] Iter [226/391]\t\tLoss: 0.4415 Acc@1: 88.000%\n",
      "| Epoch [ 24/200] Iter [251/391]\t\tLoss: 0.2017 Acc@1: 88.000%\n",
      "| Epoch [ 24/200] Iter [276/391]\t\tLoss: 0.2879 Acc@1: 88.000%\n",
      "| Epoch [ 24/200] Iter [301/391]\t\tLoss: 0.3040 Acc@1: 88.000%\n",
      "| Epoch [ 24/200] Iter [326/391]\t\tLoss: 0.3322 Acc@1: 87.000%\n",
      "| Epoch [ 24/200] Iter [351/391]\t\tLoss: 0.2777 Acc@1: 87.000%\n",
      "| Epoch [ 24/200] Iter [376/391]\t\tLoss: 0.2334 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #24\t\t\tLoss: 0.6218 Acc@1: 82.00%\n",
      "\n",
      "=> Training Epoch #25, LR=0.1000\n",
      "| Epoch [ 25/200] Iter [  1/391]\t\tLoss: 0.3720 Acc@1: 87.000%\n",
      "| Epoch [ 25/200] Iter [ 26/391]\t\tLoss: 0.3313 Acc@1: 89.000%\n",
      "| Epoch [ 25/200] Iter [ 51/391]\t\tLoss: 0.3912 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [ 76/391]\t\tLoss: 0.4968 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [101/391]\t\tLoss: 0.3895 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [126/391]\t\tLoss: 0.3672 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [151/391]\t\tLoss: 0.5456 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [176/391]\t\tLoss: 0.3258 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [201/391]\t\tLoss: 0.4956 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [226/391]\t\tLoss: 0.2665 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [251/391]\t\tLoss: 0.2781 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [276/391]\t\tLoss: 0.5064 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [301/391]\t\tLoss: 0.3258 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [326/391]\t\tLoss: 0.3787 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [351/391]\t\tLoss: 0.3621 Acc@1: 88.000%\n",
      "| Epoch [ 25/200] Iter [376/391]\t\tLoss: 0.4876 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #25\t\t\tLoss: 0.2407 Acc@1: 86.00%\n",
      "| Saving Best model...\t\t\tTop1 = 86.00%\n",
      "\n",
      "=> Training Epoch #26, LR=0.1000\n",
      "| Epoch [ 26/200] Iter [  1/391]\t\tLoss: 0.1856 Acc@1: 95.000%\n",
      "| Epoch [ 26/200] Iter [ 26/391]\t\tLoss: 0.3197 Acc@1: 90.000%\n",
      "| Epoch [ 26/200] Iter [ 51/391]\t\tLoss: 0.3009 Acc@1: 89.000%\n",
      "| Epoch [ 26/200] Iter [ 76/391]\t\tLoss: 0.3827 Acc@1: 89.000%\n",
      "| Epoch [ 26/200] Iter [101/391]\t\tLoss: 0.3905 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [126/391]\t\tLoss: 0.4213 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [151/391]\t\tLoss: 0.2371 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [176/391]\t\tLoss: 0.2888 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [201/391]\t\tLoss: 0.2341 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [226/391]\t\tLoss: 0.2563 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [251/391]\t\tLoss: 0.3985 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [276/391]\t\tLoss: 0.4042 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [301/391]\t\tLoss: 0.4138 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [326/391]\t\tLoss: 0.3557 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [351/391]\t\tLoss: 0.3128 Acc@1: 88.000%\n",
      "| Epoch [ 26/200] Iter [376/391]\t\tLoss: 0.3488 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #26\t\t\tLoss: 0.3180 Acc@1: 85.00%\n",
      "\n",
      "=> Training Epoch #27, LR=0.1000\n",
      "| Epoch [ 27/200] Iter [  1/391]\t\tLoss: 0.3031 Acc@1: 89.000%\n",
      "| Epoch [ 27/200] Iter [ 26/391]\t\tLoss: 0.2610 Acc@1: 90.000%\n",
      "| Epoch [ 27/200] Iter [ 51/391]\t\tLoss: 0.2484 Acc@1: 90.000%\n",
      "| Epoch [ 27/200] Iter [ 76/391]\t\tLoss: 0.4597 Acc@1: 89.000%\n",
      "| Epoch [ 27/200] Iter [101/391]\t\tLoss: 0.4062 Acc@1: 89.000%\n",
      "| Epoch [ 27/200] Iter [126/391]\t\tLoss: 0.4674 Acc@1: 89.000%\n",
      "| Epoch [ 27/200] Iter [151/391]\t\tLoss: 0.3145 Acc@1: 88.000%\n",
      "| Epoch [ 27/200] Iter [176/391]\t\tLoss: 0.3542 Acc@1: 88.000%\n",
      "| Epoch [ 27/200] Iter [201/391]\t\tLoss: 0.4399 Acc@1: 88.000%\n",
      "| Epoch [ 27/200] Iter [226/391]\t\tLoss: 0.3183 Acc@1: 88.000%\n",
      "| Epoch [ 27/200] Iter [251/391]\t\tLoss: 0.3825 Acc@1: 88.000%\n",
      "| Epoch [ 27/200] Iter [276/391]\t\tLoss: 0.3671 Acc@1: 88.000%\n",
      "| Epoch [ 27/200] Iter [301/391]\t\tLoss: 0.3025 Acc@1: 88.000%\n",
      "| Epoch [ 27/200] Iter [326/391]\t\tLoss: 0.4311 Acc@1: 88.000%\n",
      "| Epoch [ 27/200] Iter [351/391]\t\tLoss: 0.4172 Acc@1: 88.000%\n",
      "| Epoch [ 27/200] Iter [376/391]\t\tLoss: 0.2666 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #27\t\t\tLoss: 0.6449 Acc@1: 78.00%\n",
      "\n",
      "=> Training Epoch #28, LR=0.1000\n",
      "| Epoch [ 28/200] Iter [  1/391]\t\tLoss: 0.5060 Acc@1: 85.000%\n",
      "| Epoch [ 28/200] Iter [ 26/391]\t\tLoss: 0.2551 Acc@1: 89.000%\n",
      "| Epoch [ 28/200] Iter [ 51/391]\t\tLoss: 0.2644 Acc@1: 89.000%\n",
      "| Epoch [ 28/200] Iter [ 76/391]\t\tLoss: 0.2996 Acc@1: 89.000%\n",
      "| Epoch [ 28/200] Iter [101/391]\t\tLoss: 0.3388 Acc@1: 89.000%\n",
      "| Epoch [ 28/200] Iter [126/391]\t\tLoss: 0.4273 Acc@1: 89.000%\n",
      "| Epoch [ 28/200] Iter [151/391]\t\tLoss: 0.4135 Acc@1: 89.000%\n",
      "| Epoch [ 28/200] Iter [176/391]\t\tLoss: 0.3458 Acc@1: 89.000%\n",
      "| Epoch [ 28/200] Iter [201/391]\t\tLoss: 0.4237 Acc@1: 88.000%\n",
      "| Epoch [ 28/200] Iter [226/391]\t\tLoss: 0.3172 Acc@1: 88.000%\n",
      "| Epoch [ 28/200] Iter [251/391]\t\tLoss: 0.2698 Acc@1: 88.000%\n",
      "| Epoch [ 28/200] Iter [276/391]\t\tLoss: 0.4248 Acc@1: 88.000%\n",
      "| Epoch [ 28/200] Iter [301/391]\t\tLoss: 0.3367 Acc@1: 88.000%\n",
      "| Epoch [ 28/200] Iter [326/391]\t\tLoss: 0.2541 Acc@1: 88.000%\n",
      "| Epoch [ 28/200] Iter [351/391]\t\tLoss: 0.4250 Acc@1: 88.000%\n",
      "| Epoch [ 28/200] Iter [376/391]\t\tLoss: 0.2790 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #28\t\t\tLoss: 0.4354 Acc@1: 85.00%\n",
      "\n",
      "=> Training Epoch #29, LR=0.1000\n",
      "| Epoch [ 29/200] Iter [  1/391]\t\tLoss: 0.3606 Acc@1: 87.000%\n",
      "| Epoch [ 29/200] Iter [ 26/391]\t\tLoss: 0.3051 Acc@1: 89.000%\n",
      "| Epoch [ 29/200] Iter [ 51/391]\t\tLoss: 0.3650 Acc@1: 89.000%\n",
      "| Epoch [ 29/200] Iter [ 76/391]\t\tLoss: 0.2806 Acc@1: 89.000%\n",
      "| Epoch [ 29/200] Iter [101/391]\t\tLoss: 0.2702 Acc@1: 89.000%\n",
      "| Epoch [ 29/200] Iter [126/391]\t\tLoss: 0.4019 Acc@1: 89.000%\n",
      "| Epoch [ 29/200] Iter [151/391]\t\tLoss: 0.3193 Acc@1: 88.000%\n",
      "| Epoch [ 29/200] Iter [176/391]\t\tLoss: 0.3069 Acc@1: 88.000%\n",
      "| Epoch [ 29/200] Iter [201/391]\t\tLoss: 0.3616 Acc@1: 88.000%\n",
      "| Epoch [ 29/200] Iter [226/391]\t\tLoss: 0.3431 Acc@1: 88.000%\n",
      "| Epoch [ 29/200] Iter [251/391]\t\tLoss: 0.4765 Acc@1: 88.000%\n",
      "| Epoch [ 29/200] Iter [276/391]\t\tLoss: 0.3521 Acc@1: 88.000%\n",
      "| Epoch [ 29/200] Iter [301/391]\t\tLoss: 0.3695 Acc@1: 88.000%\n",
      "| Epoch [ 29/200] Iter [326/391]\t\tLoss: 0.3001 Acc@1: 88.000%\n",
      "| Epoch [ 29/200] Iter [351/391]\t\tLoss: 0.3031 Acc@1: 88.000%\n",
      "| Epoch [ 29/200] Iter [376/391]\t\tLoss: 0.3269 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #29\t\t\tLoss: 0.7203 Acc@1: 79.00%\n",
      "\n",
      "=> Training Epoch #30, LR=0.1000\n",
      "| Epoch [ 30/200] Iter [  1/391]\t\tLoss: 0.2869 Acc@1: 91.000%\n",
      "| Epoch [ 30/200] Iter [ 26/391]\t\tLoss: 0.2983 Acc@1: 90.000%\n",
      "| Epoch [ 30/200] Iter [ 51/391]\t\tLoss: 0.2664 Acc@1: 89.000%\n",
      "| Epoch [ 30/200] Iter [ 76/391]\t\tLoss: 0.2629 Acc@1: 89.000%\n",
      "| Epoch [ 30/200] Iter [101/391]\t\tLoss: 0.3241 Acc@1: 89.000%\n",
      "| Epoch [ 30/200] Iter [126/391]\t\tLoss: 0.3636 Acc@1: 88.000%\n",
      "| Epoch [ 30/200] Iter [151/391]\t\tLoss: 0.3871 Acc@1: 88.000%\n",
      "| Epoch [ 30/200] Iter [176/391]\t\tLoss: 0.2407 Acc@1: 88.000%\n",
      "| Epoch [ 30/200] Iter [201/391]\t\tLoss: 0.2109 Acc@1: 88.000%\n",
      "| Epoch [ 30/200] Iter [226/391]\t\tLoss: 0.3595 Acc@1: 88.000%\n",
      "| Epoch [ 30/200] Iter [251/391]\t\tLoss: 0.2746 Acc@1: 88.000%\n",
      "| Epoch [ 30/200] Iter [276/391]\t\tLoss: 0.3649 Acc@1: 88.000%\n",
      "| Epoch [ 30/200] Iter [301/391]\t\tLoss: 0.4492 Acc@1: 88.000%\n",
      "| Epoch [ 30/200] Iter [326/391]\t\tLoss: 0.3103 Acc@1: 88.000%\n",
      "| Epoch [ 30/200] Iter [351/391]\t\tLoss: 0.3155 Acc@1: 88.000%\n",
      "| Epoch [ 30/200] Iter [376/391]\t\tLoss: 0.3213 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #30\t\t\tLoss: 0.4192 Acc@1: 83.00%\n",
      "\n",
      "=> Training Epoch #31, LR=0.1000\n",
      "| Epoch [ 31/200] Iter [  1/391]\t\tLoss: 0.4336 Acc@1: 85.000%\n",
      "| Epoch [ 31/200] Iter [ 26/391]\t\tLoss: 0.1889 Acc@1: 90.000%\n",
      "| Epoch [ 31/200] Iter [ 51/391]\t\tLoss: 0.2667 Acc@1: 89.000%\n",
      "| Epoch [ 31/200] Iter [ 76/391]\t\tLoss: 0.3286 Acc@1: 89.000%\n",
      "| Epoch [ 31/200] Iter [101/391]\t\tLoss: 0.2858 Acc@1: 89.000%\n",
      "| Epoch [ 31/200] Iter [126/391]\t\tLoss: 0.2945 Acc@1: 89.000%\n",
      "| Epoch [ 31/200] Iter [151/391]\t\tLoss: 0.3999 Acc@1: 89.000%\n",
      "| Epoch [ 31/200] Iter [176/391]\t\tLoss: 0.3443 Acc@1: 89.000%\n",
      "| Epoch [ 31/200] Iter [201/391]\t\tLoss: 0.4020 Acc@1: 89.000%\n",
      "| Epoch [ 31/200] Iter [226/391]\t\tLoss: 0.3942 Acc@1: 88.000%\n",
      "| Epoch [ 31/200] Iter [251/391]\t\tLoss: 0.2804 Acc@1: 88.000%\n",
      "| Epoch [ 31/200] Iter [276/391]\t\tLoss: 0.2255 Acc@1: 88.000%\n",
      "| Epoch [ 31/200] Iter [301/391]\t\tLoss: 0.3305 Acc@1: 88.000%\n",
      "| Epoch [ 31/200] Iter [326/391]\t\tLoss: 0.2818 Acc@1: 88.000%\n",
      "| Epoch [ 31/200] Iter [351/391]\t\tLoss: 0.3980 Acc@1: 88.000%\n",
      "| Epoch [ 31/200] Iter [376/391]\t\tLoss: 0.3243 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #31\t\t\tLoss: 0.5387 Acc@1: 83.00%\n",
      "\n",
      "=> Training Epoch #32, LR=0.1000\n",
      "| Epoch [ 32/200] Iter [  1/391]\t\tLoss: 0.2973 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [ 26/391]\t\tLoss: 0.2333 Acc@1: 90.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 32/200] Iter [ 51/391]\t\tLoss: 0.3901 Acc@1: 90.000%\n",
      "| Epoch [ 32/200] Iter [ 76/391]\t\tLoss: 0.2619 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [101/391]\t\tLoss: 0.2298 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [126/391]\t\tLoss: 0.2884 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [151/391]\t\tLoss: 0.5098 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [176/391]\t\tLoss: 0.3813 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [201/391]\t\tLoss: 0.3029 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [226/391]\t\tLoss: 0.2539 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [251/391]\t\tLoss: 0.3277 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [276/391]\t\tLoss: 0.3323 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [301/391]\t\tLoss: 0.3040 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [326/391]\t\tLoss: 0.2536 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [351/391]\t\tLoss: 0.4398 Acc@1: 89.000%\n",
      "| Epoch [ 32/200] Iter [376/391]\t\tLoss: 0.2721 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #32\t\t\tLoss: 0.8520 Acc@1: 77.00%\n",
      "\n",
      "=> Training Epoch #33, LR=0.1000\n",
      "| Epoch [ 33/200] Iter [  1/391]\t\tLoss: 0.2698 Acc@1: 91.000%\n",
      "| Epoch [ 33/200] Iter [ 26/391]\t\tLoss: 0.2499 Acc@1: 90.000%\n",
      "| Epoch [ 33/200] Iter [ 51/391]\t\tLoss: 0.2701 Acc@1: 90.000%\n",
      "| Epoch [ 33/200] Iter [ 76/391]\t\tLoss: 0.3043 Acc@1: 89.000%\n",
      "| Epoch [ 33/200] Iter [101/391]\t\tLoss: 0.2313 Acc@1: 89.000%\n",
      "| Epoch [ 33/200] Iter [126/391]\t\tLoss: 0.2913 Acc@1: 89.000%\n",
      "| Epoch [ 33/200] Iter [151/391]\t\tLoss: 0.3056 Acc@1: 89.000%\n",
      "| Epoch [ 33/200] Iter [176/391]\t\tLoss: 0.3977 Acc@1: 88.000%\n",
      "| Epoch [ 33/200] Iter [201/391]\t\tLoss: 0.4260 Acc@1: 88.000%\n",
      "| Epoch [ 33/200] Iter [226/391]\t\tLoss: 0.2290 Acc@1: 88.000%\n",
      "| Epoch [ 33/200] Iter [251/391]\t\tLoss: 0.2220 Acc@1: 88.000%\n",
      "| Epoch [ 33/200] Iter [276/391]\t\tLoss: 0.3841 Acc@1: 88.000%\n",
      "| Epoch [ 33/200] Iter [301/391]\t\tLoss: 0.2285 Acc@1: 88.000%\n",
      "| Epoch [ 33/200] Iter [326/391]\t\tLoss: 0.2338 Acc@1: 88.000%\n",
      "| Epoch [ 33/200] Iter [351/391]\t\tLoss: 0.4357 Acc@1: 88.000%\n",
      "| Epoch [ 33/200] Iter [376/391]\t\tLoss: 0.3179 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #33\t\t\tLoss: 0.9698 Acc@1: 80.00%\n",
      "\n",
      "=> Training Epoch #34, LR=0.1000\n",
      "| Epoch [ 34/200] Iter [  1/391]\t\tLoss: 0.4998 Acc@1: 83.000%\n",
      "| Epoch [ 34/200] Iter [ 26/391]\t\tLoss: 0.2499 Acc@1: 89.000%\n",
      "| Epoch [ 34/200] Iter [ 51/391]\t\tLoss: 0.4557 Acc@1: 89.000%\n",
      "| Epoch [ 34/200] Iter [ 76/391]\t\tLoss: 0.2267 Acc@1: 89.000%\n",
      "| Epoch [ 34/200] Iter [101/391]\t\tLoss: 0.2839 Acc@1: 89.000%\n",
      "| Epoch [ 34/200] Iter [126/391]\t\tLoss: 0.2185 Acc@1: 89.000%\n",
      "| Epoch [ 34/200] Iter [151/391]\t\tLoss: 0.3568 Acc@1: 89.000%\n",
      "| Epoch [ 34/200] Iter [176/391]\t\tLoss: 0.2717 Acc@1: 88.000%\n",
      "| Epoch [ 34/200] Iter [201/391]\t\tLoss: 0.3791 Acc@1: 88.000%\n",
      "| Epoch [ 34/200] Iter [226/391]\t\tLoss: 0.1958 Acc@1: 88.000%\n",
      "| Epoch [ 34/200] Iter [251/391]\t\tLoss: 0.4274 Acc@1: 88.000%\n",
      "| Epoch [ 34/200] Iter [276/391]\t\tLoss: 0.2393 Acc@1: 88.000%\n",
      "| Epoch [ 34/200] Iter [301/391]\t\tLoss: 0.4325 Acc@1: 88.000%\n",
      "| Epoch [ 34/200] Iter [326/391]\t\tLoss: 0.2322 Acc@1: 88.000%\n",
      "| Epoch [ 34/200] Iter [351/391]\t\tLoss: 0.2350 Acc@1: 89.000%\n",
      "| Epoch [ 34/200] Iter [376/391]\t\tLoss: 0.3049 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #34\t\t\tLoss: 0.6314 Acc@1: 82.00%\n",
      "\n",
      "=> Training Epoch #35, LR=0.1000\n",
      "| Epoch [ 35/200] Iter [  1/391]\t\tLoss: 0.2332 Acc@1: 94.000%\n",
      "| Epoch [ 35/200] Iter [ 26/391]\t\tLoss: 0.3222 Acc@1: 90.000%\n",
      "| Epoch [ 35/200] Iter [ 51/391]\t\tLoss: 0.3340 Acc@1: 90.000%\n",
      "| Epoch [ 35/200] Iter [ 76/391]\t\tLoss: 0.3368 Acc@1: 90.000%\n",
      "| Epoch [ 35/200] Iter [101/391]\t\tLoss: 0.3557 Acc@1: 90.000%\n",
      "| Epoch [ 35/200] Iter [126/391]\t\tLoss: 0.3965 Acc@1: 89.000%\n",
      "| Epoch [ 35/200] Iter [151/391]\t\tLoss: 0.4154 Acc@1: 89.000%\n",
      "| Epoch [ 35/200] Iter [176/391]\t\tLoss: 0.3737 Acc@1: 89.000%\n",
      "| Epoch [ 35/200] Iter [201/391]\t\tLoss: 0.2804 Acc@1: 89.000%\n",
      "| Epoch [ 35/200] Iter [226/391]\t\tLoss: 0.2958 Acc@1: 89.000%\n",
      "| Epoch [ 35/200] Iter [251/391]\t\tLoss: 0.3653 Acc@1: 89.000%\n",
      "| Epoch [ 35/200] Iter [276/391]\t\tLoss: 0.3650 Acc@1: 89.000%\n",
      "| Epoch [ 35/200] Iter [301/391]\t\tLoss: 0.2164 Acc@1: 89.000%\n",
      "| Epoch [ 35/200] Iter [326/391]\t\tLoss: 0.3668 Acc@1: 89.000%\n",
      "| Epoch [ 35/200] Iter [351/391]\t\tLoss: 0.2392 Acc@1: 89.000%\n",
      "| Epoch [ 35/200] Iter [376/391]\t\tLoss: 0.2891 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #35\t\t\tLoss: 0.7755 Acc@1: 82.00%\n",
      "\n",
      "=> Training Epoch #36, LR=0.1000\n",
      "| Epoch [ 36/200] Iter [  1/391]\t\tLoss: 0.2854 Acc@1: 89.000%\n",
      "| Epoch [ 36/200] Iter [ 26/391]\t\tLoss: 0.3857 Acc@1: 89.000%\n",
      "| Epoch [ 36/200] Iter [ 51/391]\t\tLoss: 0.3317 Acc@1: 89.000%\n",
      "| Epoch [ 36/200] Iter [ 76/391]\t\tLoss: 0.2894 Acc@1: 89.000%\n",
      "| Epoch [ 36/200] Iter [101/391]\t\tLoss: 0.3618 Acc@1: 89.000%\n",
      "| Epoch [ 36/200] Iter [126/391]\t\tLoss: 0.3175 Acc@1: 89.000%\n",
      "| Epoch [ 36/200] Iter [151/391]\t\tLoss: 0.3072 Acc@1: 89.000%\n",
      "| Epoch [ 36/200] Iter [176/391]\t\tLoss: 0.4390 Acc@1: 89.000%\n",
      "| Epoch [ 36/200] Iter [201/391]\t\tLoss: 0.3127 Acc@1: 89.000%\n",
      "| Epoch [ 36/200] Iter [226/391]\t\tLoss: 0.2526 Acc@1: 89.000%\n",
      "| Epoch [ 36/200] Iter [251/391]\t\tLoss: 0.3644 Acc@1: 88.000%\n",
      "| Epoch [ 36/200] Iter [276/391]\t\tLoss: 0.3158 Acc@1: 88.000%\n",
      "| Epoch [ 36/200] Iter [301/391]\t\tLoss: 0.3720 Acc@1: 88.000%\n",
      "| Epoch [ 36/200] Iter [326/391]\t\tLoss: 0.3114 Acc@1: 88.000%\n",
      "| Epoch [ 36/200] Iter [351/391]\t\tLoss: 0.3005 Acc@1: 88.000%\n",
      "| Epoch [ 36/200] Iter [376/391]\t\tLoss: 0.3571 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #36\t\t\tLoss: 0.4909 Acc@1: 85.00%\n",
      "\n",
      "=> Training Epoch #37, LR=0.1000\n",
      "| Epoch [ 37/200] Iter [  1/391]\t\tLoss: 0.3109 Acc@1: 90.000%\n",
      "| Epoch [ 37/200] Iter [ 26/391]\t\tLoss: 0.3687 Acc@1: 90.000%\n",
      "| Epoch [ 37/200] Iter [ 51/391]\t\tLoss: 0.3177 Acc@1: 90.000%\n",
      "| Epoch [ 37/200] Iter [ 76/391]\t\tLoss: 0.4025 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [101/391]\t\tLoss: 0.4027 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [126/391]\t\tLoss: 0.3004 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [151/391]\t\tLoss: 0.3536 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [176/391]\t\tLoss: 0.2497 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [201/391]\t\tLoss: 0.4168 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [226/391]\t\tLoss: 0.2735 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [251/391]\t\tLoss: 0.3834 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [276/391]\t\tLoss: 0.3706 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [301/391]\t\tLoss: 0.4517 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [326/391]\t\tLoss: 0.2616 Acc@1: 89.000%\n",
      "| Epoch [ 37/200] Iter [351/391]\t\tLoss: 0.2248 Acc@1: 88.000%\n",
      "| Epoch [ 37/200] Iter [376/391]\t\tLoss: 0.3812 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #37\t\t\tLoss: 0.4072 Acc@1: 84.00%\n",
      "\n",
      "=> Training Epoch #38, LR=0.1000\n",
      "| Epoch [ 38/200] Iter [  1/391]\t\tLoss: 0.2736 Acc@1: 87.000%\n",
      "| Epoch [ 38/200] Iter [ 26/391]\t\tLoss: 0.2853 Acc@1: 89.000%\n",
      "| Epoch [ 38/200] Iter [ 51/391]\t\tLoss: 0.3203 Acc@1: 89.000%\n",
      "| Epoch [ 38/200] Iter [ 76/391]\t\tLoss: 0.4409 Acc@1: 89.000%\n",
      "| Epoch [ 38/200] Iter [101/391]\t\tLoss: 0.3898 Acc@1: 89.000%\n",
      "| Epoch [ 38/200] Iter [126/391]\t\tLoss: 0.3368 Acc@1: 89.000%\n",
      "| Epoch [ 38/200] Iter [151/391]\t\tLoss: 0.3154 Acc@1: 88.000%\n",
      "| Epoch [ 38/200] Iter [176/391]\t\tLoss: 0.3101 Acc@1: 88.000%\n",
      "| Epoch [ 38/200] Iter [201/391]\t\tLoss: 0.4053 Acc@1: 88.000%\n",
      "| Epoch [ 38/200] Iter [226/391]\t\tLoss: 0.3025 Acc@1: 88.000%\n",
      "| Epoch [ 38/200] Iter [251/391]\t\tLoss: 0.4103 Acc@1: 88.000%\n",
      "| Epoch [ 38/200] Iter [276/391]\t\tLoss: 0.5169 Acc@1: 88.000%\n",
      "| Epoch [ 38/200] Iter [301/391]\t\tLoss: 0.4154 Acc@1: 88.000%\n",
      "| Epoch [ 38/200] Iter [326/391]\t\tLoss: 0.4116 Acc@1: 88.000%\n",
      "| Epoch [ 38/200] Iter [351/391]\t\tLoss: 0.3883 Acc@1: 88.000%\n",
      "| Epoch [ 38/200] Iter [376/391]\t\tLoss: 0.3395 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #38\t\t\tLoss: 0.5420 Acc@1: 81.00%\n",
      "\n",
      "=> Training Epoch #39, LR=0.1000\n",
      "| Epoch [ 39/200] Iter [  1/391]\t\tLoss: 0.2083 Acc@1: 93.000%\n",
      "| Epoch [ 39/200] Iter [ 26/391]\t\tLoss: 0.2677 Acc@1: 90.000%\n",
      "| Epoch [ 39/200] Iter [ 51/391]\t\tLoss: 0.2932 Acc@1: 90.000%\n",
      "| Epoch [ 39/200] Iter [ 76/391]\t\tLoss: 0.2797 Acc@1: 90.000%\n",
      "| Epoch [ 39/200] Iter [101/391]\t\tLoss: 0.3873 Acc@1: 89.000%\n",
      "| Epoch [ 39/200] Iter [126/391]\t\tLoss: 0.2489 Acc@1: 89.000%\n",
      "| Epoch [ 39/200] Iter [151/391]\t\tLoss: 0.2747 Acc@1: 89.000%\n",
      "| Epoch [ 39/200] Iter [176/391]\t\tLoss: 0.3138 Acc@1: 89.000%\n",
      "| Epoch [ 39/200] Iter [201/391]\t\tLoss: 0.2195 Acc@1: 89.000%\n",
      "| Epoch [ 39/200] Iter [226/391]\t\tLoss: 0.3871 Acc@1: 89.000%\n",
      "| Epoch [ 39/200] Iter [251/391]\t\tLoss: 0.3222 Acc@1: 89.000%\n",
      "| Epoch [ 39/200] Iter [276/391]\t\tLoss: 0.3544 Acc@1: 89.000%\n",
      "| Epoch [ 39/200] Iter [301/391]\t\tLoss: 0.3781 Acc@1: 89.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 39/200] Iter [326/391]\t\tLoss: 0.2984 Acc@1: 89.000%\n",
      "| Epoch [ 39/200] Iter [351/391]\t\tLoss: 0.3553 Acc@1: 88.000%\n",
      "| Epoch [ 39/200] Iter [376/391]\t\tLoss: 0.4395 Acc@1: 88.000%\n",
      "\n",
      "| Validation Epoch #39\t\t\tLoss: 0.4749 Acc@1: 84.00%\n",
      "\n",
      "=> Training Epoch #40, LR=0.1000\n",
      "| Epoch [ 40/200] Iter [  1/391]\t\tLoss: 0.3405 Acc@1: 87.000%\n",
      "| Epoch [ 40/200] Iter [ 26/391]\t\tLoss: 0.2829 Acc@1: 91.000%\n",
      "| Epoch [ 40/200] Iter [ 51/391]\t\tLoss: 0.2439 Acc@1: 90.000%\n",
      "| Epoch [ 40/200] Iter [ 76/391]\t\tLoss: 0.3901 Acc@1: 90.000%\n",
      "| Epoch [ 40/200] Iter [101/391]\t\tLoss: 0.3362 Acc@1: 90.000%\n",
      "| Epoch [ 40/200] Iter [126/391]\t\tLoss: 0.3403 Acc@1: 90.000%\n",
      "| Epoch [ 40/200] Iter [151/391]\t\tLoss: 0.4828 Acc@1: 89.000%\n",
      "| Epoch [ 40/200] Iter [176/391]\t\tLoss: 0.2624 Acc@1: 89.000%\n",
      "| Epoch [ 40/200] Iter [201/391]\t\tLoss: 0.3685 Acc@1: 89.000%\n",
      "| Epoch [ 40/200] Iter [226/391]\t\tLoss: 0.2882 Acc@1: 89.000%\n",
      "| Epoch [ 40/200] Iter [251/391]\t\tLoss: 0.3388 Acc@1: 89.000%\n",
      "| Epoch [ 40/200] Iter [276/391]\t\tLoss: 0.3611 Acc@1: 89.000%\n",
      "| Epoch [ 40/200] Iter [301/391]\t\tLoss: 0.3142 Acc@1: 89.000%\n",
      "| Epoch [ 40/200] Iter [326/391]\t\tLoss: 0.3023 Acc@1: 89.000%\n",
      "| Epoch [ 40/200] Iter [351/391]\t\tLoss: 0.4457 Acc@1: 89.000%\n",
      "| Epoch [ 40/200] Iter [376/391]\t\tLoss: 0.3249 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #40\t\t\tLoss: 0.4975 Acc@1: 80.00%\n",
      "\n",
      "=> Training Epoch #41, LR=0.1000\n",
      "| Epoch [ 41/200] Iter [  1/391]\t\tLoss: 0.2789 Acc@1: 91.000%\n",
      "| Epoch [ 41/200] Iter [ 26/391]\t\tLoss: 0.2920 Acc@1: 91.000%\n",
      "| Epoch [ 41/200] Iter [ 51/391]\t\tLoss: 0.2686 Acc@1: 90.000%\n",
      "| Epoch [ 41/200] Iter [ 76/391]\t\tLoss: 0.2113 Acc@1: 90.000%\n",
      "| Epoch [ 41/200] Iter [101/391]\t\tLoss: 0.3436 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [126/391]\t\tLoss: 0.2468 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [151/391]\t\tLoss: 0.3763 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [176/391]\t\tLoss: 0.2580 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [201/391]\t\tLoss: 0.2677 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [226/391]\t\tLoss: 0.3015 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [251/391]\t\tLoss: 0.2326 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [276/391]\t\tLoss: 0.2531 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [301/391]\t\tLoss: 0.3894 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [326/391]\t\tLoss: 0.3574 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [351/391]\t\tLoss: 0.3612 Acc@1: 89.000%\n",
      "| Epoch [ 41/200] Iter [376/391]\t\tLoss: 0.3584 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #41\t\t\tLoss: 0.2952 Acc@1: 86.00%\n",
      "\n",
      "=> Training Epoch #42, LR=0.1000\n",
      "| Epoch [ 42/200] Iter [  1/391]\t\tLoss: 0.2530 Acc@1: 91.000%\n",
      "| Epoch [ 42/200] Iter [ 26/391]\t\tLoss: 0.3841 Acc@1: 90.000%\n",
      "| Epoch [ 42/200] Iter [ 51/391]\t\tLoss: 0.2307 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [ 76/391]\t\tLoss: 0.2870 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [101/391]\t\tLoss: 0.3981 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [126/391]\t\tLoss: 0.3346 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [151/391]\t\tLoss: 0.4299 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [176/391]\t\tLoss: 0.3646 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [201/391]\t\tLoss: 0.3109 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [226/391]\t\tLoss: 0.4377 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [251/391]\t\tLoss: 0.2992 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [276/391]\t\tLoss: 0.2366 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [301/391]\t\tLoss: 0.2993 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [326/391]\t\tLoss: 0.3601 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [351/391]\t\tLoss: 0.4533 Acc@1: 89.000%\n",
      "| Epoch [ 42/200] Iter [376/391]\t\tLoss: 0.3475 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #42\t\t\tLoss: 0.4983 Acc@1: 86.00%\n",
      "\n",
      "=> Training Epoch #43, LR=0.1000\n",
      "| Epoch [ 43/200] Iter [  1/391]\t\tLoss: 0.2237 Acc@1: 90.000%\n",
      "| Epoch [ 43/200] Iter [ 26/391]\t\tLoss: 0.2860 Acc@1: 91.000%\n",
      "| Epoch [ 43/200] Iter [ 51/391]\t\tLoss: 0.2093 Acc@1: 90.000%\n",
      "| Epoch [ 43/200] Iter [ 76/391]\t\tLoss: 0.2141 Acc@1: 90.000%\n",
      "| Epoch [ 43/200] Iter [101/391]\t\tLoss: 0.2253 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [126/391]\t\tLoss: 0.2561 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [151/391]\t\tLoss: 0.2572 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [176/391]\t\tLoss: 0.4884 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [201/391]\t\tLoss: 0.2520 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [226/391]\t\tLoss: 0.2104 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [251/391]\t\tLoss: 0.2519 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [276/391]\t\tLoss: 0.3962 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [301/391]\t\tLoss: 0.4275 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [326/391]\t\tLoss: 0.2072 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [351/391]\t\tLoss: 0.2693 Acc@1: 89.000%\n",
      "| Epoch [ 43/200] Iter [376/391]\t\tLoss: 0.2669 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #43\t\t\tLoss: 0.3637 Acc@1: 86.00%\n",
      "\n",
      "=> Training Epoch #44, LR=0.1000\n",
      "| Epoch [ 44/200] Iter [  1/391]\t\tLoss: 0.1838 Acc@1: 95.000%\n",
      "| Epoch [ 44/200] Iter [ 26/391]\t\tLoss: 0.2488 Acc@1: 91.000%\n",
      "| Epoch [ 44/200] Iter [ 51/391]\t\tLoss: 0.3069 Acc@1: 90.000%\n",
      "| Epoch [ 44/200] Iter [ 76/391]\t\tLoss: 0.2700 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [101/391]\t\tLoss: 0.3062 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [126/391]\t\tLoss: 0.3726 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [151/391]\t\tLoss: 0.2660 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [176/391]\t\tLoss: 0.3027 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [201/391]\t\tLoss: 0.3014 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [226/391]\t\tLoss: 0.3835 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [251/391]\t\tLoss: 0.2901 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [276/391]\t\tLoss: 0.4056 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [301/391]\t\tLoss: 0.2226 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [326/391]\t\tLoss: 0.2844 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [351/391]\t\tLoss: 0.5137 Acc@1: 89.000%\n",
      "| Epoch [ 44/200] Iter [376/391]\t\tLoss: 0.3351 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #44\t\t\tLoss: 0.2972 Acc@1: 84.00%\n",
      "\n",
      "=> Training Epoch #45, LR=0.1000\n",
      "| Epoch [ 45/200] Iter [  1/391]\t\tLoss: 0.2217 Acc@1: 92.000%\n",
      "| Epoch [ 45/200] Iter [ 26/391]\t\tLoss: 0.2044 Acc@1: 90.000%\n",
      "| Epoch [ 45/200] Iter [ 51/391]\t\tLoss: 0.3378 Acc@1: 90.000%\n",
      "| Epoch [ 45/200] Iter [ 76/391]\t\tLoss: 0.3520 Acc@1: 90.000%\n",
      "| Epoch [ 45/200] Iter [101/391]\t\tLoss: 0.2990 Acc@1: 90.000%\n",
      "| Epoch [ 45/200] Iter [126/391]\t\tLoss: 0.4009 Acc@1: 89.000%\n",
      "| Epoch [ 45/200] Iter [151/391]\t\tLoss: 0.3462 Acc@1: 89.000%\n",
      "| Epoch [ 45/200] Iter [176/391]\t\tLoss: 0.2353 Acc@1: 89.000%\n",
      "| Epoch [ 45/200] Iter [201/391]\t\tLoss: 0.3842 Acc@1: 89.000%\n",
      "| Epoch [ 45/200] Iter [226/391]\t\tLoss: 0.3405 Acc@1: 89.000%\n",
      "| Epoch [ 45/200] Iter [251/391]\t\tLoss: 0.4094 Acc@1: 89.000%\n",
      "| Epoch [ 45/200] Iter [276/391]\t\tLoss: 0.4437 Acc@1: 89.000%\n",
      "| Epoch [ 45/200] Iter [301/391]\t\tLoss: 0.4030 Acc@1: 89.000%\n",
      "| Epoch [ 45/200] Iter [326/391]\t\tLoss: 0.3500 Acc@1: 89.000%\n",
      "| Epoch [ 45/200] Iter [351/391]\t\tLoss: 0.4381 Acc@1: 89.000%\n",
      "| Epoch [ 45/200] Iter [376/391]\t\tLoss: 0.2861 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #45\t\t\tLoss: 0.4208 Acc@1: 80.00%\n",
      "\n",
      "=> Training Epoch #46, LR=0.1000\n",
      "| Epoch [ 46/200] Iter [  1/391]\t\tLoss: 0.3133 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [ 26/391]\t\tLoss: 0.4793 Acc@1: 91.000%\n",
      "| Epoch [ 46/200] Iter [ 51/391]\t\tLoss: 0.3229 Acc@1: 90.000%\n",
      "| Epoch [ 46/200] Iter [ 76/391]\t\tLoss: 0.3916 Acc@1: 90.000%\n",
      "| Epoch [ 46/200] Iter [101/391]\t\tLoss: 0.2775 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [126/391]\t\tLoss: 0.2528 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [151/391]\t\tLoss: 0.2523 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [176/391]\t\tLoss: 0.1937 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [201/391]\t\tLoss: 0.2654 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [226/391]\t\tLoss: 0.1715 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [251/391]\t\tLoss: 0.2481 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [276/391]\t\tLoss: 0.4014 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [301/391]\t\tLoss: 0.2613 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [326/391]\t\tLoss: 0.3398 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [351/391]\t\tLoss: 0.3385 Acc@1: 89.000%\n",
      "| Epoch [ 46/200] Iter [376/391]\t\tLoss: 0.4660 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #46\t\t\tLoss: 0.4041 Acc@1: 85.00%\n",
      "\n",
      "=> Training Epoch #47, LR=0.1000\n",
      "| Epoch [ 47/200] Iter [  1/391]\t\tLoss: 0.2579 Acc@1: 90.000%\n",
      "| Epoch [ 47/200] Iter [ 26/391]\t\tLoss: 0.2967 Acc@1: 90.000%\n",
      "| Epoch [ 47/200] Iter [ 51/391]\t\tLoss: 0.2522 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [ 76/391]\t\tLoss: 0.1613 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [101/391]\t\tLoss: 0.3837 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [126/391]\t\tLoss: 0.2947 Acc@1: 89.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 47/200] Iter [151/391]\t\tLoss: 0.3502 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [176/391]\t\tLoss: 0.3305 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [201/391]\t\tLoss: 0.3763 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [226/391]\t\tLoss: 0.3210 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [251/391]\t\tLoss: 0.4161 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [276/391]\t\tLoss: 0.2459 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [301/391]\t\tLoss: 0.2531 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [326/391]\t\tLoss: 0.2630 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [351/391]\t\tLoss: 0.2691 Acc@1: 89.000%\n",
      "| Epoch [ 47/200] Iter [376/391]\t\tLoss: 0.3005 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #47\t\t\tLoss: 0.3307 Acc@1: 86.00%\n",
      "\n",
      "=> Training Epoch #48, LR=0.1000\n",
      "| Epoch [ 48/200] Iter [  1/391]\t\tLoss: 0.2865 Acc@1: 90.000%\n",
      "| Epoch [ 48/200] Iter [ 26/391]\t\tLoss: 0.2951 Acc@1: 91.000%\n",
      "| Epoch [ 48/200] Iter [ 51/391]\t\tLoss: 0.3449 Acc@1: 91.000%\n",
      "| Epoch [ 48/200] Iter [ 76/391]\t\tLoss: 0.3066 Acc@1: 90.000%\n",
      "| Epoch [ 48/200] Iter [101/391]\t\tLoss: 0.2252 Acc@1: 90.000%\n",
      "| Epoch [ 48/200] Iter [126/391]\t\tLoss: 0.3191 Acc@1: 90.000%\n",
      "| Epoch [ 48/200] Iter [151/391]\t\tLoss: 0.2081 Acc@1: 89.000%\n",
      "| Epoch [ 48/200] Iter [176/391]\t\tLoss: 0.3026 Acc@1: 89.000%\n",
      "| Epoch [ 48/200] Iter [201/391]\t\tLoss: 0.2567 Acc@1: 89.000%\n",
      "| Epoch [ 48/200] Iter [226/391]\t\tLoss: 0.2854 Acc@1: 89.000%\n",
      "| Epoch [ 48/200] Iter [251/391]\t\tLoss: 0.2981 Acc@1: 89.000%\n",
      "| Epoch [ 48/200] Iter [276/391]\t\tLoss: 0.2468 Acc@1: 89.000%\n",
      "| Epoch [ 48/200] Iter [301/391]\t\tLoss: 0.3191 Acc@1: 89.000%\n",
      "| Epoch [ 48/200] Iter [326/391]\t\tLoss: 0.2390 Acc@1: 89.000%\n",
      "| Epoch [ 48/200] Iter [351/391]\t\tLoss: 0.3048 Acc@1: 89.000%\n",
      "| Epoch [ 48/200] Iter [376/391]\t\tLoss: 0.2503 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #48\t\t\tLoss: 0.4102 Acc@1: 86.00%\n",
      "\n",
      "=> Training Epoch #49, LR=0.1000\n",
      "| Epoch [ 49/200] Iter [  1/391]\t\tLoss: 0.2972 Acc@1: 85.000%\n",
      "| Epoch [ 49/200] Iter [ 26/391]\t\tLoss: 0.2916 Acc@1: 91.000%\n",
      "| Epoch [ 49/200] Iter [ 51/391]\t\tLoss: 0.3148 Acc@1: 91.000%\n",
      "| Epoch [ 49/200] Iter [ 76/391]\t\tLoss: 0.3406 Acc@1: 90.000%\n",
      "| Epoch [ 49/200] Iter [101/391]\t\tLoss: 0.2360 Acc@1: 90.000%\n",
      "| Epoch [ 49/200] Iter [126/391]\t\tLoss: 0.2477 Acc@1: 90.000%\n",
      "| Epoch [ 49/200] Iter [151/391]\t\tLoss: 0.4021 Acc@1: 90.000%\n",
      "| Epoch [ 49/200] Iter [176/391]\t\tLoss: 0.3049 Acc@1: 90.000%\n",
      "| Epoch [ 49/200] Iter [201/391]\t\tLoss: 0.3456 Acc@1: 89.000%\n",
      "| Epoch [ 49/200] Iter [226/391]\t\tLoss: 0.3681 Acc@1: 89.000%\n",
      "| Epoch [ 49/200] Iter [251/391]\t\tLoss: 0.3744 Acc@1: 89.000%\n",
      "| Epoch [ 49/200] Iter [276/391]\t\tLoss: 0.3450 Acc@1: 89.000%\n",
      "| Epoch [ 49/200] Iter [301/391]\t\tLoss: 0.1837 Acc@1: 89.000%\n",
      "| Epoch [ 49/200] Iter [326/391]\t\tLoss: 0.4260 Acc@1: 89.000%\n",
      "| Epoch [ 49/200] Iter [351/391]\t\tLoss: 0.3216 Acc@1: 89.000%\n",
      "| Epoch [ 49/200] Iter [376/391]\t\tLoss: 0.4086 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #49\t\t\tLoss: 0.3570 Acc@1: 86.00%\n",
      "\n",
      "=> Training Epoch #50, LR=0.1000\n",
      "| Epoch [ 50/200] Iter [  1/391]\t\tLoss: 0.2462 Acc@1: 92.000%\n",
      "| Epoch [ 50/200] Iter [ 26/391]\t\tLoss: 0.2483 Acc@1: 92.000%\n",
      "| Epoch [ 50/200] Iter [ 51/391]\t\tLoss: 0.2702 Acc@1: 91.000%\n",
      "| Epoch [ 50/200] Iter [ 76/391]\t\tLoss: 0.1895 Acc@1: 90.000%\n",
      "| Epoch [ 50/200] Iter [101/391]\t\tLoss: 0.3520 Acc@1: 90.000%\n",
      "| Epoch [ 50/200] Iter [126/391]\t\tLoss: 0.3275 Acc@1: 89.000%\n",
      "| Epoch [ 50/200] Iter [151/391]\t\tLoss: 0.2482 Acc@1: 89.000%\n",
      "| Epoch [ 50/200] Iter [176/391]\t\tLoss: 0.3126 Acc@1: 89.000%\n",
      "| Epoch [ 50/200] Iter [201/391]\t\tLoss: 0.3080 Acc@1: 89.000%\n",
      "| Epoch [ 50/200] Iter [226/391]\t\tLoss: 0.4378 Acc@1: 89.000%\n",
      "| Epoch [ 50/200] Iter [251/391]\t\tLoss: 0.3652 Acc@1: 89.000%\n",
      "| Epoch [ 50/200] Iter [276/391]\t\tLoss: 0.3060 Acc@1: 89.000%\n",
      "| Epoch [ 50/200] Iter [301/391]\t\tLoss: 0.4446 Acc@1: 89.000%\n",
      "| Epoch [ 50/200] Iter [326/391]\t\tLoss: 0.3307 Acc@1: 89.000%\n",
      "| Epoch [ 50/200] Iter [351/391]\t\tLoss: 0.2930 Acc@1: 89.000%\n",
      "| Epoch [ 50/200] Iter [376/391]\t\tLoss: 0.3278 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #50\t\t\tLoss: 0.4209 Acc@1: 85.00%\n",
      "\n",
      "=> Training Epoch #51, LR=0.1000\n",
      "| Epoch [ 51/200] Iter [  1/391]\t\tLoss: 0.3308 Acc@1: 87.000%\n",
      "| Epoch [ 51/200] Iter [ 26/391]\t\tLoss: 0.2138 Acc@1: 90.000%\n",
      "| Epoch [ 51/200] Iter [ 51/391]\t\tLoss: 0.2448 Acc@1: 91.000%\n",
      "| Epoch [ 51/200] Iter [ 76/391]\t\tLoss: 0.2643 Acc@1: 90.000%\n",
      "| Epoch [ 51/200] Iter [101/391]\t\tLoss: 0.1903 Acc@1: 90.000%\n",
      "| Epoch [ 51/200] Iter [126/391]\t\tLoss: 0.2098 Acc@1: 90.000%\n",
      "| Epoch [ 51/200] Iter [151/391]\t\tLoss: 0.3402 Acc@1: 90.000%\n",
      "| Epoch [ 51/200] Iter [176/391]\t\tLoss: 0.4032 Acc@1: 89.000%\n",
      "| Epoch [ 51/200] Iter [201/391]\t\tLoss: 0.3875 Acc@1: 89.000%\n",
      "| Epoch [ 51/200] Iter [226/391]\t\tLoss: 0.2507 Acc@1: 89.000%\n",
      "| Epoch [ 51/200] Iter [251/391]\t\tLoss: 0.3569 Acc@1: 89.000%\n",
      "| Epoch [ 51/200] Iter [276/391]\t\tLoss: 0.3351 Acc@1: 89.000%\n",
      "| Epoch [ 51/200] Iter [301/391]\t\tLoss: 0.2681 Acc@1: 89.000%\n",
      "| Epoch [ 51/200] Iter [326/391]\t\tLoss: 0.2892 Acc@1: 89.000%\n",
      "| Epoch [ 51/200] Iter [351/391]\t\tLoss: 0.2017 Acc@1: 89.000%\n",
      "| Epoch [ 51/200] Iter [376/391]\t\tLoss: 0.3672 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #51\t\t\tLoss: 0.5921 Acc@1: 82.00%\n",
      "\n",
      "=> Training Epoch #52, LR=0.1000\n",
      "| Epoch [ 52/200] Iter [  1/391]\t\tLoss: 0.3321 Acc@1: 87.000%\n",
      "| Epoch [ 52/200] Iter [ 26/391]\t\tLoss: 0.3374 Acc@1: 90.000%\n",
      "| Epoch [ 52/200] Iter [ 51/391]\t\tLoss: 0.2965 Acc@1: 90.000%\n",
      "| Epoch [ 52/200] Iter [ 76/391]\t\tLoss: 0.3341 Acc@1: 90.000%\n",
      "| Epoch [ 52/200] Iter [101/391]\t\tLoss: 0.4228 Acc@1: 90.000%\n",
      "| Epoch [ 52/200] Iter [126/391]\t\tLoss: 0.3766 Acc@1: 89.000%\n",
      "| Epoch [ 52/200] Iter [151/391]\t\tLoss: 0.1990 Acc@1: 89.000%\n",
      "| Epoch [ 52/200] Iter [176/391]\t\tLoss: 0.3761 Acc@1: 89.000%\n",
      "| Epoch [ 52/200] Iter [201/391]\t\tLoss: 0.3821 Acc@1: 89.000%\n",
      "| Epoch [ 52/200] Iter [226/391]\t\tLoss: 0.5261 Acc@1: 89.000%\n",
      "| Epoch [ 52/200] Iter [251/391]\t\tLoss: 0.3899 Acc@1: 89.000%\n",
      "| Epoch [ 52/200] Iter [276/391]\t\tLoss: 0.3537 Acc@1: 89.000%\n",
      "| Epoch [ 52/200] Iter [301/391]\t\tLoss: 0.3929 Acc@1: 89.000%\n",
      "| Epoch [ 52/200] Iter [326/391]\t\tLoss: 0.3441 Acc@1: 89.000%\n",
      "| Epoch [ 52/200] Iter [351/391]\t\tLoss: 0.2606 Acc@1: 89.000%\n",
      "| Epoch [ 52/200] Iter [376/391]\t\tLoss: 0.3035 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #52\t\t\tLoss: 0.2082 Acc@1: 85.00%\n",
      "\n",
      "=> Training Epoch #53, LR=0.1000\n",
      "| Epoch [ 53/200] Iter [  1/391]\t\tLoss: 0.2266 Acc@1: 89.000%\n",
      "| Epoch [ 53/200] Iter [ 26/391]\t\tLoss: 0.2443 Acc@1: 91.000%\n",
      "| Epoch [ 53/200] Iter [ 51/391]\t\tLoss: 0.3061 Acc@1: 90.000%\n",
      "| Epoch [ 53/200] Iter [ 76/391]\t\tLoss: 0.2535 Acc@1: 90.000%\n",
      "| Epoch [ 53/200] Iter [101/391]\t\tLoss: 0.3057 Acc@1: 90.000%\n",
      "| Epoch [ 53/200] Iter [126/391]\t\tLoss: 0.3743 Acc@1: 90.000%\n",
      "| Epoch [ 53/200] Iter [151/391]\t\tLoss: 0.2556 Acc@1: 90.000%\n",
      "| Epoch [ 53/200] Iter [176/391]\t\tLoss: 0.3092 Acc@1: 90.000%\n",
      "| Epoch [ 53/200] Iter [201/391]\t\tLoss: 0.2126 Acc@1: 89.000%\n",
      "| Epoch [ 53/200] Iter [226/391]\t\tLoss: 0.2279 Acc@1: 89.000%\n",
      "| Epoch [ 53/200] Iter [251/391]\t\tLoss: 0.3755 Acc@1: 89.000%\n",
      "| Epoch [ 53/200] Iter [276/391]\t\tLoss: 0.2496 Acc@1: 89.000%\n",
      "| Epoch [ 53/200] Iter [301/391]\t\tLoss: 0.4092 Acc@1: 89.000%\n",
      "| Epoch [ 53/200] Iter [326/391]\t\tLoss: 0.3020 Acc@1: 89.000%\n",
      "| Epoch [ 53/200] Iter [351/391]\t\tLoss: 0.3022 Acc@1: 89.000%\n",
      "| Epoch [ 53/200] Iter [376/391]\t\tLoss: 0.3187 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #53\t\t\tLoss: 0.3345 Acc@1: 84.00%\n",
      "\n",
      "=> Training Epoch #54, LR=0.1000\n",
      "| Epoch [ 54/200] Iter [  1/391]\t\tLoss: 0.3256 Acc@1: 90.000%\n",
      "| Epoch [ 54/200] Iter [ 26/391]\t\tLoss: 0.2824 Acc@1: 90.000%\n",
      "| Epoch [ 54/200] Iter [ 51/391]\t\tLoss: 0.4733 Acc@1: 90.000%\n",
      "| Epoch [ 54/200] Iter [ 76/391]\t\tLoss: 0.2439 Acc@1: 90.000%\n",
      "| Epoch [ 54/200] Iter [101/391]\t\tLoss: 0.2588 Acc@1: 89.000%\n",
      "| Epoch [ 54/200] Iter [126/391]\t\tLoss: 0.2890 Acc@1: 89.000%\n",
      "| Epoch [ 54/200] Iter [151/391]\t\tLoss: 0.3081 Acc@1: 90.000%\n",
      "| Epoch [ 54/200] Iter [176/391]\t\tLoss: 0.2382 Acc@1: 90.000%\n",
      "| Epoch [ 54/200] Iter [201/391]\t\tLoss: 0.2758 Acc@1: 90.000%\n",
      "| Epoch [ 54/200] Iter [226/391]\t\tLoss: 0.3900 Acc@1: 89.000%\n",
      "| Epoch [ 54/200] Iter [251/391]\t\tLoss: 0.3229 Acc@1: 89.000%\n",
      "| Epoch [ 54/200] Iter [276/391]\t\tLoss: 0.2668 Acc@1: 89.000%\n",
      "| Epoch [ 54/200] Iter [301/391]\t\tLoss: 0.4553 Acc@1: 89.000%\n",
      "| Epoch [ 54/200] Iter [326/391]\t\tLoss: 0.3818 Acc@1: 89.000%\n",
      "| Epoch [ 54/200] Iter [351/391]\t\tLoss: 0.4487 Acc@1: 89.000%\n",
      "| Epoch [ 54/200] Iter [376/391]\t\tLoss: 0.3802 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #54\t\t\tLoss: 0.5475 Acc@1: 83.00%\n",
      "\n",
      "=> Training Epoch #55, LR=0.1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 55/200] Iter [  1/391]\t\tLoss: 0.3493 Acc@1: 85.000%\n",
      "| Epoch [ 55/200] Iter [ 26/391]\t\tLoss: 0.2417 Acc@1: 91.000%\n",
      "| Epoch [ 55/200] Iter [ 51/391]\t\tLoss: 0.3821 Acc@1: 90.000%\n",
      "| Epoch [ 55/200] Iter [ 76/391]\t\tLoss: 0.2324 Acc@1: 90.000%\n",
      "| Epoch [ 55/200] Iter [101/391]\t\tLoss: 0.3231 Acc@1: 90.000%\n",
      "| Epoch [ 55/200] Iter [126/391]\t\tLoss: 0.2813 Acc@1: 89.000%\n",
      "| Epoch [ 55/200] Iter [151/391]\t\tLoss: 0.2603 Acc@1: 89.000%\n",
      "| Epoch [ 55/200] Iter [176/391]\t\tLoss: 0.3309 Acc@1: 89.000%\n",
      "| Epoch [ 55/200] Iter [201/391]\t\tLoss: 0.3153 Acc@1: 89.000%\n",
      "| Epoch [ 55/200] Iter [226/391]\t\tLoss: 0.4373 Acc@1: 89.000%\n",
      "| Epoch [ 55/200] Iter [251/391]\t\tLoss: 0.2539 Acc@1: 89.000%\n",
      "| Epoch [ 55/200] Iter [276/391]\t\tLoss: 0.3384 Acc@1: 89.000%\n",
      "| Epoch [ 55/200] Iter [301/391]\t\tLoss: 0.4022 Acc@1: 89.000%\n",
      "| Epoch [ 55/200] Iter [326/391]\t\tLoss: 0.3470 Acc@1: 89.000%\n",
      "| Epoch [ 55/200] Iter [351/391]\t\tLoss: 0.2129 Acc@1: 89.000%\n",
      "| Epoch [ 55/200] Iter [376/391]\t\tLoss: 0.2515 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #55\t\t\tLoss: 0.6015 Acc@1: 84.00%\n",
      "\n",
      "=> Training Epoch #56, LR=0.1000\n",
      "| Epoch [ 56/200] Iter [  1/391]\t\tLoss: 0.2480 Acc@1: 90.000%\n",
      "| Epoch [ 56/200] Iter [ 26/391]\t\tLoss: 0.2285 Acc@1: 90.000%\n",
      "| Epoch [ 56/200] Iter [ 51/391]\t\tLoss: 0.3219 Acc@1: 90.000%\n",
      "| Epoch [ 56/200] Iter [ 76/391]\t\tLoss: 0.2170 Acc@1: 90.000%\n",
      "| Epoch [ 56/200] Iter [101/391]\t\tLoss: 0.2304 Acc@1: 90.000%\n",
      "| Epoch [ 56/200] Iter [126/391]\t\tLoss: 0.4586 Acc@1: 90.000%\n",
      "| Epoch [ 56/200] Iter [151/391]\t\tLoss: 0.2470 Acc@1: 90.000%\n",
      "| Epoch [ 56/200] Iter [176/391]\t\tLoss: 0.3351 Acc@1: 90.000%\n",
      "| Epoch [ 56/200] Iter [201/391]\t\tLoss: 0.3344 Acc@1: 89.000%\n",
      "| Epoch [ 56/200] Iter [226/391]\t\tLoss: 0.2310 Acc@1: 89.000%\n",
      "| Epoch [ 56/200] Iter [251/391]\t\tLoss: 0.4602 Acc@1: 89.000%\n",
      "| Epoch [ 56/200] Iter [276/391]\t\tLoss: 0.2658 Acc@1: 89.000%\n",
      "| Epoch [ 56/200] Iter [301/391]\t\tLoss: 0.3010 Acc@1: 89.000%\n",
      "| Epoch [ 56/200] Iter [326/391]\t\tLoss: 0.3063 Acc@1: 89.000%\n",
      "| Epoch [ 56/200] Iter [351/391]\t\tLoss: 0.2581 Acc@1: 89.000%\n",
      "| Epoch [ 56/200] Iter [376/391]\t\tLoss: 0.2713 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #56\t\t\tLoss: 0.2732 Acc@1: 85.00%\n",
      "\n",
      "=> Training Epoch #57, LR=0.1000\n",
      "| Epoch [ 57/200] Iter [  1/391]\t\tLoss: 0.2194 Acc@1: 92.000%\n",
      "| Epoch [ 57/200] Iter [ 26/391]\t\tLoss: 0.2828 Acc@1: 90.000%\n",
      "| Epoch [ 57/200] Iter [ 51/391]\t\tLoss: 0.2929 Acc@1: 90.000%\n",
      "| Epoch [ 57/200] Iter [ 76/391]\t\tLoss: 0.3281 Acc@1: 90.000%\n",
      "| Epoch [ 57/200] Iter [101/391]\t\tLoss: 0.2777 Acc@1: 90.000%\n",
      "| Epoch [ 57/200] Iter [126/391]\t\tLoss: 0.3901 Acc@1: 90.000%\n",
      "| Epoch [ 57/200] Iter [151/391]\t\tLoss: 0.3191 Acc@1: 89.000%\n",
      "| Epoch [ 57/200] Iter [176/391]\t\tLoss: 0.2542 Acc@1: 89.000%\n",
      "| Epoch [ 57/200] Iter [201/391]\t\tLoss: 0.3316 Acc@1: 89.000%\n",
      "| Epoch [ 57/200] Iter [226/391]\t\tLoss: 0.4049 Acc@1: 89.000%\n",
      "| Epoch [ 57/200] Iter [251/391]\t\tLoss: 0.3083 Acc@1: 89.000%\n",
      "| Epoch [ 57/200] Iter [276/391]\t\tLoss: 0.2827 Acc@1: 89.000%\n",
      "| Epoch [ 57/200] Iter [301/391]\t\tLoss: 0.2590 Acc@1: 89.000%\n",
      "| Epoch [ 57/200] Iter [326/391]\t\tLoss: 0.4227 Acc@1: 89.000%\n",
      "| Epoch [ 57/200] Iter [351/391]\t\tLoss: 0.2334 Acc@1: 89.000%\n",
      "| Epoch [ 57/200] Iter [376/391]\t\tLoss: 0.3815 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #57\t\t\tLoss: 0.5908 Acc@1: 79.00%\n",
      "\n",
      "=> Training Epoch #58, LR=0.1000\n",
      "| Epoch [ 58/200] Iter [  1/391]\t\tLoss: 0.4979 Acc@1: 83.000%\n",
      "| Epoch [ 58/200] Iter [ 26/391]\t\tLoss: 0.2374 Acc@1: 91.000%\n",
      "| Epoch [ 58/200] Iter [ 51/391]\t\tLoss: 0.3544 Acc@1: 90.000%\n",
      "| Epoch [ 58/200] Iter [ 76/391]\t\tLoss: 0.3955 Acc@1: 90.000%\n",
      "| Epoch [ 58/200] Iter [101/391]\t\tLoss: 0.3319 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [126/391]\t\tLoss: 0.3639 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [151/391]\t\tLoss: 0.4388 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [176/391]\t\tLoss: 0.3106 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [201/391]\t\tLoss: 0.2291 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [226/391]\t\tLoss: 0.2496 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [251/391]\t\tLoss: 0.2995 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [276/391]\t\tLoss: 0.3008 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [301/391]\t\tLoss: 0.2272 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [326/391]\t\tLoss: 0.2233 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [351/391]\t\tLoss: 0.3091 Acc@1: 89.000%\n",
      "| Epoch [ 58/200] Iter [376/391]\t\tLoss: 0.3261 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #58\t\t\tLoss: 0.5608 Acc@1: 81.00%\n",
      "\n",
      "=> Training Epoch #59, LR=0.1000\n",
      "| Epoch [ 59/200] Iter [  1/391]\t\tLoss: 0.4075 Acc@1: 87.000%\n",
      "| Epoch [ 59/200] Iter [ 26/391]\t\tLoss: 0.2611 Acc@1: 91.000%\n",
      "| Epoch [ 59/200] Iter [ 51/391]\t\tLoss: 0.2168 Acc@1: 90.000%\n",
      "| Epoch [ 59/200] Iter [ 76/391]\t\tLoss: 0.2481 Acc@1: 90.000%\n",
      "| Epoch [ 59/200] Iter [101/391]\t\tLoss: 0.2699 Acc@1: 90.000%\n",
      "| Epoch [ 59/200] Iter [126/391]\t\tLoss: 0.5089 Acc@1: 90.000%\n",
      "| Epoch [ 59/200] Iter [151/391]\t\tLoss: 0.2629 Acc@1: 90.000%\n",
      "| Epoch [ 59/200] Iter [176/391]\t\tLoss: 0.2894 Acc@1: 90.000%\n",
      "| Epoch [ 59/200] Iter [201/391]\t\tLoss: 0.2756 Acc@1: 90.000%\n",
      "| Epoch [ 59/200] Iter [226/391]\t\tLoss: 0.3414 Acc@1: 89.000%\n",
      "| Epoch [ 59/200] Iter [251/391]\t\tLoss: 0.3264 Acc@1: 89.000%\n",
      "| Epoch [ 59/200] Iter [276/391]\t\tLoss: 0.2635 Acc@1: 89.000%\n",
      "| Epoch [ 59/200] Iter [301/391]\t\tLoss: 0.2882 Acc@1: 89.000%\n",
      "| Epoch [ 59/200] Iter [326/391]\t\tLoss: 0.3983 Acc@1: 89.000%\n",
      "| Epoch [ 59/200] Iter [351/391]\t\tLoss: 0.3934 Acc@1: 89.000%\n",
      "| Epoch [ 59/200] Iter [376/391]\t\tLoss: 0.2266 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #59\t\t\tLoss: 0.3298 Acc@1: 86.00%\n",
      "\n",
      "=> Training Epoch #60, LR=0.1000\n",
      "| Epoch [ 60/200] Iter [  1/391]\t\tLoss: 0.2338 Acc@1: 91.000%\n",
      "| Epoch [ 60/200] Iter [ 26/391]\t\tLoss: 0.1953 Acc@1: 91.000%\n",
      "| Epoch [ 60/200] Iter [ 51/391]\t\tLoss: 0.3332 Acc@1: 91.000%\n",
      "| Epoch [ 60/200] Iter [ 76/391]\t\tLoss: 0.2656 Acc@1: 91.000%\n",
      "| Epoch [ 60/200] Iter [101/391]\t\tLoss: 0.3762 Acc@1: 90.000%\n",
      "| Epoch [ 60/200] Iter [126/391]\t\tLoss: 0.3120 Acc@1: 90.000%\n",
      "| Epoch [ 60/200] Iter [151/391]\t\tLoss: 0.2019 Acc@1: 90.000%\n",
      "| Epoch [ 60/200] Iter [176/391]\t\tLoss: 0.3428 Acc@1: 90.000%\n",
      "| Epoch [ 60/200] Iter [201/391]\t\tLoss: 0.2039 Acc@1: 90.000%\n",
      "| Epoch [ 60/200] Iter [226/391]\t\tLoss: 0.2444 Acc@1: 90.000%\n",
      "| Epoch [ 60/200] Iter [251/391]\t\tLoss: 0.3222 Acc@1: 90.000%\n",
      "| Epoch [ 60/200] Iter [276/391]\t\tLoss: 0.4541 Acc@1: 90.000%\n",
      "| Epoch [ 60/200] Iter [301/391]\t\tLoss: 0.3876 Acc@1: 89.000%\n",
      "| Epoch [ 60/200] Iter [326/391]\t\tLoss: 0.3354 Acc@1: 89.000%\n",
      "| Epoch [ 60/200] Iter [351/391]\t\tLoss: 0.2268 Acc@1: 89.000%\n",
      "| Epoch [ 60/200] Iter [376/391]\t\tLoss: 0.2760 Acc@1: 89.000%\n",
      "\n",
      "| Validation Epoch #60\t\t\tLoss: 1.1989 Acc@1: 76.00%\n",
      "\n",
      "=> Training Epoch #61, LR=0.0200\n",
      "| Epoch [ 61/200] Iter [  1/391]\t\tLoss: 0.2694 Acc@1: 90.000%\n",
      "| Epoch [ 61/200] Iter [ 26/391]\t\tLoss: 0.1940 Acc@1: 91.000%\n",
      "| Epoch [ 61/200] Iter [ 51/391]\t\tLoss: 0.1957 Acc@1: 92.000%\n",
      "| Epoch [ 61/200] Iter [ 76/391]\t\tLoss: 0.1308 Acc@1: 92.000%\n",
      "| Epoch [ 61/200] Iter [101/391]\t\tLoss: 0.1455 Acc@1: 93.000%\n",
      "| Epoch [ 61/200] Iter [126/391]\t\tLoss: 0.2136 Acc@1: 93.000%\n",
      "| Epoch [ 61/200] Iter [151/391]\t\tLoss: 0.1205 Acc@1: 93.000%\n",
      "| Epoch [ 61/200] Iter [176/391]\t\tLoss: 0.1412 Acc@1: 93.000%\n",
      "| Epoch [ 61/200] Iter [201/391]\t\tLoss: 0.2187 Acc@1: 94.000%\n",
      "| Epoch [ 61/200] Iter [226/391]\t\tLoss: 0.1315 Acc@1: 94.000%\n",
      "| Epoch [ 61/200] Iter [251/391]\t\tLoss: 0.1865 Acc@1: 94.000%\n",
      "| Epoch [ 61/200] Iter [276/391]\t\tLoss: 0.1654 Acc@1: 94.000%\n",
      "| Epoch [ 61/200] Iter [301/391]\t\tLoss: 0.1508 Acc@1: 94.000%\n",
      "| Epoch [ 61/200] Iter [326/391]\t\tLoss: 0.1057 Acc@1: 94.000%\n",
      "| Epoch [ 61/200] Iter [351/391]\t\tLoss: 0.1946 Acc@1: 94.000%\n",
      "| Epoch [ 61/200] Iter [376/391]\t\tLoss: 0.1071 Acc@1: 94.000%\n",
      "\n",
      "| Validation Epoch #61\t\t\tLoss: 0.1699 Acc@1: 93.00%\n",
      "| Saving Best model...\t\t\tTop1 = 93.00%\n",
      "\n",
      "=> Training Epoch #62, LR=0.0200\n",
      "| Epoch [ 62/200] Iter [  1/391]\t\tLoss: 0.1204 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [ 26/391]\t\tLoss: 0.0804 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [ 51/391]\t\tLoss: 0.0496 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [ 76/391]\t\tLoss: 0.0548 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [101/391]\t\tLoss: 0.0759 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [126/391]\t\tLoss: 0.0530 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [151/391]\t\tLoss: 0.0713 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [176/391]\t\tLoss: 0.1139 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [201/391]\t\tLoss: 0.1497 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [226/391]\t\tLoss: 0.0662 Acc@1: 96.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 62/200] Iter [251/391]\t\tLoss: 0.1317 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [276/391]\t\tLoss: 0.1279 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [301/391]\t\tLoss: 0.1528 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [326/391]\t\tLoss: 0.1102 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [351/391]\t\tLoss: 0.1242 Acc@1: 96.000%\n",
      "| Epoch [ 62/200] Iter [376/391]\t\tLoss: 0.1000 Acc@1: 96.000%\n",
      "\n",
      "| Validation Epoch #62\t\t\tLoss: 0.1763 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #63, LR=0.0200\n",
      "| Epoch [ 63/200] Iter [  1/391]\t\tLoss: 0.0835 Acc@1: 97.000%\n",
      "| Epoch [ 63/200] Iter [ 26/391]\t\tLoss: 0.0753 Acc@1: 97.000%\n",
      "| Epoch [ 63/200] Iter [ 51/391]\t\tLoss: 0.0928 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [ 76/391]\t\tLoss: 0.1772 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [101/391]\t\tLoss: 0.0312 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [126/391]\t\tLoss: 0.1173 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [151/391]\t\tLoss: 0.0815 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [176/391]\t\tLoss: 0.1031 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [201/391]\t\tLoss: 0.1563 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [226/391]\t\tLoss: 0.1180 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [251/391]\t\tLoss: 0.1372 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [276/391]\t\tLoss: 0.0683 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [301/391]\t\tLoss: 0.0596 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [326/391]\t\tLoss: 0.0591 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [351/391]\t\tLoss: 0.0839 Acc@1: 96.000%\n",
      "| Epoch [ 63/200] Iter [376/391]\t\tLoss: 0.0941 Acc@1: 96.000%\n",
      "\n",
      "| Validation Epoch #63\t\t\tLoss: 0.1418 Acc@1: 93.00%\n",
      "\n",
      "=> Training Epoch #64, LR=0.0200\n",
      "| Epoch [ 64/200] Iter [  1/391]\t\tLoss: 0.0653 Acc@1: 98.000%\n",
      "| Epoch [ 64/200] Iter [ 26/391]\t\tLoss: 0.0331 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [ 51/391]\t\tLoss: 0.1268 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [ 76/391]\t\tLoss: 0.0743 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [101/391]\t\tLoss: 0.0991 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [126/391]\t\tLoss: 0.0485 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [151/391]\t\tLoss: 0.0966 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [176/391]\t\tLoss: 0.0629 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [201/391]\t\tLoss: 0.1075 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [226/391]\t\tLoss: 0.0990 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [251/391]\t\tLoss: 0.1017 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [276/391]\t\tLoss: 0.0728 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [301/391]\t\tLoss: 0.1022 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [326/391]\t\tLoss: 0.0901 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [351/391]\t\tLoss: 0.1214 Acc@1: 97.000%\n",
      "| Epoch [ 64/200] Iter [376/391]\t\tLoss: 0.0687 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #64\t\t\tLoss: 0.1219 Acc@1: 93.00%\n",
      "\n",
      "=> Training Epoch #65, LR=0.0200\n",
      "| Epoch [ 65/200] Iter [  1/391]\t\tLoss: 0.0625 Acc@1: 98.000%\n",
      "| Epoch [ 65/200] Iter [ 26/391]\t\tLoss: 0.0385 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [ 51/391]\t\tLoss: 0.0573 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [ 76/391]\t\tLoss: 0.1309 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [101/391]\t\tLoss: 0.0891 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [126/391]\t\tLoss: 0.0859 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [151/391]\t\tLoss: 0.0798 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [176/391]\t\tLoss: 0.0952 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [201/391]\t\tLoss: 0.0623 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [226/391]\t\tLoss: 0.0980 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [251/391]\t\tLoss: 0.0869 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [276/391]\t\tLoss: 0.1587 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [301/391]\t\tLoss: 0.0467 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [326/391]\t\tLoss: 0.0945 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [351/391]\t\tLoss: 0.0442 Acc@1: 97.000%\n",
      "| Epoch [ 65/200] Iter [376/391]\t\tLoss: 0.1243 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #65\t\t\tLoss: 0.1537 Acc@1: 93.00%\n",
      "\n",
      "=> Training Epoch #66, LR=0.0200\n",
      "| Epoch [ 66/200] Iter [  1/391]\t\tLoss: 0.0361 Acc@1: 99.000%\n",
      "| Epoch [ 66/200] Iter [ 26/391]\t\tLoss: 0.0435 Acc@1: 98.000%\n",
      "| Epoch [ 66/200] Iter [ 51/391]\t\tLoss: 0.0548 Acc@1: 98.000%\n",
      "| Epoch [ 66/200] Iter [ 76/391]\t\tLoss: 0.0592 Acc@1: 98.000%\n",
      "| Epoch [ 66/200] Iter [101/391]\t\tLoss: 0.0221 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [126/391]\t\tLoss: 0.0615 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [151/391]\t\tLoss: 0.1305 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [176/391]\t\tLoss: 0.0497 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [201/391]\t\tLoss: 0.0994 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [226/391]\t\tLoss: 0.0743 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [251/391]\t\tLoss: 0.0649 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [276/391]\t\tLoss: 0.1183 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [301/391]\t\tLoss: 0.0931 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [326/391]\t\tLoss: 0.0400 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [351/391]\t\tLoss: 0.0590 Acc@1: 97.000%\n",
      "| Epoch [ 66/200] Iter [376/391]\t\tLoss: 0.1208 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #66\t\t\tLoss: 0.1098 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #67, LR=0.0200\n",
      "| Epoch [ 67/200] Iter [  1/391]\t\tLoss: 0.0859 Acc@1: 96.000%\n",
      "| Epoch [ 67/200] Iter [ 26/391]\t\tLoss: 0.1230 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [ 51/391]\t\tLoss: 0.0302 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [ 76/391]\t\tLoss: 0.0958 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [101/391]\t\tLoss: 0.0763 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [126/391]\t\tLoss: 0.0382 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [151/391]\t\tLoss: 0.0528 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [176/391]\t\tLoss: 0.0412 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [201/391]\t\tLoss: 0.0296 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [226/391]\t\tLoss: 0.0893 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [251/391]\t\tLoss: 0.0729 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [276/391]\t\tLoss: 0.0393 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [301/391]\t\tLoss: 0.0500 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [326/391]\t\tLoss: 0.0973 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [351/391]\t\tLoss: 0.0691 Acc@1: 97.000%\n",
      "| Epoch [ 67/200] Iter [376/391]\t\tLoss: 0.0855 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #67\t\t\tLoss: 0.1455 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #68, LR=0.0200\n",
      "| Epoch [ 68/200] Iter [  1/391]\t\tLoss: 0.0863 Acc@1: 96.000%\n",
      "| Epoch [ 68/200] Iter [ 26/391]\t\tLoss: 0.0604 Acc@1: 98.000%\n",
      "| Epoch [ 68/200] Iter [ 51/391]\t\tLoss: 0.0559 Acc@1: 98.000%\n",
      "| Epoch [ 68/200] Iter [ 76/391]\t\tLoss: 0.0428 Acc@1: 98.000%\n",
      "| Epoch [ 68/200] Iter [101/391]\t\tLoss: 0.0290 Acc@1: 98.000%\n",
      "| Epoch [ 68/200] Iter [126/391]\t\tLoss: 0.0743 Acc@1: 98.000%\n",
      "| Epoch [ 68/200] Iter [151/391]\t\tLoss: 0.0677 Acc@1: 97.000%\n",
      "| Epoch [ 68/200] Iter [176/391]\t\tLoss: 0.0518 Acc@1: 97.000%\n",
      "| Epoch [ 68/200] Iter [201/391]\t\tLoss: 0.0473 Acc@1: 97.000%\n",
      "| Epoch [ 68/200] Iter [226/391]\t\tLoss: 0.0281 Acc@1: 97.000%\n",
      "| Epoch [ 68/200] Iter [251/391]\t\tLoss: 0.1525 Acc@1: 97.000%\n",
      "| Epoch [ 68/200] Iter [276/391]\t\tLoss: 0.0686 Acc@1: 97.000%\n",
      "| Epoch [ 68/200] Iter [301/391]\t\tLoss: 0.0661 Acc@1: 97.000%\n",
      "| Epoch [ 68/200] Iter [326/391]\t\tLoss: 0.0561 Acc@1: 97.000%\n",
      "| Epoch [ 68/200] Iter [351/391]\t\tLoss: 0.0401 Acc@1: 97.000%\n",
      "| Epoch [ 68/200] Iter [376/391]\t\tLoss: 0.0498 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #68\t\t\tLoss: 0.1657 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #69, LR=0.0200\n",
      "| Epoch [ 69/200] Iter [  1/391]\t\tLoss: 0.0739 Acc@1: 96.000%\n",
      "| Epoch [ 69/200] Iter [ 26/391]\t\tLoss: 0.0155 Acc@1: 98.000%\n",
      "| Epoch [ 69/200] Iter [ 51/391]\t\tLoss: 0.0748 Acc@1: 98.000%\n",
      "| Epoch [ 69/200] Iter [ 76/391]\t\tLoss: 0.0437 Acc@1: 98.000%\n",
      "| Epoch [ 69/200] Iter [101/391]\t\tLoss: 0.0249 Acc@1: 98.000%\n",
      "| Epoch [ 69/200] Iter [126/391]\t\tLoss: 0.0622 Acc@1: 98.000%\n",
      "| Epoch [ 69/200] Iter [151/391]\t\tLoss: 0.0402 Acc@1: 97.000%\n",
      "| Epoch [ 69/200] Iter [176/391]\t\tLoss: 0.0449 Acc@1: 97.000%\n",
      "| Epoch [ 69/200] Iter [201/391]\t\tLoss: 0.0774 Acc@1: 97.000%\n",
      "| Epoch [ 69/200] Iter [226/391]\t\tLoss: 0.1308 Acc@1: 97.000%\n",
      "| Epoch [ 69/200] Iter [251/391]\t\tLoss: 0.0375 Acc@1: 97.000%\n",
      "| Epoch [ 69/200] Iter [276/391]\t\tLoss: 0.0773 Acc@1: 97.000%\n",
      "| Epoch [ 69/200] Iter [301/391]\t\tLoss: 0.0264 Acc@1: 97.000%\n",
      "| Epoch [ 69/200] Iter [326/391]\t\tLoss: 0.0601 Acc@1: 97.000%\n",
      "| Epoch [ 69/200] Iter [351/391]\t\tLoss: 0.0566 Acc@1: 97.000%\n",
      "| Epoch [ 69/200] Iter [376/391]\t\tLoss: 0.1649 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #69\t\t\tLoss: 0.1499 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #70, LR=0.0200\n",
      "| Epoch [ 70/200] Iter [  1/391]\t\tLoss: 0.0546 Acc@1: 96.000%\n",
      "| Epoch [ 70/200] Iter [ 26/391]\t\tLoss: 0.0769 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [ 51/391]\t\tLoss: 0.0522 Acc@1: 97.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 70/200] Iter [ 76/391]\t\tLoss: 0.0243 Acc@1: 98.000%\n",
      "| Epoch [ 70/200] Iter [101/391]\t\tLoss: 0.0405 Acc@1: 98.000%\n",
      "| Epoch [ 70/200] Iter [126/391]\t\tLoss: 0.0642 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [151/391]\t\tLoss: 0.1217 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [176/391]\t\tLoss: 0.0714 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [201/391]\t\tLoss: 0.0447 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [226/391]\t\tLoss: 0.0785 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [251/391]\t\tLoss: 0.0756 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [276/391]\t\tLoss: 0.0724 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [301/391]\t\tLoss: 0.1465 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [326/391]\t\tLoss: 0.1635 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [351/391]\t\tLoss: 0.0548 Acc@1: 97.000%\n",
      "| Epoch [ 70/200] Iter [376/391]\t\tLoss: 0.0698 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #70\t\t\tLoss: 0.2292 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #71, LR=0.0200\n",
      "| Epoch [ 71/200] Iter [  1/391]\t\tLoss: 0.1293 Acc@1: 96.000%\n",
      "| Epoch [ 71/200] Iter [ 26/391]\t\tLoss: 0.0571 Acc@1: 98.000%\n",
      "| Epoch [ 71/200] Iter [ 51/391]\t\tLoss: 0.0198 Acc@1: 98.000%\n",
      "| Epoch [ 71/200] Iter [ 76/391]\t\tLoss: 0.0386 Acc@1: 98.000%\n",
      "| Epoch [ 71/200] Iter [101/391]\t\tLoss: 0.0837 Acc@1: 98.000%\n",
      "| Epoch [ 71/200] Iter [126/391]\t\tLoss: 0.1042 Acc@1: 98.000%\n",
      "| Epoch [ 71/200] Iter [151/391]\t\tLoss: 0.0418 Acc@1: 97.000%\n",
      "| Epoch [ 71/200] Iter [176/391]\t\tLoss: 0.0721 Acc@1: 97.000%\n",
      "| Epoch [ 71/200] Iter [201/391]\t\tLoss: 0.0841 Acc@1: 97.000%\n",
      "| Epoch [ 71/200] Iter [226/391]\t\tLoss: 0.0797 Acc@1: 97.000%\n",
      "| Epoch [ 71/200] Iter [251/391]\t\tLoss: 0.0430 Acc@1: 97.000%\n",
      "| Epoch [ 71/200] Iter [276/391]\t\tLoss: 0.0812 Acc@1: 97.000%\n",
      "| Epoch [ 71/200] Iter [301/391]\t\tLoss: 0.0997 Acc@1: 97.000%\n",
      "| Epoch [ 71/200] Iter [326/391]\t\tLoss: 0.0461 Acc@1: 97.000%\n",
      "| Epoch [ 71/200] Iter [351/391]\t\tLoss: 0.0788 Acc@1: 97.000%\n",
      "| Epoch [ 71/200] Iter [376/391]\t\tLoss: 0.0632 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #71\t\t\tLoss: 0.2524 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #72, LR=0.0200\n",
      "| Epoch [ 72/200] Iter [  1/391]\t\tLoss: 0.0466 Acc@1: 98.000%\n",
      "| Epoch [ 72/200] Iter [ 26/391]\t\tLoss: 0.0706 Acc@1: 98.000%\n",
      "| Epoch [ 72/200] Iter [ 51/391]\t\tLoss: 0.0464 Acc@1: 98.000%\n",
      "| Epoch [ 72/200] Iter [ 76/391]\t\tLoss: 0.1584 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [101/391]\t\tLoss: 0.0275 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [126/391]\t\tLoss: 0.1285 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [151/391]\t\tLoss: 0.0724 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [176/391]\t\tLoss: 0.0409 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [201/391]\t\tLoss: 0.0574 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [226/391]\t\tLoss: 0.0739 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [251/391]\t\tLoss: 0.0854 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [276/391]\t\tLoss: 0.0978 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [301/391]\t\tLoss: 0.0655 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [326/391]\t\tLoss: 0.1076 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [351/391]\t\tLoss: 0.1123 Acc@1: 97.000%\n",
      "| Epoch [ 72/200] Iter [376/391]\t\tLoss: 0.1080 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #72\t\t\tLoss: 0.0949 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #73, LR=0.0200\n",
      "| Epoch [ 73/200] Iter [  1/391]\t\tLoss: 0.1328 Acc@1: 96.000%\n",
      "| Epoch [ 73/200] Iter [ 26/391]\t\tLoss: 0.0949 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [ 51/391]\t\tLoss: 0.0571 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [ 76/391]\t\tLoss: 0.0742 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [101/391]\t\tLoss: 0.0794 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [126/391]\t\tLoss: 0.0967 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [151/391]\t\tLoss: 0.0616 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [176/391]\t\tLoss: 0.0679 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [201/391]\t\tLoss: 0.1078 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [226/391]\t\tLoss: 0.0932 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [251/391]\t\tLoss: 0.0696 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [276/391]\t\tLoss: 0.0906 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [301/391]\t\tLoss: 0.1201 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [326/391]\t\tLoss: 0.0459 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [351/391]\t\tLoss: 0.1282 Acc@1: 97.000%\n",
      "| Epoch [ 73/200] Iter [376/391]\t\tLoss: 0.0754 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #73\t\t\tLoss: 0.1763 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #74, LR=0.0200\n",
      "| Epoch [ 74/200] Iter [  1/391]\t\tLoss: 0.1048 Acc@1: 96.000%\n",
      "| Epoch [ 74/200] Iter [ 26/391]\t\tLoss: 0.1305 Acc@1: 98.000%\n",
      "| Epoch [ 74/200] Iter [ 51/391]\t\tLoss: 0.0874 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [ 76/391]\t\tLoss: 0.0415 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [101/391]\t\tLoss: 0.0427 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [126/391]\t\tLoss: 0.0332 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [151/391]\t\tLoss: 0.0883 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [176/391]\t\tLoss: 0.1124 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [201/391]\t\tLoss: 0.0716 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [226/391]\t\tLoss: 0.1121 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [251/391]\t\tLoss: 0.0608 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [276/391]\t\tLoss: 0.0680 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [301/391]\t\tLoss: 0.1114 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [326/391]\t\tLoss: 0.1028 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [351/391]\t\tLoss: 0.1093 Acc@1: 97.000%\n",
      "| Epoch [ 74/200] Iter [376/391]\t\tLoss: 0.0716 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #74\t\t\tLoss: 0.1324 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #75, LR=0.0200\n",
      "| Epoch [ 75/200] Iter [  1/391]\t\tLoss: 0.0661 Acc@1: 98.000%\n",
      "| Epoch [ 75/200] Iter [ 26/391]\t\tLoss: 0.0439 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [ 51/391]\t\tLoss: 0.0573 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [ 76/391]\t\tLoss: 0.0975 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [101/391]\t\tLoss: 0.0429 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [126/391]\t\tLoss: 0.0387 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [151/391]\t\tLoss: 0.0655 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [176/391]\t\tLoss: 0.0852 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [201/391]\t\tLoss: 0.0724 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [226/391]\t\tLoss: 0.0591 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [251/391]\t\tLoss: 0.0603 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [276/391]\t\tLoss: 0.0488 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [301/391]\t\tLoss: 0.0780 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [326/391]\t\tLoss: 0.0581 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [351/391]\t\tLoss: 0.1297 Acc@1: 97.000%\n",
      "| Epoch [ 75/200] Iter [376/391]\t\tLoss: 0.0986 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #75\t\t\tLoss: 0.1953 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #76, LR=0.0200\n",
      "| Epoch [ 76/200] Iter [  1/391]\t\tLoss: 0.0357 Acc@1: 99.000%\n",
      "| Epoch [ 76/200] Iter [ 26/391]\t\tLoss: 0.1020 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [ 51/391]\t\tLoss: 0.1238 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [ 76/391]\t\tLoss: 0.0441 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [101/391]\t\tLoss: 0.0624 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [126/391]\t\tLoss: 0.0486 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [151/391]\t\tLoss: 0.0933 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [176/391]\t\tLoss: 0.1045 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [201/391]\t\tLoss: 0.0635 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [226/391]\t\tLoss: 0.1225 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [251/391]\t\tLoss: 0.1083 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [276/391]\t\tLoss: 0.1199 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [301/391]\t\tLoss: 0.1773 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [326/391]\t\tLoss: 0.0718 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [351/391]\t\tLoss: 0.0883 Acc@1: 97.000%\n",
      "| Epoch [ 76/200] Iter [376/391]\t\tLoss: 0.1247 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #76\t\t\tLoss: 0.2479 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #77, LR=0.0200\n",
      "| Epoch [ 77/200] Iter [  1/391]\t\tLoss: 0.0808 Acc@1: 95.000%\n",
      "| Epoch [ 77/200] Iter [ 26/391]\t\tLoss: 0.0618 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [ 51/391]\t\tLoss: 0.0508 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [ 76/391]\t\tLoss: 0.0355 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [101/391]\t\tLoss: 0.0684 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [126/391]\t\tLoss: 0.1154 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [151/391]\t\tLoss: 0.0806 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [176/391]\t\tLoss: 0.0340 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [201/391]\t\tLoss: 0.1538 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [226/391]\t\tLoss: 0.0628 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [251/391]\t\tLoss: 0.1589 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [276/391]\t\tLoss: 0.1767 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [301/391]\t\tLoss: 0.0463 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [326/391]\t\tLoss: 0.0450 Acc@1: 97.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 77/200] Iter [351/391]\t\tLoss: 0.0426 Acc@1: 97.000%\n",
      "| Epoch [ 77/200] Iter [376/391]\t\tLoss: 0.0416 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #77\t\t\tLoss: 0.2119 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #78, LR=0.0200\n",
      "| Epoch [ 78/200] Iter [  1/391]\t\tLoss: 0.0879 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [ 26/391]\t\tLoss: 0.0563 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [ 51/391]\t\tLoss: 0.0485 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [ 76/391]\t\tLoss: 0.0187 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [101/391]\t\tLoss: 0.0557 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [126/391]\t\tLoss: 0.0470 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [151/391]\t\tLoss: 0.0962 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [176/391]\t\tLoss: 0.1456 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [201/391]\t\tLoss: 0.0640 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [226/391]\t\tLoss: 0.0810 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [251/391]\t\tLoss: 0.1139 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [276/391]\t\tLoss: 0.0603 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [301/391]\t\tLoss: 0.0456 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [326/391]\t\tLoss: 0.0876 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [351/391]\t\tLoss: 0.1925 Acc@1: 97.000%\n",
      "| Epoch [ 78/200] Iter [376/391]\t\tLoss: 0.0312 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #78\t\t\tLoss: 0.3073 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #79, LR=0.0200\n",
      "| Epoch [ 79/200] Iter [  1/391]\t\tLoss: 0.0623 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [ 26/391]\t\tLoss: 0.0650 Acc@1: 98.000%\n",
      "| Epoch [ 79/200] Iter [ 51/391]\t\tLoss: 0.0475 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [ 76/391]\t\tLoss: 0.1029 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [101/391]\t\tLoss: 0.0726 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [126/391]\t\tLoss: 0.0565 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [151/391]\t\tLoss: 0.0434 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [176/391]\t\tLoss: 0.1014 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [201/391]\t\tLoss: 0.0600 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [226/391]\t\tLoss: 0.0489 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [251/391]\t\tLoss: 0.1508 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [276/391]\t\tLoss: 0.0515 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [301/391]\t\tLoss: 0.0494 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [326/391]\t\tLoss: 0.0680 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [351/391]\t\tLoss: 0.0780 Acc@1: 97.000%\n",
      "| Epoch [ 79/200] Iter [376/391]\t\tLoss: 0.1440 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #79\t\t\tLoss: 0.1523 Acc@1: 90.00%\n",
      "\n",
      "=> Training Epoch #80, LR=0.0200\n",
      "| Epoch [ 80/200] Iter [  1/391]\t\tLoss: 0.0741 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [ 26/391]\t\tLoss: 0.0502 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [ 51/391]\t\tLoss: 0.1597 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [ 76/391]\t\tLoss: 0.0646 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [101/391]\t\tLoss: 0.0660 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [126/391]\t\tLoss: 0.0805 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [151/391]\t\tLoss: 0.1121 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [176/391]\t\tLoss: 0.1065 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [201/391]\t\tLoss: 0.1157 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [226/391]\t\tLoss: 0.0436 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [251/391]\t\tLoss: 0.1248 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [276/391]\t\tLoss: 0.0782 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [301/391]\t\tLoss: 0.0768 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [326/391]\t\tLoss: 0.1259 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [351/391]\t\tLoss: 0.1211 Acc@1: 97.000%\n",
      "| Epoch [ 80/200] Iter [376/391]\t\tLoss: 0.0508 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #80\t\t\tLoss: 0.1148 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #81, LR=0.0200\n",
      "| Epoch [ 81/200] Iter [  1/391]\t\tLoss: 0.0728 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [ 26/391]\t\tLoss: 0.0833 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [ 51/391]\t\tLoss: 0.0845 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [ 76/391]\t\tLoss: 0.1094 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [101/391]\t\tLoss: 0.0587 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [126/391]\t\tLoss: 0.0431 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [151/391]\t\tLoss: 0.1016 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [176/391]\t\tLoss: 0.0485 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [201/391]\t\tLoss: 0.0579 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [226/391]\t\tLoss: 0.0859 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [251/391]\t\tLoss: 0.0474 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [276/391]\t\tLoss: 0.0961 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [301/391]\t\tLoss: 0.0628 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [326/391]\t\tLoss: 0.1503 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [351/391]\t\tLoss: 0.0606 Acc@1: 97.000%\n",
      "| Epoch [ 81/200] Iter [376/391]\t\tLoss: 0.1142 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #81\t\t\tLoss: 0.1824 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #82, LR=0.0200\n",
      "| Epoch [ 82/200] Iter [  1/391]\t\tLoss: 0.0852 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [ 26/391]\t\tLoss: 0.0625 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [ 51/391]\t\tLoss: 0.0655 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [ 76/391]\t\tLoss: 0.1351 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [101/391]\t\tLoss: 0.0468 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [126/391]\t\tLoss: 0.0398 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [151/391]\t\tLoss: 0.1350 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [176/391]\t\tLoss: 0.1198 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [201/391]\t\tLoss: 0.0776 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [226/391]\t\tLoss: 0.1524 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [251/391]\t\tLoss: 0.0916 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [276/391]\t\tLoss: 0.0892 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [301/391]\t\tLoss: 0.0662 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [326/391]\t\tLoss: 0.1096 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [351/391]\t\tLoss: 0.0849 Acc@1: 97.000%\n",
      "| Epoch [ 82/200] Iter [376/391]\t\tLoss: 0.0821 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #82\t\t\tLoss: 0.0970 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #83, LR=0.0200\n",
      "| Epoch [ 83/200] Iter [  1/391]\t\tLoss: 0.1325 Acc@1: 93.000%\n",
      "| Epoch [ 83/200] Iter [ 26/391]\t\tLoss: 0.0913 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [ 51/391]\t\tLoss: 0.0416 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [ 76/391]\t\tLoss: 0.0395 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [101/391]\t\tLoss: 0.0972 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [126/391]\t\tLoss: 0.0859 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [151/391]\t\tLoss: 0.0852 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [176/391]\t\tLoss: 0.1288 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [201/391]\t\tLoss: 0.0947 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [226/391]\t\tLoss: 0.0890 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [251/391]\t\tLoss: 0.1275 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [276/391]\t\tLoss: 0.0628 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [301/391]\t\tLoss: 0.1906 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [326/391]\t\tLoss: 0.0522 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [351/391]\t\tLoss: 0.0600 Acc@1: 97.000%\n",
      "| Epoch [ 83/200] Iter [376/391]\t\tLoss: 0.0692 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #83\t\t\tLoss: 0.1296 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #84, LR=0.0200\n",
      "| Epoch [ 84/200] Iter [  1/391]\t\tLoss: 0.0642 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [ 26/391]\t\tLoss: 0.0836 Acc@1: 98.000%\n",
      "| Epoch [ 84/200] Iter [ 51/391]\t\tLoss: 0.0851 Acc@1: 98.000%\n",
      "| Epoch [ 84/200] Iter [ 76/391]\t\tLoss: 0.0776 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [101/391]\t\tLoss: 0.1489 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [126/391]\t\tLoss: 0.0555 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [151/391]\t\tLoss: 0.0356 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [176/391]\t\tLoss: 0.0700 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [201/391]\t\tLoss: 0.1434 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [226/391]\t\tLoss: 0.0331 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [251/391]\t\tLoss: 0.0622 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [276/391]\t\tLoss: 0.0834 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [301/391]\t\tLoss: 0.0821 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [326/391]\t\tLoss: 0.0511 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [351/391]\t\tLoss: 0.0757 Acc@1: 97.000%\n",
      "| Epoch [ 84/200] Iter [376/391]\t\tLoss: 0.0564 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #84\t\t\tLoss: 0.1236 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #85, LR=0.0200\n",
      "| Epoch [ 85/200] Iter [  1/391]\t\tLoss: 0.0789 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [ 26/391]\t\tLoss: 0.0566 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [ 51/391]\t\tLoss: 0.0810 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [ 76/391]\t\tLoss: 0.1026 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [101/391]\t\tLoss: 0.0805 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [126/391]\t\tLoss: 0.0643 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [151/391]\t\tLoss: 0.1070 Acc@1: 97.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 85/200] Iter [176/391]\t\tLoss: 0.0756 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [201/391]\t\tLoss: 0.0844 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [226/391]\t\tLoss: 0.1583 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [251/391]\t\tLoss: 0.0743 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [276/391]\t\tLoss: 0.0937 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [301/391]\t\tLoss: 0.0627 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [326/391]\t\tLoss: 0.0604 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [351/391]\t\tLoss: 0.0575 Acc@1: 97.000%\n",
      "| Epoch [ 85/200] Iter [376/391]\t\tLoss: 0.1284 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #85\t\t\tLoss: 0.1824 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #86, LR=0.0200\n",
      "| Epoch [ 86/200] Iter [  1/391]\t\tLoss: 0.0898 Acc@1: 96.000%\n",
      "| Epoch [ 86/200] Iter [ 26/391]\t\tLoss: 0.0284 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [ 51/391]\t\tLoss: 0.0741 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [ 76/391]\t\tLoss: 0.0579 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [101/391]\t\tLoss: 0.0804 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [126/391]\t\tLoss: 0.0537 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [151/391]\t\tLoss: 0.0426 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [176/391]\t\tLoss: 0.0713 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [201/391]\t\tLoss: 0.1396 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [226/391]\t\tLoss: 0.0984 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [251/391]\t\tLoss: 0.1021 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [276/391]\t\tLoss: 0.0763 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [301/391]\t\tLoss: 0.0413 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [326/391]\t\tLoss: 0.1298 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [351/391]\t\tLoss: 0.0538 Acc@1: 97.000%\n",
      "| Epoch [ 86/200] Iter [376/391]\t\tLoss: 0.1548 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #86\t\t\tLoss: 0.2153 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #87, LR=0.0200\n",
      "| Epoch [ 87/200] Iter [  1/391]\t\tLoss: 0.0753 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [ 26/391]\t\tLoss: 0.0313 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [ 51/391]\t\tLoss: 0.0317 Acc@1: 98.000%\n",
      "| Epoch [ 87/200] Iter [ 76/391]\t\tLoss: 0.0400 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [101/391]\t\tLoss: 0.0639 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [126/391]\t\tLoss: 0.0652 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [151/391]\t\tLoss: 0.0705 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [176/391]\t\tLoss: 0.1252 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [201/391]\t\tLoss: 0.0425 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [226/391]\t\tLoss: 0.1076 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [251/391]\t\tLoss: 0.0890 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [276/391]\t\tLoss: 0.0729 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [301/391]\t\tLoss: 0.0599 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [326/391]\t\tLoss: 0.0925 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [351/391]\t\tLoss: 0.1396 Acc@1: 97.000%\n",
      "| Epoch [ 87/200] Iter [376/391]\t\tLoss: 0.0474 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #87\t\t\tLoss: 0.1400 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #88, LR=0.0200\n",
      "| Epoch [ 88/200] Iter [  1/391]\t\tLoss: 0.0614 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [ 26/391]\t\tLoss: 0.0502 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [ 51/391]\t\tLoss: 0.0568 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [ 76/391]\t\tLoss: 0.0794 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [101/391]\t\tLoss: 0.0809 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [126/391]\t\tLoss: 0.0726 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [151/391]\t\tLoss: 0.0848 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [176/391]\t\tLoss: 0.1041 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [201/391]\t\tLoss: 0.0458 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [226/391]\t\tLoss: 0.1118 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [251/391]\t\tLoss: 0.0759 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [276/391]\t\tLoss: 0.0549 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [301/391]\t\tLoss: 0.0940 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [326/391]\t\tLoss: 0.0849 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [351/391]\t\tLoss: 0.1823 Acc@1: 97.000%\n",
      "| Epoch [ 88/200] Iter [376/391]\t\tLoss: 0.0947 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #88\t\t\tLoss: 0.1857 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #89, LR=0.0200\n",
      "| Epoch [ 89/200] Iter [  1/391]\t\tLoss: 0.0352 Acc@1: 99.000%\n",
      "| Epoch [ 89/200] Iter [ 26/391]\t\tLoss: 0.0299 Acc@1: 98.000%\n",
      "| Epoch [ 89/200] Iter [ 51/391]\t\tLoss: 0.0550 Acc@1: 98.000%\n",
      "| Epoch [ 89/200] Iter [ 76/391]\t\tLoss: 0.0538 Acc@1: 98.000%\n",
      "| Epoch [ 89/200] Iter [101/391]\t\tLoss: 0.0479 Acc@1: 98.000%\n",
      "| Epoch [ 89/200] Iter [126/391]\t\tLoss: 0.0660 Acc@1: 98.000%\n",
      "| Epoch [ 89/200] Iter [151/391]\t\tLoss: 0.0666 Acc@1: 98.000%\n",
      "| Epoch [ 89/200] Iter [176/391]\t\tLoss: 0.2027 Acc@1: 97.000%\n",
      "| Epoch [ 89/200] Iter [201/391]\t\tLoss: 0.1853 Acc@1: 97.000%\n",
      "| Epoch [ 89/200] Iter [226/391]\t\tLoss: 0.0816 Acc@1: 97.000%\n",
      "| Epoch [ 89/200] Iter [251/391]\t\tLoss: 0.0530 Acc@1: 97.000%\n",
      "| Epoch [ 89/200] Iter [276/391]\t\tLoss: 0.0688 Acc@1: 97.000%\n",
      "| Epoch [ 89/200] Iter [301/391]\t\tLoss: 0.0918 Acc@1: 97.000%\n",
      "| Epoch [ 89/200] Iter [326/391]\t\tLoss: 0.0410 Acc@1: 97.000%\n",
      "| Epoch [ 89/200] Iter [351/391]\t\tLoss: 0.0398 Acc@1: 97.000%\n",
      "| Epoch [ 89/200] Iter [376/391]\t\tLoss: 0.0318 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #89\t\t\tLoss: 0.2370 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #90, LR=0.0200\n",
      "| Epoch [ 90/200] Iter [  1/391]\t\tLoss: 0.0479 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [ 26/391]\t\tLoss: 0.0344 Acc@1: 98.000%\n",
      "| Epoch [ 90/200] Iter [ 51/391]\t\tLoss: 0.0684 Acc@1: 98.000%\n",
      "| Epoch [ 90/200] Iter [ 76/391]\t\tLoss: 0.0969 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [101/391]\t\tLoss: 0.0367 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [126/391]\t\tLoss: 0.0714 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [151/391]\t\tLoss: 0.0917 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [176/391]\t\tLoss: 0.0645 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [201/391]\t\tLoss: 0.0766 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [226/391]\t\tLoss: 0.1443 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [251/391]\t\tLoss: 0.1025 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [276/391]\t\tLoss: 0.0814 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [301/391]\t\tLoss: 0.0774 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [326/391]\t\tLoss: 0.0956 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [351/391]\t\tLoss: 0.0789 Acc@1: 97.000%\n",
      "| Epoch [ 90/200] Iter [376/391]\t\tLoss: 0.0844 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #90\t\t\tLoss: 0.1807 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #91, LR=0.0200\n",
      "| Epoch [ 91/200] Iter [  1/391]\t\tLoss: 0.0327 Acc@1: 98.000%\n",
      "| Epoch [ 91/200] Iter [ 26/391]\t\tLoss: 0.0274 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [ 51/391]\t\tLoss: 0.0244 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [ 76/391]\t\tLoss: 0.0196 Acc@1: 98.000%\n",
      "| Epoch [ 91/200] Iter [101/391]\t\tLoss: 0.0663 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [126/391]\t\tLoss: 0.0614 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [151/391]\t\tLoss: 0.0983 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [176/391]\t\tLoss: 0.0808 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [201/391]\t\tLoss: 0.0927 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [226/391]\t\tLoss: 0.0662 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [251/391]\t\tLoss: 0.0417 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [276/391]\t\tLoss: 0.0917 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [301/391]\t\tLoss: 0.0556 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [326/391]\t\tLoss: 0.1037 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [351/391]\t\tLoss: 0.0996 Acc@1: 97.000%\n",
      "| Epoch [ 91/200] Iter [376/391]\t\tLoss: 0.0593 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #91\t\t\tLoss: 0.1760 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #92, LR=0.0200\n",
      "| Epoch [ 92/200] Iter [  1/391]\t\tLoss: 0.0837 Acc@1: 98.000%\n",
      "| Epoch [ 92/200] Iter [ 26/391]\t\tLoss: 0.0662 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [ 51/391]\t\tLoss: 0.0892 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [ 76/391]\t\tLoss: 0.0899 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [101/391]\t\tLoss: 0.0582 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [126/391]\t\tLoss: 0.0823 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [151/391]\t\tLoss: 0.0507 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [176/391]\t\tLoss: 0.0695 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [201/391]\t\tLoss: 0.0624 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [226/391]\t\tLoss: 0.0649 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [251/391]\t\tLoss: 0.0884 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [276/391]\t\tLoss: 0.1363 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [301/391]\t\tLoss: 0.1798 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [326/391]\t\tLoss: 0.0827 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [351/391]\t\tLoss: 0.0948 Acc@1: 97.000%\n",
      "| Epoch [ 92/200] Iter [376/391]\t\tLoss: 0.0824 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #92\t\t\tLoss: 0.3265 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #93, LR=0.0200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [ 93/200] Iter [  1/391]\t\tLoss: 0.0870 Acc@1: 98.000%\n",
      "| Epoch [ 93/200] Iter [ 26/391]\t\tLoss: 0.0826 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [ 51/391]\t\tLoss: 0.0536 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [ 76/391]\t\tLoss: 0.0599 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [101/391]\t\tLoss: 0.0907 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [126/391]\t\tLoss: 0.1214 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [151/391]\t\tLoss: 0.0558 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [176/391]\t\tLoss: 0.0514 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [201/391]\t\tLoss: 0.0794 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [226/391]\t\tLoss: 0.0891 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [251/391]\t\tLoss: 0.0882 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [276/391]\t\tLoss: 0.0592 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [301/391]\t\tLoss: 0.0414 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [326/391]\t\tLoss: 0.1004 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [351/391]\t\tLoss: 0.0829 Acc@1: 97.000%\n",
      "| Epoch [ 93/200] Iter [376/391]\t\tLoss: 0.0512 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #93\t\t\tLoss: 0.2562 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #94, LR=0.0200\n",
      "| Epoch [ 94/200] Iter [  1/391]\t\tLoss: 0.0680 Acc@1: 98.000%\n",
      "| Epoch [ 94/200] Iter [ 26/391]\t\tLoss: 0.0331 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [ 51/391]\t\tLoss: 0.0313 Acc@1: 98.000%\n",
      "| Epoch [ 94/200] Iter [ 76/391]\t\tLoss: 0.0616 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [101/391]\t\tLoss: 0.0685 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [126/391]\t\tLoss: 0.0590 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [151/391]\t\tLoss: 0.0990 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [176/391]\t\tLoss: 0.0542 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [201/391]\t\tLoss: 0.0377 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [226/391]\t\tLoss: 0.2741 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [251/391]\t\tLoss: 0.0635 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [276/391]\t\tLoss: 0.1128 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [301/391]\t\tLoss: 0.0370 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [326/391]\t\tLoss: 0.0838 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [351/391]\t\tLoss: 0.0839 Acc@1: 97.000%\n",
      "| Epoch [ 94/200] Iter [376/391]\t\tLoss: 0.0252 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #94\t\t\tLoss: 0.4709 Acc@1: 90.00%\n",
      "\n",
      "=> Training Epoch #95, LR=0.0200\n",
      "| Epoch [ 95/200] Iter [  1/391]\t\tLoss: 0.1296 Acc@1: 94.000%\n",
      "| Epoch [ 95/200] Iter [ 26/391]\t\tLoss: 0.1066 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [ 51/391]\t\tLoss: 0.0444 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [ 76/391]\t\tLoss: 0.0881 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [101/391]\t\tLoss: 0.0796 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [126/391]\t\tLoss: 0.0652 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [151/391]\t\tLoss: 0.0840 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [176/391]\t\tLoss: 0.0424 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [201/391]\t\tLoss: 0.0631 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [226/391]\t\tLoss: 0.0947 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [251/391]\t\tLoss: 0.1306 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [276/391]\t\tLoss: 0.0751 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [301/391]\t\tLoss: 0.1349 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [326/391]\t\tLoss: 0.0860 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [351/391]\t\tLoss: 0.0435 Acc@1: 97.000%\n",
      "| Epoch [ 95/200] Iter [376/391]\t\tLoss: 0.0616 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #95\t\t\tLoss: 0.1908 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #96, LR=0.0200\n",
      "| Epoch [ 96/200] Iter [  1/391]\t\tLoss: 0.0656 Acc@1: 97.000%\n",
      "| Epoch [ 96/200] Iter [ 26/391]\t\tLoss: 0.0790 Acc@1: 98.000%\n",
      "| Epoch [ 96/200] Iter [ 51/391]\t\tLoss: 0.0459 Acc@1: 98.000%\n",
      "| Epoch [ 96/200] Iter [ 76/391]\t\tLoss: 0.1210 Acc@1: 98.000%\n",
      "| Epoch [ 96/200] Iter [101/391]\t\tLoss: 0.0886 Acc@1: 98.000%\n",
      "| Epoch [ 96/200] Iter [126/391]\t\tLoss: 0.0615 Acc@1: 98.000%\n",
      "| Epoch [ 96/200] Iter [151/391]\t\tLoss: 0.0466 Acc@1: 97.000%\n",
      "| Epoch [ 96/200] Iter [176/391]\t\tLoss: 0.1485 Acc@1: 97.000%\n",
      "| Epoch [ 96/200] Iter [201/391]\t\tLoss: 0.0900 Acc@1: 97.000%\n",
      "| Epoch [ 96/200] Iter [226/391]\t\tLoss: 0.0971 Acc@1: 97.000%\n",
      "| Epoch [ 96/200] Iter [251/391]\t\tLoss: 0.0790 Acc@1: 97.000%\n",
      "| Epoch [ 96/200] Iter [276/391]\t\tLoss: 0.0758 Acc@1: 97.000%\n",
      "| Epoch [ 96/200] Iter [301/391]\t\tLoss: 0.0792 Acc@1: 97.000%\n",
      "| Epoch [ 96/200] Iter [326/391]\t\tLoss: 0.0491 Acc@1: 97.000%\n",
      "| Epoch [ 96/200] Iter [351/391]\t\tLoss: 0.0772 Acc@1: 97.000%\n",
      "| Epoch [ 96/200] Iter [376/391]\t\tLoss: 0.0893 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #96\t\t\tLoss: 0.1306 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #97, LR=0.0200\n",
      "| Epoch [ 97/200] Iter [  1/391]\t\tLoss: 0.0593 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [ 26/391]\t\tLoss: 0.0349 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [ 51/391]\t\tLoss: 0.0301 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [ 76/391]\t\tLoss: 0.1172 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [101/391]\t\tLoss: 0.1186 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [126/391]\t\tLoss: 0.0513 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [151/391]\t\tLoss: 0.0646 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [176/391]\t\tLoss: 0.0957 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [201/391]\t\tLoss: 0.1288 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [226/391]\t\tLoss: 0.0271 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [251/391]\t\tLoss: 0.1445 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [276/391]\t\tLoss: 0.1063 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [301/391]\t\tLoss: 0.0955 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [326/391]\t\tLoss: 0.1417 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [351/391]\t\tLoss: 0.0842 Acc@1: 97.000%\n",
      "| Epoch [ 97/200] Iter [376/391]\t\tLoss: 0.1054 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #97\t\t\tLoss: 0.3211 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #98, LR=0.0200\n",
      "| Epoch [ 98/200] Iter [  1/391]\t\tLoss: 0.0893 Acc@1: 96.000%\n",
      "| Epoch [ 98/200] Iter [ 26/391]\t\tLoss: 0.0455 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [ 51/391]\t\tLoss: 0.0844 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [ 76/391]\t\tLoss: 0.0639 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [101/391]\t\tLoss: 0.0976 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [126/391]\t\tLoss: 0.0645 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [151/391]\t\tLoss: 0.1190 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [176/391]\t\tLoss: 0.0692 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [201/391]\t\tLoss: 0.1151 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [226/391]\t\tLoss: 0.0986 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [251/391]\t\tLoss: 0.1303 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [276/391]\t\tLoss: 0.0983 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [301/391]\t\tLoss: 0.0945 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [326/391]\t\tLoss: 0.1659 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [351/391]\t\tLoss: 0.0388 Acc@1: 97.000%\n",
      "| Epoch [ 98/200] Iter [376/391]\t\tLoss: 0.1175 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #98\t\t\tLoss: 0.1928 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #99, LR=0.0200\n",
      "| Epoch [ 99/200] Iter [  1/391]\t\tLoss: 0.1221 Acc@1: 94.000%\n",
      "| Epoch [ 99/200] Iter [ 26/391]\t\tLoss: 0.0493 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [ 51/391]\t\tLoss: 0.0833 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [ 76/391]\t\tLoss: 0.0167 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [101/391]\t\tLoss: 0.0885 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [126/391]\t\tLoss: 0.0483 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [151/391]\t\tLoss: 0.0784 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [176/391]\t\tLoss: 0.1256 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [201/391]\t\tLoss: 0.0285 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [226/391]\t\tLoss: 0.0723 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [251/391]\t\tLoss: 0.0501 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [276/391]\t\tLoss: 0.0367 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [301/391]\t\tLoss: 0.0938 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [326/391]\t\tLoss: 0.1354 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [351/391]\t\tLoss: 0.0340 Acc@1: 97.000%\n",
      "| Epoch [ 99/200] Iter [376/391]\t\tLoss: 0.0429 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #99\t\t\tLoss: 0.2111 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #100, LR=0.0200\n",
      "| Epoch [100/200] Iter [  1/391]\t\tLoss: 0.0548 Acc@1: 98.000%\n",
      "| Epoch [100/200] Iter [ 26/391]\t\tLoss: 0.0740 Acc@1: 98.000%\n",
      "| Epoch [100/200] Iter [ 51/391]\t\tLoss: 0.0974 Acc@1: 98.000%\n",
      "| Epoch [100/200] Iter [ 76/391]\t\tLoss: 0.1430 Acc@1: 98.000%\n",
      "| Epoch [100/200] Iter [101/391]\t\tLoss: 0.1254 Acc@1: 97.000%\n",
      "| Epoch [100/200] Iter [126/391]\t\tLoss: 0.0471 Acc@1: 97.000%\n",
      "| Epoch [100/200] Iter [151/391]\t\tLoss: 0.1551 Acc@1: 97.000%\n",
      "| Epoch [100/200] Iter [176/391]\t\tLoss: 0.1116 Acc@1: 97.000%\n",
      "| Epoch [100/200] Iter [201/391]\t\tLoss: 0.1165 Acc@1: 97.000%\n",
      "| Epoch [100/200] Iter [226/391]\t\tLoss: 0.1205 Acc@1: 97.000%\n",
      "| Epoch [100/200] Iter [251/391]\t\tLoss: 0.1643 Acc@1: 97.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [100/200] Iter [276/391]\t\tLoss: 0.1020 Acc@1: 97.000%\n",
      "| Epoch [100/200] Iter [301/391]\t\tLoss: 0.1070 Acc@1: 97.000%\n",
      "| Epoch [100/200] Iter [326/391]\t\tLoss: 0.0895 Acc@1: 97.000%\n",
      "| Epoch [100/200] Iter [351/391]\t\tLoss: 0.0814 Acc@1: 97.000%\n",
      "| Epoch [100/200] Iter [376/391]\t\tLoss: 0.1102 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #100\t\t\tLoss: 0.1808 Acc@1: 90.00%\n",
      "\n",
      "=> Training Epoch #101, LR=0.0200\n",
      "| Epoch [101/200] Iter [  1/391]\t\tLoss: 0.0774 Acc@1: 96.000%\n",
      "| Epoch [101/200] Iter [ 26/391]\t\tLoss: 0.0979 Acc@1: 98.000%\n",
      "| Epoch [101/200] Iter [ 51/391]\t\tLoss: 0.0515 Acc@1: 98.000%\n",
      "| Epoch [101/200] Iter [ 76/391]\t\tLoss: 0.0963 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [101/391]\t\tLoss: 0.0686 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [126/391]\t\tLoss: 0.0423 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [151/391]\t\tLoss: 0.0677 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [176/391]\t\tLoss: 0.0903 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [201/391]\t\tLoss: 0.0506 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [226/391]\t\tLoss: 0.0804 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [251/391]\t\tLoss: 0.0481 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [276/391]\t\tLoss: 0.0850 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [301/391]\t\tLoss: 0.0612 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [326/391]\t\tLoss: 0.0684 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [351/391]\t\tLoss: 0.1015 Acc@1: 97.000%\n",
      "| Epoch [101/200] Iter [376/391]\t\tLoss: 0.0694 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #101\t\t\tLoss: 0.2377 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #102, LR=0.0200\n",
      "| Epoch [102/200] Iter [  1/391]\t\tLoss: 0.0601 Acc@1: 96.000%\n",
      "| Epoch [102/200] Iter [ 26/391]\t\tLoss: 0.0400 Acc@1: 98.000%\n",
      "| Epoch [102/200] Iter [ 51/391]\t\tLoss: 0.0274 Acc@1: 98.000%\n",
      "| Epoch [102/200] Iter [ 76/391]\t\tLoss: 0.0352 Acc@1: 98.000%\n",
      "| Epoch [102/200] Iter [101/391]\t\tLoss: 0.0363 Acc@1: 98.000%\n",
      "| Epoch [102/200] Iter [126/391]\t\tLoss: 0.1296 Acc@1: 98.000%\n",
      "| Epoch [102/200] Iter [151/391]\t\tLoss: 0.0708 Acc@1: 98.000%\n",
      "| Epoch [102/200] Iter [176/391]\t\tLoss: 0.0801 Acc@1: 98.000%\n",
      "| Epoch [102/200] Iter [201/391]\t\tLoss: 0.0260 Acc@1: 97.000%\n",
      "| Epoch [102/200] Iter [226/391]\t\tLoss: 0.0811 Acc@1: 97.000%\n",
      "| Epoch [102/200] Iter [251/391]\t\tLoss: 0.0513 Acc@1: 97.000%\n",
      "| Epoch [102/200] Iter [276/391]\t\tLoss: 0.1118 Acc@1: 97.000%\n",
      "| Epoch [102/200] Iter [301/391]\t\tLoss: 0.0845 Acc@1: 97.000%\n",
      "| Epoch [102/200] Iter [326/391]\t\tLoss: 0.0562 Acc@1: 97.000%\n",
      "| Epoch [102/200] Iter [351/391]\t\tLoss: 0.0659 Acc@1: 97.000%\n",
      "| Epoch [102/200] Iter [376/391]\t\tLoss: 0.0616 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #102\t\t\tLoss: 0.2181 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #103, LR=0.0200\n",
      "| Epoch [103/200] Iter [  1/391]\t\tLoss: 0.0374 Acc@1: 98.000%\n",
      "| Epoch [103/200] Iter [ 26/391]\t\tLoss: 0.1088 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [ 51/391]\t\tLoss: 0.0503 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [ 76/391]\t\tLoss: 0.0803 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [101/391]\t\tLoss: 0.0443 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [126/391]\t\tLoss: 0.1100 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [151/391]\t\tLoss: 0.0677 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [176/391]\t\tLoss: 0.0471 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [201/391]\t\tLoss: 0.0276 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [226/391]\t\tLoss: 0.0530 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [251/391]\t\tLoss: 0.0967 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [276/391]\t\tLoss: 0.0712 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [301/391]\t\tLoss: 0.0769 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [326/391]\t\tLoss: 0.1573 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [351/391]\t\tLoss: 0.0959 Acc@1: 97.000%\n",
      "| Epoch [103/200] Iter [376/391]\t\tLoss: 0.0840 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #103\t\t\tLoss: 0.1463 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #104, LR=0.0200\n",
      "| Epoch [104/200] Iter [  1/391]\t\tLoss: 0.1059 Acc@1: 95.000%\n",
      "| Epoch [104/200] Iter [ 26/391]\t\tLoss: 0.0337 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [ 51/391]\t\tLoss: 0.0436 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [ 76/391]\t\tLoss: 0.0621 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [101/391]\t\tLoss: 0.0733 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [126/391]\t\tLoss: 0.0594 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [151/391]\t\tLoss: 0.0784 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [176/391]\t\tLoss: 0.0856 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [201/391]\t\tLoss: 0.1196 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [226/391]\t\tLoss: 0.1038 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [251/391]\t\tLoss: 0.1054 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [276/391]\t\tLoss: 0.0516 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [301/391]\t\tLoss: 0.1215 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [326/391]\t\tLoss: 0.0925 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [351/391]\t\tLoss: 0.1715 Acc@1: 97.000%\n",
      "| Epoch [104/200] Iter [376/391]\t\tLoss: 0.1725 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #104\t\t\tLoss: 0.1915 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #105, LR=0.0200\n",
      "| Epoch [105/200] Iter [  1/391]\t\tLoss: 0.0928 Acc@1: 98.000%\n",
      "| Epoch [105/200] Iter [ 26/391]\t\tLoss: 0.0560 Acc@1: 98.000%\n",
      "| Epoch [105/200] Iter [ 51/391]\t\tLoss: 0.0329 Acc@1: 98.000%\n",
      "| Epoch [105/200] Iter [ 76/391]\t\tLoss: 0.0446 Acc@1: 98.000%\n",
      "| Epoch [105/200] Iter [101/391]\t\tLoss: 0.0384 Acc@1: 98.000%\n",
      "| Epoch [105/200] Iter [126/391]\t\tLoss: 0.0860 Acc@1: 97.000%\n",
      "| Epoch [105/200] Iter [151/391]\t\tLoss: 0.1752 Acc@1: 97.000%\n",
      "| Epoch [105/200] Iter [176/391]\t\tLoss: 0.0647 Acc@1: 97.000%\n",
      "| Epoch [105/200] Iter [201/391]\t\tLoss: 0.0691 Acc@1: 97.000%\n",
      "| Epoch [105/200] Iter [226/391]\t\tLoss: 0.0448 Acc@1: 97.000%\n",
      "| Epoch [105/200] Iter [251/391]\t\tLoss: 0.0596 Acc@1: 97.000%\n",
      "| Epoch [105/200] Iter [276/391]\t\tLoss: 0.0887 Acc@1: 97.000%\n",
      "| Epoch [105/200] Iter [301/391]\t\tLoss: 0.0743 Acc@1: 97.000%\n",
      "| Epoch [105/200] Iter [326/391]\t\tLoss: 0.0770 Acc@1: 97.000%\n",
      "| Epoch [105/200] Iter [351/391]\t\tLoss: 0.0728 Acc@1: 97.000%\n",
      "| Epoch [105/200] Iter [376/391]\t\tLoss: 0.0879 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #105\t\t\tLoss: 0.1102 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #106, LR=0.0200\n",
      "| Epoch [106/200] Iter [  1/391]\t\tLoss: 0.0268 Acc@1: 100.000%\n",
      "| Epoch [106/200] Iter [ 26/391]\t\tLoss: 0.1366 Acc@1: 98.000%\n",
      "| Epoch [106/200] Iter [ 51/391]\t\tLoss: 0.0354 Acc@1: 98.000%\n",
      "| Epoch [106/200] Iter [ 76/391]\t\tLoss: 0.0312 Acc@1: 98.000%\n",
      "| Epoch [106/200] Iter [101/391]\t\tLoss: 0.0449 Acc@1: 98.000%\n",
      "| Epoch [106/200] Iter [126/391]\t\tLoss: 0.0458 Acc@1: 98.000%\n",
      "| Epoch [106/200] Iter [151/391]\t\tLoss: 0.0573 Acc@1: 98.000%\n",
      "| Epoch [106/200] Iter [176/391]\t\tLoss: 0.0463 Acc@1: 98.000%\n",
      "| Epoch [106/200] Iter [201/391]\t\tLoss: 0.0573 Acc@1: 97.000%\n",
      "| Epoch [106/200] Iter [226/391]\t\tLoss: 0.0933 Acc@1: 97.000%\n",
      "| Epoch [106/200] Iter [251/391]\t\tLoss: 0.0827 Acc@1: 97.000%\n",
      "| Epoch [106/200] Iter [276/391]\t\tLoss: 0.0253 Acc@1: 97.000%\n",
      "| Epoch [106/200] Iter [301/391]\t\tLoss: 0.0419 Acc@1: 97.000%\n",
      "| Epoch [106/200] Iter [326/391]\t\tLoss: 0.1405 Acc@1: 97.000%\n",
      "| Epoch [106/200] Iter [351/391]\t\tLoss: 0.1800 Acc@1: 97.000%\n",
      "| Epoch [106/200] Iter [376/391]\t\tLoss: 0.1238 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #106\t\t\tLoss: 0.2110 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #107, LR=0.0200\n",
      "| Epoch [107/200] Iter [  1/391]\t\tLoss: 0.0550 Acc@1: 98.000%\n",
      "| Epoch [107/200] Iter [ 26/391]\t\tLoss: 0.0569 Acc@1: 98.000%\n",
      "| Epoch [107/200] Iter [ 51/391]\t\tLoss: 0.0194 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [ 76/391]\t\tLoss: 0.0516 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [101/391]\t\tLoss: 0.0920 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [126/391]\t\tLoss: 0.0340 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [151/391]\t\tLoss: 0.0700 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [176/391]\t\tLoss: 0.0719 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [201/391]\t\tLoss: 0.0733 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [226/391]\t\tLoss: 0.0844 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [251/391]\t\tLoss: 0.0542 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [276/391]\t\tLoss: 0.0559 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [301/391]\t\tLoss: 0.0736 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [326/391]\t\tLoss: 0.0910 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [351/391]\t\tLoss: 0.0894 Acc@1: 97.000%\n",
      "| Epoch [107/200] Iter [376/391]\t\tLoss: 0.0801 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #107\t\t\tLoss: 0.0892 Acc@1: 90.00%\n",
      "\n",
      "=> Training Epoch #108, LR=0.0200\n",
      "| Epoch [108/200] Iter [  1/391]\t\tLoss: 0.0654 Acc@1: 96.000%\n",
      "| Epoch [108/200] Iter [ 26/391]\t\tLoss: 0.0303 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [ 51/391]\t\tLoss: 0.0875 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [ 76/391]\t\tLoss: 0.0763 Acc@1: 97.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [108/200] Iter [101/391]\t\tLoss: 0.0747 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [126/391]\t\tLoss: 0.0624 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [151/391]\t\tLoss: 0.1612 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [176/391]\t\tLoss: 0.0753 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [201/391]\t\tLoss: 0.1093 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [226/391]\t\tLoss: 0.0900 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [251/391]\t\tLoss: 0.1033 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [276/391]\t\tLoss: 0.1790 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [301/391]\t\tLoss: 0.0573 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [326/391]\t\tLoss: 0.0967 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [351/391]\t\tLoss: 0.1079 Acc@1: 97.000%\n",
      "| Epoch [108/200] Iter [376/391]\t\tLoss: 0.1001 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #108\t\t\tLoss: 0.1493 Acc@1: 92.00%\n",
      "\n",
      "=> Training Epoch #109, LR=0.0200\n",
      "| Epoch [109/200] Iter [  1/391]\t\tLoss: 0.1219 Acc@1: 96.000%\n",
      "| Epoch [109/200] Iter [ 26/391]\t\tLoss: 0.0698 Acc@1: 98.000%\n",
      "| Epoch [109/200] Iter [ 51/391]\t\tLoss: 0.0784 Acc@1: 98.000%\n",
      "| Epoch [109/200] Iter [ 76/391]\t\tLoss: 0.0178 Acc@1: 98.000%\n",
      "| Epoch [109/200] Iter [101/391]\t\tLoss: 0.0729 Acc@1: 98.000%\n",
      "| Epoch [109/200] Iter [126/391]\t\tLoss: 0.0635 Acc@1: 98.000%\n",
      "| Epoch [109/200] Iter [151/391]\t\tLoss: 0.0423 Acc@1: 98.000%\n",
      "| Epoch [109/200] Iter [176/391]\t\tLoss: 0.0301 Acc@1: 98.000%\n",
      "| Epoch [109/200] Iter [201/391]\t\tLoss: 0.0846 Acc@1: 97.000%\n",
      "| Epoch [109/200] Iter [226/391]\t\tLoss: 0.0336 Acc@1: 97.000%\n",
      "| Epoch [109/200] Iter [251/391]\t\tLoss: 0.0800 Acc@1: 97.000%\n",
      "| Epoch [109/200] Iter [276/391]\t\tLoss: 0.1511 Acc@1: 97.000%\n",
      "| Epoch [109/200] Iter [301/391]\t\tLoss: 0.0656 Acc@1: 97.000%\n",
      "| Epoch [109/200] Iter [326/391]\t\tLoss: 0.0712 Acc@1: 97.000%\n",
      "| Epoch [109/200] Iter [351/391]\t\tLoss: 0.0756 Acc@1: 97.000%\n",
      "| Epoch [109/200] Iter [376/391]\t\tLoss: 0.0547 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #109\t\t\tLoss: 0.1718 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #110, LR=0.0200\n",
      "| Epoch [110/200] Iter [  1/391]\t\tLoss: 0.0275 Acc@1: 99.000%\n",
      "| Epoch [110/200] Iter [ 26/391]\t\tLoss: 0.0249 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [ 51/391]\t\tLoss: 0.0564 Acc@1: 98.000%\n",
      "| Epoch [110/200] Iter [ 76/391]\t\tLoss: 0.0696 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [101/391]\t\tLoss: 0.0416 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [126/391]\t\tLoss: 0.0433 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [151/391]\t\tLoss: 0.1001 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [176/391]\t\tLoss: 0.0511 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [201/391]\t\tLoss: 0.1225 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [226/391]\t\tLoss: 0.0501 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [251/391]\t\tLoss: 0.0675 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [276/391]\t\tLoss: 0.0408 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [301/391]\t\tLoss: 0.0970 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [326/391]\t\tLoss: 0.1092 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [351/391]\t\tLoss: 0.1327 Acc@1: 97.000%\n",
      "| Epoch [110/200] Iter [376/391]\t\tLoss: 0.0819 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #110\t\t\tLoss: 0.2469 Acc@1: 90.00%\n",
      "\n",
      "=> Training Epoch #111, LR=0.0200\n",
      "| Epoch [111/200] Iter [  1/391]\t\tLoss: 0.1046 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [ 26/391]\t\tLoss: 0.0320 Acc@1: 98.000%\n",
      "| Epoch [111/200] Iter [ 51/391]\t\tLoss: 0.0682 Acc@1: 98.000%\n",
      "| Epoch [111/200] Iter [ 76/391]\t\tLoss: 0.0859 Acc@1: 98.000%\n",
      "| Epoch [111/200] Iter [101/391]\t\tLoss: 0.1549 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [126/391]\t\tLoss: 0.0934 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [151/391]\t\tLoss: 0.0593 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [176/391]\t\tLoss: 0.0953 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [201/391]\t\tLoss: 0.0676 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [226/391]\t\tLoss: 0.0603 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [251/391]\t\tLoss: 0.1083 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [276/391]\t\tLoss: 0.0594 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [301/391]\t\tLoss: 0.0406 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [326/391]\t\tLoss: 0.0515 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [351/391]\t\tLoss: 0.0417 Acc@1: 97.000%\n",
      "| Epoch [111/200] Iter [376/391]\t\tLoss: 0.0433 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #111\t\t\tLoss: 0.2045 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #112, LR=0.0200\n",
      "| Epoch [112/200] Iter [  1/391]\t\tLoss: 0.0647 Acc@1: 98.000%\n",
      "| Epoch [112/200] Iter [ 26/391]\t\tLoss: 0.0574 Acc@1: 98.000%\n",
      "| Epoch [112/200] Iter [ 51/391]\t\tLoss: 0.0315 Acc@1: 98.000%\n",
      "| Epoch [112/200] Iter [ 76/391]\t\tLoss: 0.0889 Acc@1: 98.000%\n",
      "| Epoch [112/200] Iter [101/391]\t\tLoss: 0.1433 Acc@1: 98.000%\n",
      "| Epoch [112/200] Iter [126/391]\t\tLoss: 0.0356 Acc@1: 98.000%\n",
      "| Epoch [112/200] Iter [151/391]\t\tLoss: 0.0378 Acc@1: 97.000%\n",
      "| Epoch [112/200] Iter [176/391]\t\tLoss: 0.0578 Acc@1: 97.000%\n",
      "| Epoch [112/200] Iter [201/391]\t\tLoss: 0.1166 Acc@1: 97.000%\n",
      "| Epoch [112/200] Iter [226/391]\t\tLoss: 0.0422 Acc@1: 97.000%\n",
      "| Epoch [112/200] Iter [251/391]\t\tLoss: 0.0951 Acc@1: 97.000%\n",
      "| Epoch [112/200] Iter [276/391]\t\tLoss: 0.0632 Acc@1: 97.000%\n",
      "| Epoch [112/200] Iter [301/391]\t\tLoss: 0.0285 Acc@1: 97.000%\n",
      "| Epoch [112/200] Iter [326/391]\t\tLoss: 0.0772 Acc@1: 97.000%\n",
      "| Epoch [112/200] Iter [351/391]\t\tLoss: 0.0895 Acc@1: 97.000%\n",
      "| Epoch [112/200] Iter [376/391]\t\tLoss: 0.1359 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #112\t\t\tLoss: 0.1711 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #113, LR=0.0200\n",
      "| Epoch [113/200] Iter [  1/391]\t\tLoss: 0.1072 Acc@1: 96.000%\n",
      "| Epoch [113/200] Iter [ 26/391]\t\tLoss: 0.0473 Acc@1: 98.000%\n",
      "| Epoch [113/200] Iter [ 51/391]\t\tLoss: 0.0399 Acc@1: 98.000%\n",
      "| Epoch [113/200] Iter [ 76/391]\t\tLoss: 0.1332 Acc@1: 98.000%\n",
      "| Epoch [113/200] Iter [101/391]\t\tLoss: 0.0630 Acc@1: 98.000%\n",
      "| Epoch [113/200] Iter [126/391]\t\tLoss: 0.0857 Acc@1: 98.000%\n",
      "| Epoch [113/200] Iter [151/391]\t\tLoss: 0.0295 Acc@1: 98.000%\n",
      "| Epoch [113/200] Iter [176/391]\t\tLoss: 0.0664 Acc@1: 98.000%\n",
      "| Epoch [113/200] Iter [201/391]\t\tLoss: 0.0604 Acc@1: 97.000%\n",
      "| Epoch [113/200] Iter [226/391]\t\tLoss: 0.0853 Acc@1: 97.000%\n",
      "| Epoch [113/200] Iter [251/391]\t\tLoss: 0.1420 Acc@1: 97.000%\n",
      "| Epoch [113/200] Iter [276/391]\t\tLoss: 0.0787 Acc@1: 97.000%\n",
      "| Epoch [113/200] Iter [301/391]\t\tLoss: 0.0793 Acc@1: 97.000%\n",
      "| Epoch [113/200] Iter [326/391]\t\tLoss: 0.1421 Acc@1: 97.000%\n",
      "| Epoch [113/200] Iter [351/391]\t\tLoss: 0.0627 Acc@1: 97.000%\n",
      "| Epoch [113/200] Iter [376/391]\t\tLoss: 0.0152 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #113\t\t\tLoss: 0.3181 Acc@1: 90.00%\n",
      "\n",
      "=> Training Epoch #114, LR=0.0200\n",
      "| Epoch [114/200] Iter [  1/391]\t\tLoss: 0.0540 Acc@1: 98.000%\n",
      "| Epoch [114/200] Iter [ 26/391]\t\tLoss: 0.0596 Acc@1: 98.000%\n",
      "| Epoch [114/200] Iter [ 51/391]\t\tLoss: 0.0559 Acc@1: 98.000%\n",
      "| Epoch [114/200] Iter [ 76/391]\t\tLoss: 0.1144 Acc@1: 98.000%\n",
      "| Epoch [114/200] Iter [101/391]\t\tLoss: 0.1133 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [126/391]\t\tLoss: 0.0670 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [151/391]\t\tLoss: 0.0371 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [176/391]\t\tLoss: 0.0719 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [201/391]\t\tLoss: 0.0430 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [226/391]\t\tLoss: 0.0775 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [251/391]\t\tLoss: 0.0183 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [276/391]\t\tLoss: 0.1395 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [301/391]\t\tLoss: 0.0925 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [326/391]\t\tLoss: 0.1116 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [351/391]\t\tLoss: 0.0509 Acc@1: 97.000%\n",
      "| Epoch [114/200] Iter [376/391]\t\tLoss: 0.1393 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #114\t\t\tLoss: 0.1912 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #115, LR=0.0200\n",
      "| Epoch [115/200] Iter [  1/391]\t\tLoss: 0.0297 Acc@1: 99.000%\n",
      "| Epoch [115/200] Iter [ 26/391]\t\tLoss: 0.0545 Acc@1: 98.000%\n",
      "| Epoch [115/200] Iter [ 51/391]\t\tLoss: 0.0278 Acc@1: 98.000%\n",
      "| Epoch [115/200] Iter [ 76/391]\t\tLoss: 0.0750 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [101/391]\t\tLoss: 0.0285 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [126/391]\t\tLoss: 0.1049 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [151/391]\t\tLoss: 0.0364 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [176/391]\t\tLoss: 0.0336 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [201/391]\t\tLoss: 0.1429 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [226/391]\t\tLoss: 0.0643 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [251/391]\t\tLoss: 0.0562 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [276/391]\t\tLoss: 0.0443 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [301/391]\t\tLoss: 0.0843 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [326/391]\t\tLoss: 0.1023 Acc@1: 97.000%\n",
      "| Epoch [115/200] Iter [351/391]\t\tLoss: 0.0631 Acc@1: 97.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [115/200] Iter [376/391]\t\tLoss: 0.0446 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #115\t\t\tLoss: 0.2851 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #116, LR=0.0200\n",
      "| Epoch [116/200] Iter [  1/391]\t\tLoss: 0.0745 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [ 26/391]\t\tLoss: 0.0374 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [ 51/391]\t\tLoss: 0.0536 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [ 76/391]\t\tLoss: 0.0683 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [101/391]\t\tLoss: 0.0944 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [126/391]\t\tLoss: 0.0622 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [151/391]\t\tLoss: 0.0496 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [176/391]\t\tLoss: 0.0241 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [201/391]\t\tLoss: 0.0582 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [226/391]\t\tLoss: 0.0445 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [251/391]\t\tLoss: 0.0760 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [276/391]\t\tLoss: 0.0789 Acc@1: 98.000%\n",
      "| Epoch [116/200] Iter [301/391]\t\tLoss: 0.1195 Acc@1: 97.000%\n",
      "| Epoch [116/200] Iter [326/391]\t\tLoss: 0.0730 Acc@1: 97.000%\n",
      "| Epoch [116/200] Iter [351/391]\t\tLoss: 0.0398 Acc@1: 97.000%\n",
      "| Epoch [116/200] Iter [376/391]\t\tLoss: 0.0714 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #116\t\t\tLoss: 0.1804 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #117, LR=0.0200\n",
      "| Epoch [117/200] Iter [  1/391]\t\tLoss: 0.0881 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [ 26/391]\t\tLoss: 0.0466 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [ 51/391]\t\tLoss: 0.0392 Acc@1: 98.000%\n",
      "| Epoch [117/200] Iter [ 76/391]\t\tLoss: 0.0584 Acc@1: 98.000%\n",
      "| Epoch [117/200] Iter [101/391]\t\tLoss: 0.1241 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [126/391]\t\tLoss: 0.0799 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [151/391]\t\tLoss: 0.0948 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [176/391]\t\tLoss: 0.0402 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [201/391]\t\tLoss: 0.0583 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [226/391]\t\tLoss: 0.0489 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [251/391]\t\tLoss: 0.1421 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [276/391]\t\tLoss: 0.0672 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [301/391]\t\tLoss: 0.0742 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [326/391]\t\tLoss: 0.0719 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [351/391]\t\tLoss: 0.0743 Acc@1: 97.000%\n",
      "| Epoch [117/200] Iter [376/391]\t\tLoss: 0.0363 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #117\t\t\tLoss: 0.2539 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #118, LR=0.0200\n",
      "| Epoch [118/200] Iter [  1/391]\t\tLoss: 0.0574 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [ 26/391]\t\tLoss: 0.0624 Acc@1: 98.000%\n",
      "| Epoch [118/200] Iter [ 51/391]\t\tLoss: 0.0551 Acc@1: 98.000%\n",
      "| Epoch [118/200] Iter [ 76/391]\t\tLoss: 0.0686 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [101/391]\t\tLoss: 0.1434 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [126/391]\t\tLoss: 0.0254 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [151/391]\t\tLoss: 0.0630 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [176/391]\t\tLoss: 0.1340 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [201/391]\t\tLoss: 0.0588 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [226/391]\t\tLoss: 0.0676 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [251/391]\t\tLoss: 0.1006 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [276/391]\t\tLoss: 0.0795 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [301/391]\t\tLoss: 0.1084 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [326/391]\t\tLoss: 0.0944 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [351/391]\t\tLoss: 0.0823 Acc@1: 97.000%\n",
      "| Epoch [118/200] Iter [376/391]\t\tLoss: 0.0654 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #118\t\t\tLoss: 0.2761 Acc@1: 90.00%\n",
      "\n",
      "=> Training Epoch #119, LR=0.0200\n",
      "| Epoch [119/200] Iter [  1/391]\t\tLoss: 0.0533 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [ 26/391]\t\tLoss: 0.0776 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [ 51/391]\t\tLoss: 0.0495 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [ 76/391]\t\tLoss: 0.0670 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [101/391]\t\tLoss: 0.0672 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [126/391]\t\tLoss: 0.0593 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [151/391]\t\tLoss: 0.0949 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [176/391]\t\tLoss: 0.0794 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [201/391]\t\tLoss: 0.0341 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [226/391]\t\tLoss: 0.0425 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [251/391]\t\tLoss: 0.0995 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [276/391]\t\tLoss: 0.0318 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [301/391]\t\tLoss: 0.0762 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [326/391]\t\tLoss: 0.1005 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [351/391]\t\tLoss: 0.0527 Acc@1: 97.000%\n",
      "| Epoch [119/200] Iter [376/391]\t\tLoss: 0.0690 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #119\t\t\tLoss: 0.3545 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #120, LR=0.0200\n",
      "| Epoch [120/200] Iter [  1/391]\t\tLoss: 0.0194 Acc@1: 100.000%\n",
      "| Epoch [120/200] Iter [ 26/391]\t\tLoss: 0.0510 Acc@1: 98.000%\n",
      "| Epoch [120/200] Iter [ 51/391]\t\tLoss: 0.0799 Acc@1: 98.000%\n",
      "| Epoch [120/200] Iter [ 76/391]\t\tLoss: 0.0636 Acc@1: 98.000%\n",
      "| Epoch [120/200] Iter [101/391]\t\tLoss: 0.0651 Acc@1: 98.000%\n",
      "| Epoch [120/200] Iter [126/391]\t\tLoss: 0.0623 Acc@1: 98.000%\n",
      "| Epoch [120/200] Iter [151/391]\t\tLoss: 0.0507 Acc@1: 98.000%\n",
      "| Epoch [120/200] Iter [176/391]\t\tLoss: 0.0621 Acc@1: 98.000%\n",
      "| Epoch [120/200] Iter [201/391]\t\tLoss: 0.0560 Acc@1: 97.000%\n",
      "| Epoch [120/200] Iter [226/391]\t\tLoss: 0.0475 Acc@1: 97.000%\n",
      "| Epoch [120/200] Iter [251/391]\t\tLoss: 0.0393 Acc@1: 98.000%\n",
      "| Epoch [120/200] Iter [276/391]\t\tLoss: 0.1095 Acc@1: 97.000%\n",
      "| Epoch [120/200] Iter [301/391]\t\tLoss: 0.1400 Acc@1: 97.000%\n",
      "| Epoch [120/200] Iter [326/391]\t\tLoss: 0.0647 Acc@1: 97.000%\n",
      "| Epoch [120/200] Iter [351/391]\t\tLoss: 0.0792 Acc@1: 97.000%\n",
      "| Epoch [120/200] Iter [376/391]\t\tLoss: 0.0961 Acc@1: 97.000%\n",
      "\n",
      "| Validation Epoch #120\t\t\tLoss: 0.3025 Acc@1: 91.00%\n",
      "\n",
      "=> Training Epoch #121, LR=0.0040\n",
      "| Epoch [121/200] Iter [  1/391]\t\tLoss: 0.0835 Acc@1: 95.000%\n",
      "| Epoch [121/200] Iter [ 26/391]\t\tLoss: 0.0341 Acc@1: 98.000%\n",
      "| Epoch [121/200] Iter [ 51/391]\t\tLoss: 0.0453 Acc@1: 98.000%\n",
      "| Epoch [121/200] Iter [ 76/391]\t\tLoss: 0.0281 Acc@1: 98.000%\n",
      "| Epoch [121/200] Iter [101/391]\t\tLoss: 0.0226 Acc@1: 98.000%\n",
      "| Epoch [121/200] Iter [126/391]\t\tLoss: 0.0167 Acc@1: 98.000%\n",
      "| Epoch [121/200] Iter [151/391]\t\tLoss: 0.0089 Acc@1: 99.000%\n",
      "| Epoch [121/200] Iter [176/391]\t\tLoss: 0.0086 Acc@1: 99.000%\n",
      "| Epoch [121/200] Iter [201/391]\t\tLoss: 0.0760 Acc@1: 99.000%\n",
      "| Epoch [121/200] Iter [226/391]\t\tLoss: 0.0506 Acc@1: 99.000%\n",
      "| Epoch [121/200] Iter [251/391]\t\tLoss: 0.0122 Acc@1: 99.000%\n",
      "| Epoch [121/200] Iter [276/391]\t\tLoss: 0.0067 Acc@1: 99.000%\n",
      "| Epoch [121/200] Iter [301/391]\t\tLoss: 0.0078 Acc@1: 99.000%\n",
      "| Epoch [121/200] Iter [326/391]\t\tLoss: 0.0183 Acc@1: 99.000%\n",
      "| Epoch [121/200] Iter [351/391]\t\tLoss: 0.0089 Acc@1: 99.000%\n",
      "| Epoch [121/200] Iter [376/391]\t\tLoss: 0.0114 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #121\t\t\tLoss: 0.1157 Acc@1: 94.00%\n",
      "| Saving Best model...\t\t\tTop1 = 94.00%\n",
      "\n",
      "=> Training Epoch #122, LR=0.0040\n",
      "| Epoch [122/200] Iter [  1/391]\t\tLoss: 0.0068 Acc@1: 100.000%\n",
      "| Epoch [122/200] Iter [ 26/391]\t\tLoss: 0.0119 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [ 51/391]\t\tLoss: 0.0117 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [ 76/391]\t\tLoss: 0.0056 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [101/391]\t\tLoss: 0.0053 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [126/391]\t\tLoss: 0.0137 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [151/391]\t\tLoss: 0.0241 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [176/391]\t\tLoss: 0.0140 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [201/391]\t\tLoss: 0.0150 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [226/391]\t\tLoss: 0.0084 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [251/391]\t\tLoss: 0.0057 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [276/391]\t\tLoss: 0.0080 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [301/391]\t\tLoss: 0.0075 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [326/391]\t\tLoss: 0.0090 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [351/391]\t\tLoss: 0.0067 Acc@1: 99.000%\n",
      "| Epoch [122/200] Iter [376/391]\t\tLoss: 0.0484 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #122\t\t\tLoss: 0.0807 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #123, LR=0.0040\n",
      "| Epoch [123/200] Iter [  1/391]\t\tLoss: 0.0087 Acc@1: 100.000%\n",
      "| Epoch [123/200] Iter [ 26/391]\t\tLoss: 0.0182 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [ 51/391]\t\tLoss: 0.0208 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [ 76/391]\t\tLoss: 0.0163 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [101/391]\t\tLoss: 0.0118 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [126/391]\t\tLoss: 0.0086 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [151/391]\t\tLoss: 0.0099 Acc@1: 99.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [123/200] Iter [176/391]\t\tLoss: 0.0104 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [201/391]\t\tLoss: 0.0078 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [226/391]\t\tLoss: 0.0050 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [251/391]\t\tLoss: 0.0062 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [276/391]\t\tLoss: 0.0086 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [301/391]\t\tLoss: 0.0068 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [326/391]\t\tLoss: 0.0110 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [351/391]\t\tLoss: 0.0080 Acc@1: 99.000%\n",
      "| Epoch [123/200] Iter [376/391]\t\tLoss: 0.0046 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #123\t\t\tLoss: 0.1003 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #124, LR=0.0040\n",
      "| Epoch [124/200] Iter [  1/391]\t\tLoss: 0.0049 Acc@1: 100.000%\n",
      "| Epoch [124/200] Iter [ 26/391]\t\tLoss: 0.0103 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [ 51/391]\t\tLoss: 0.0059 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [ 76/391]\t\tLoss: 0.0164 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [101/391]\t\tLoss: 0.0050 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [126/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [151/391]\t\tLoss: 0.0094 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [176/391]\t\tLoss: 0.0227 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [201/391]\t\tLoss: 0.0055 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [226/391]\t\tLoss: 0.0121 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [251/391]\t\tLoss: 0.0087 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [276/391]\t\tLoss: 0.0074 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [301/391]\t\tLoss: 0.0098 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [326/391]\t\tLoss: 0.0079 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [351/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [124/200] Iter [376/391]\t\tLoss: 0.0062 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #124\t\t\tLoss: 0.0756 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #125, LR=0.0040\n",
      "| Epoch [125/200] Iter [  1/391]\t\tLoss: 0.0169 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [ 26/391]\t\tLoss: 0.0037 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [ 51/391]\t\tLoss: 0.0040 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [ 76/391]\t\tLoss: 0.0053 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [101/391]\t\tLoss: 0.0096 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [126/391]\t\tLoss: 0.0072 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [151/391]\t\tLoss: 0.0106 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [176/391]\t\tLoss: 0.0051 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [201/391]\t\tLoss: 0.0057 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [226/391]\t\tLoss: 0.0070 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [251/391]\t\tLoss: 0.0038 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [276/391]\t\tLoss: 0.0039 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [301/391]\t\tLoss: 0.0039 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [326/391]\t\tLoss: 0.0068 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [351/391]\t\tLoss: 0.0137 Acc@1: 99.000%\n",
      "| Epoch [125/200] Iter [376/391]\t\tLoss: 0.0038 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #125\t\t\tLoss: 0.1331 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #126, LR=0.0040\n",
      "| Epoch [126/200] Iter [  1/391]\t\tLoss: 0.0060 Acc@1: 100.000%\n",
      "| Epoch [126/200] Iter [ 26/391]\t\tLoss: 0.0160 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [ 51/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [ 76/391]\t\tLoss: 0.0066 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [101/391]\t\tLoss: 0.0041 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [126/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [151/391]\t\tLoss: 0.0037 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [176/391]\t\tLoss: 0.0057 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [201/391]\t\tLoss: 0.0038 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [226/391]\t\tLoss: 0.0034 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [251/391]\t\tLoss: 0.0042 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [276/391]\t\tLoss: 0.0089 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [301/391]\t\tLoss: 0.0046 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [326/391]\t\tLoss: 0.0032 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [351/391]\t\tLoss: 0.0067 Acc@1: 99.000%\n",
      "| Epoch [126/200] Iter [376/391]\t\tLoss: 0.0057 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #126\t\t\tLoss: 0.0765 Acc@1: 95.00%\n",
      "| Saving Best model...\t\t\tTop1 = 95.00%\n",
      "\n",
      "=> Training Epoch #127, LR=0.0040\n",
      "| Epoch [127/200] Iter [  1/391]\t\tLoss: 0.0082 Acc@1: 100.000%\n",
      "| Epoch [127/200] Iter [ 26/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [127/200] Iter [ 51/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [ 76/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [101/391]\t\tLoss: 0.0101 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [126/391]\t\tLoss: 0.0060 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [151/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [176/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [201/391]\t\tLoss: 0.0073 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [226/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [251/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [276/391]\t\tLoss: 0.0106 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [301/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [326/391]\t\tLoss: 0.0088 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [351/391]\t\tLoss: 0.0061 Acc@1: 99.000%\n",
      "| Epoch [127/200] Iter [376/391]\t\tLoss: 0.0037 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #127\t\t\tLoss: 0.1123 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #128, LR=0.0040\n",
      "| Epoch [128/200] Iter [  1/391]\t\tLoss: 0.0074 Acc@1: 100.000%\n",
      "| Epoch [128/200] Iter [ 26/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [ 51/391]\t\tLoss: 0.0033 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [ 76/391]\t\tLoss: 0.0043 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [101/391]\t\tLoss: 0.0069 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [126/391]\t\tLoss: 0.0050 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [151/391]\t\tLoss: 0.0055 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [176/391]\t\tLoss: 0.0057 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [201/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [226/391]\t\tLoss: 0.0074 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [251/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [276/391]\t\tLoss: 0.0034 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [301/391]\t\tLoss: 0.0038 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [326/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [351/391]\t\tLoss: 0.0109 Acc@1: 99.000%\n",
      "| Epoch [128/200] Iter [376/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #128\t\t\tLoss: 0.0889 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #129, LR=0.0040\n",
      "| Epoch [129/200] Iter [  1/391]\t\tLoss: 0.0030 Acc@1: 100.000%\n",
      "| Epoch [129/200] Iter [ 26/391]\t\tLoss: 0.0032 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [ 51/391]\t\tLoss: 0.0073 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [ 76/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [101/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [126/391]\t\tLoss: 0.0138 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [151/391]\t\tLoss: 0.0067 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [176/391]\t\tLoss: 0.0036 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [201/391]\t\tLoss: 0.0097 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [226/391]\t\tLoss: 0.0048 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [251/391]\t\tLoss: 0.0082 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [276/391]\t\tLoss: 0.0050 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [301/391]\t\tLoss: 0.0037 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [326/391]\t\tLoss: 0.0043 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [351/391]\t\tLoss: 0.0052 Acc@1: 99.000%\n",
      "| Epoch [129/200] Iter [376/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #129\t\t\tLoss: 0.0912 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #130, LR=0.0040\n",
      "| Epoch [130/200] Iter [  1/391]\t\tLoss: 0.0031 Acc@1: 100.000%\n",
      "| Epoch [130/200] Iter [ 26/391]\t\tLoss: 0.0040 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [ 51/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [ 76/391]\t\tLoss: 0.0050 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [101/391]\t\tLoss: 0.0088 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [126/391]\t\tLoss: 0.0037 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [151/391]\t\tLoss: 0.0065 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [176/391]\t\tLoss: 0.0062 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [201/391]\t\tLoss: 0.0058 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [226/391]\t\tLoss: 0.0062 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [251/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [276/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [301/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [326/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [351/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [130/200] Iter [376/391]\t\tLoss: 0.0042 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #130\t\t\tLoss: 0.0810 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #131, LR=0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [131/200] Iter [  1/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [131/200] Iter [ 26/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [ 51/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [ 76/391]\t\tLoss: 0.0036 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [101/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [126/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [151/391]\t\tLoss: 0.0043 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [176/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [201/391]\t\tLoss: 0.0114 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [226/391]\t\tLoss: 0.0042 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [251/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [276/391]\t\tLoss: 0.0009 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [301/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [326/391]\t\tLoss: 0.0040 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [351/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [131/200] Iter [376/391]\t\tLoss: 0.0051 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #131\t\t\tLoss: 0.0885 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #132, LR=0.0040\n",
      "| Epoch [132/200] Iter [  1/391]\t\tLoss: 0.0025 Acc@1: 100.000%\n",
      "| Epoch [132/200] Iter [ 26/391]\t\tLoss: 0.0040 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [ 51/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [ 76/391]\t\tLoss: 0.0039 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [101/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [126/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [151/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [176/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [201/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [226/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [251/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [276/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [301/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [326/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [351/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [132/200] Iter [376/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #132\t\t\tLoss: 0.0947 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #133, LR=0.0040\n",
      "| Epoch [133/200] Iter [  1/391]\t\tLoss: 0.0051 Acc@1: 100.000%\n",
      "| Epoch [133/200] Iter [ 26/391]\t\tLoss: 0.0041 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [ 51/391]\t\tLoss: 0.0052 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [ 76/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [101/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [126/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [151/391]\t\tLoss: 0.0100 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [176/391]\t\tLoss: 0.0047 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [201/391]\t\tLoss: 0.0117 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [226/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [251/391]\t\tLoss: 0.0041 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [276/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [301/391]\t\tLoss: 0.0060 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [326/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [351/391]\t\tLoss: 0.0042 Acc@1: 99.000%\n",
      "| Epoch [133/200] Iter [376/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #133\t\t\tLoss: 0.0688 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #134, LR=0.0040\n",
      "| Epoch [134/200] Iter [  1/391]\t\tLoss: 0.0042 Acc@1: 100.000%\n",
      "| Epoch [134/200] Iter [ 26/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [ 51/391]\t\tLoss: 0.0032 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [ 76/391]\t\tLoss: 0.0054 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [101/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [126/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [151/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [176/391]\t\tLoss: 0.0047 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [201/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [226/391]\t\tLoss: 0.0055 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [251/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [276/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [301/391]\t\tLoss: 0.0048 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [326/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [351/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [134/200] Iter [376/391]\t\tLoss: 0.0063 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #134\t\t\tLoss: 0.0871 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #135, LR=0.0040\n",
      "| Epoch [135/200] Iter [  1/391]\t\tLoss: 0.0056 Acc@1: 100.000%\n",
      "| Epoch [135/200] Iter [ 26/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [135/200] Iter [ 51/391]\t\tLoss: 0.0010 Acc@1: 100.000%\n",
      "| Epoch [135/200] Iter [ 76/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [135/200] Iter [101/391]\t\tLoss: 0.0023 Acc@1: 100.000%\n",
      "| Epoch [135/200] Iter [126/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [135/200] Iter [151/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [135/200] Iter [176/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [135/200] Iter [201/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [135/200] Iter [226/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [135/200] Iter [251/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [135/200] Iter [276/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [135/200] Iter [301/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "| Epoch [135/200] Iter [326/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [135/200] Iter [351/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [135/200] Iter [376/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #135\t\t\tLoss: 0.0977 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #136, LR=0.0040\n",
      "| Epoch [136/200] Iter [  1/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [136/200] Iter [ 26/391]\t\tLoss: 0.0042 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [ 51/391]\t\tLoss: 0.0055 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [ 76/391]\t\tLoss: 0.0034 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [101/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [126/391]\t\tLoss: 0.0138 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [151/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [176/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [201/391]\t\tLoss: 0.0033 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [226/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [251/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [276/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [301/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [326/391]\t\tLoss: 0.0095 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [351/391]\t\tLoss: 0.0010 Acc@1: 99.000%\n",
      "| Epoch [136/200] Iter [376/391]\t\tLoss: 0.0046 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #136\t\t\tLoss: 0.0781 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #137, LR=0.0040\n",
      "| Epoch [137/200] Iter [  1/391]\t\tLoss: 0.0140 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [ 26/391]\t\tLoss: 0.0038 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [ 51/391]\t\tLoss: 0.0047 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [ 76/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [101/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [126/391]\t\tLoss: 0.0105 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [151/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [176/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [201/391]\t\tLoss: 0.0076 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [226/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [251/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [276/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [301/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [326/391]\t\tLoss: 0.0043 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [351/391]\t\tLoss: 0.0043 Acc@1: 99.000%\n",
      "| Epoch [137/200] Iter [376/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #137\t\t\tLoss: 0.0916 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #138, LR=0.0040\n",
      "| Epoch [138/200] Iter [  1/391]\t\tLoss: 0.0034 Acc@1: 100.000%\n",
      "| Epoch [138/200] Iter [ 26/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [ 51/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [ 76/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [101/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [126/391]\t\tLoss: 0.0048 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [151/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [176/391]\t\tLoss: 0.0228 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [201/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [226/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [138/200] Iter [251/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [276/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [301/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [326/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [351/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [138/200] Iter [376/391]\t\tLoss: 0.0034 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #138\t\t\tLoss: 0.0951 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #139, LR=0.0040\n",
      "| Epoch [139/200] Iter [  1/391]\t\tLoss: 0.0029 Acc@1: 100.000%\n",
      "| Epoch [139/200] Iter [ 26/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [139/200] Iter [ 51/391]\t\tLoss: 0.0023 Acc@1: 100.000%\n",
      "| Epoch [139/200] Iter [ 76/391]\t\tLoss: 0.0009 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [101/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [126/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [151/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [176/391]\t\tLoss: 0.0052 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [201/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [226/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [251/391]\t\tLoss: 0.0038 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [276/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [301/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [326/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [351/391]\t\tLoss: 0.0056 Acc@1: 99.000%\n",
      "| Epoch [139/200] Iter [376/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #139\t\t\tLoss: 0.1021 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #140, LR=0.0040\n",
      "| Epoch [140/200] Iter [  1/391]\t\tLoss: 0.0064 Acc@1: 100.000%\n",
      "| Epoch [140/200] Iter [ 26/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [140/200] Iter [ 51/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [ 76/391]\t\tLoss: 0.0091 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [101/391]\t\tLoss: 0.0042 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [126/391]\t\tLoss: 0.0095 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [151/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [176/391]\t\tLoss: 0.0158 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [201/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [226/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [251/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [276/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [301/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [326/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [351/391]\t\tLoss: 0.0039 Acc@1: 99.000%\n",
      "| Epoch [140/200] Iter [376/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #140\t\t\tLoss: 0.0916 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #141, LR=0.0040\n",
      "| Epoch [141/200] Iter [  1/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [141/200] Iter [ 26/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [141/200] Iter [ 51/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [ 76/391]\t\tLoss: 0.0170 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [101/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [126/391]\t\tLoss: 0.0047 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [151/391]\t\tLoss: 0.0058 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [176/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [201/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [226/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [251/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [276/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [301/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [326/391]\t\tLoss: 0.0040 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [351/391]\t\tLoss: 0.0062 Acc@1: 99.000%\n",
      "| Epoch [141/200] Iter [376/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #141\t\t\tLoss: 0.1332 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #142, LR=0.0040\n",
      "| Epoch [142/200] Iter [  1/391]\t\tLoss: 0.0022 Acc@1: 100.000%\n",
      "| Epoch [142/200] Iter [ 26/391]\t\tLoss: 0.0044 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [ 51/391]\t\tLoss: 0.0050 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [ 76/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [101/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [126/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [151/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [176/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [201/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [226/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [251/391]\t\tLoss: 0.0048 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [276/391]\t\tLoss: 0.0063 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [301/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [326/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [351/391]\t\tLoss: 0.0032 Acc@1: 99.000%\n",
      "| Epoch [142/200] Iter [376/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #142\t\t\tLoss: 0.0811 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #143, LR=0.0040\n",
      "| Epoch [143/200] Iter [  1/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [143/200] Iter [ 26/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [143/200] Iter [ 51/391]\t\tLoss: 0.0028 Acc@1: 100.000%\n",
      "| Epoch [143/200] Iter [ 76/391]\t\tLoss: 0.0032 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [101/391]\t\tLoss: 0.0041 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [126/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [151/391]\t\tLoss: 0.0040 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [176/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [201/391]\t\tLoss: 0.0043 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [226/391]\t\tLoss: 0.0034 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [251/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [276/391]\t\tLoss: 0.0065 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [301/391]\t\tLoss: 0.0039 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [326/391]\t\tLoss: 0.0049 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [351/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [143/200] Iter [376/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #143\t\t\tLoss: 0.0988 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #144, LR=0.0040\n",
      "| Epoch [144/200] Iter [  1/391]\t\tLoss: 0.0036 Acc@1: 100.000%\n",
      "| Epoch [144/200] Iter [ 26/391]\t\tLoss: 0.0049 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [ 51/391]\t\tLoss: 0.0044 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [ 76/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [101/391]\t\tLoss: 0.0050 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [126/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [151/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [176/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [201/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [226/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [251/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [276/391]\t\tLoss: 0.0040 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [301/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [326/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [351/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [144/200] Iter [376/391]\t\tLoss: 0.0041 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #144\t\t\tLoss: 0.1155 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #145, LR=0.0040\n",
      "| Epoch [145/200] Iter [  1/391]\t\tLoss: 0.0034 Acc@1: 100.000%\n",
      "| Epoch [145/200] Iter [ 26/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [ 51/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [ 76/391]\t\tLoss: 0.0033 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [101/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [126/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [151/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [176/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [201/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [226/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [251/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [276/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [301/391]\t\tLoss: 0.0089 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [326/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [351/391]\t\tLoss: 0.0043 Acc@1: 99.000%\n",
      "| Epoch [145/200] Iter [376/391]\t\tLoss: 0.0054 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #145\t\t\tLoss: 0.1241 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #146, LR=0.0040\n",
      "| Epoch [146/200] Iter [  1/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [146/200] Iter [ 26/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [146/200] Iter [ 51/391]\t\tLoss: 0.0064 Acc@1: 100.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [146/200] Iter [ 76/391]\t\tLoss: 0.0054 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [101/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [126/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [151/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [176/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [201/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [226/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [251/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [276/391]\t\tLoss: 0.0063 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [301/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [326/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [351/391]\t\tLoss: 0.0041 Acc@1: 99.000%\n",
      "| Epoch [146/200] Iter [376/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #146\t\t\tLoss: 0.1006 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #147, LR=0.0040\n",
      "| Epoch [147/200] Iter [  1/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [147/200] Iter [ 26/391]\t\tLoss: 0.0011 Acc@1: 100.000%\n",
      "| Epoch [147/200] Iter [ 51/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [147/200] Iter [ 76/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [147/200] Iter [101/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [126/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [151/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [176/391]\t\tLoss: 0.0051 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [201/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [226/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [251/391]\t\tLoss: 0.0077 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [276/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [301/391]\t\tLoss: 0.0009 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [326/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [351/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [147/200] Iter [376/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #147\t\t\tLoss: 0.0815 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #148, LR=0.0040\n",
      "| Epoch [148/200] Iter [  1/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [148/200] Iter [ 26/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [148/200] Iter [ 51/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [148/200] Iter [ 76/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [148/200] Iter [101/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [126/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [151/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [176/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [201/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [226/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [251/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [276/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [301/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [326/391]\t\tLoss: 0.0042 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [351/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [148/200] Iter [376/391]\t\tLoss: 0.0010 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #148\t\t\tLoss: 0.0958 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #149, LR=0.0040\n",
      "| Epoch [149/200] Iter [  1/391]\t\tLoss: 0.0022 Acc@1: 100.000%\n",
      "| Epoch [149/200] Iter [ 26/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [149/200] Iter [ 51/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [149/200] Iter [ 76/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [149/200] Iter [101/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [126/391]\t\tLoss: 0.0075 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [151/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [176/391]\t\tLoss: 0.0101 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [201/391]\t\tLoss: 0.0034 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [226/391]\t\tLoss: 0.0059 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [251/391]\t\tLoss: 0.0047 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [276/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [301/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [326/391]\t\tLoss: 0.0047 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [351/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [149/200] Iter [376/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #149\t\t\tLoss: 0.0891 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #150, LR=0.0040\n",
      "| Epoch [150/200] Iter [  1/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [150/200] Iter [ 26/391]\t\tLoss: 0.0009 Acc@1: 100.000%\n",
      "| Epoch [150/200] Iter [ 51/391]\t\tLoss: 0.0053 Acc@1: 100.000%\n",
      "| Epoch [150/200] Iter [ 76/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [150/200] Iter [101/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [126/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [151/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [176/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [201/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [226/391]\t\tLoss: 0.0107 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [251/391]\t\tLoss: 0.0107 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [276/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [301/391]\t\tLoss: 0.0086 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [326/391]\t\tLoss: 0.0202 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [351/391]\t\tLoss: 0.0058 Acc@1: 99.000%\n",
      "| Epoch [150/200] Iter [376/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #150\t\t\tLoss: 0.1037 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #151, LR=0.0040\n",
      "| Epoch [151/200] Iter [  1/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [151/200] Iter [ 26/391]\t\tLoss: 0.0029 Acc@1: 100.000%\n",
      "| Epoch [151/200] Iter [ 51/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [ 76/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [101/391]\t\tLoss: 0.0061 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [126/391]\t\tLoss: 0.0039 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [151/391]\t\tLoss: 0.0080 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [176/391]\t\tLoss: 0.0010 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [201/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [226/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [251/391]\t\tLoss: 0.0043 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [276/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [301/391]\t\tLoss: 0.0054 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [326/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [351/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [151/200] Iter [376/391]\t\tLoss: 0.0048 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #151\t\t\tLoss: 0.1488 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #152, LR=0.0040\n",
      "| Epoch [152/200] Iter [  1/391]\t\tLoss: 0.0010 Acc@1: 100.000%\n",
      "| Epoch [152/200] Iter [ 26/391]\t\tLoss: 0.0036 Acc@1: 100.000%\n",
      "| Epoch [152/200] Iter [ 51/391]\t\tLoss: 0.0104 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [ 76/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [101/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [126/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [151/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [176/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [201/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [226/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [251/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [276/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [301/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [326/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [351/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [152/200] Iter [376/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #152\t\t\tLoss: 0.1445 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #153, LR=0.0040\n",
      "| Epoch [153/200] Iter [  1/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [153/200] Iter [ 26/391]\t\tLoss: 0.0032 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [ 51/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [ 76/391]\t\tLoss: 0.0033 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [101/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [126/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [151/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [176/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [201/391]\t\tLoss: 0.0043 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [226/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [251/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [276/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [301/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [153/200] Iter [326/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [351/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [153/200] Iter [376/391]\t\tLoss: 0.0032 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #153\t\t\tLoss: 0.1607 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #154, LR=0.0040\n",
      "| Epoch [154/200] Iter [  1/391]\t\tLoss: 0.0034 Acc@1: 100.000%\n",
      "| Epoch [154/200] Iter [ 26/391]\t\tLoss: 0.0029 Acc@1: 100.000%\n",
      "| Epoch [154/200] Iter [ 51/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [ 76/391]\t\tLoss: 0.0045 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [101/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [126/391]\t\tLoss: 0.0033 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [151/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [176/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [201/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [226/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [251/391]\t\tLoss: 0.0048 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [276/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [301/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [326/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [351/391]\t\tLoss: 0.0071 Acc@1: 99.000%\n",
      "| Epoch [154/200] Iter [376/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #154\t\t\tLoss: 0.1364 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #155, LR=0.0040\n",
      "| Epoch [155/200] Iter [  1/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [155/200] Iter [ 26/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [155/200] Iter [ 51/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [ 76/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [101/391]\t\tLoss: 0.0063 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [126/391]\t\tLoss: 0.0055 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [151/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [176/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [201/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [226/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [251/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [276/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [301/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [326/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [351/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [155/200] Iter [376/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #155\t\t\tLoss: 0.1371 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #156, LR=0.0040\n",
      "| Epoch [156/200] Iter [  1/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [156/200] Iter [ 26/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [156/200] Iter [ 51/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [156/200] Iter [ 76/391]\t\tLoss: 0.0065 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [101/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [126/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [151/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [176/391]\t\tLoss: 0.0040 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [201/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [226/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [251/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [276/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [301/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [326/391]\t\tLoss: 0.0010 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [351/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [156/200] Iter [376/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #156\t\t\tLoss: 0.1351 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #157, LR=0.0040\n",
      "| Epoch [157/200] Iter [  1/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [157/200] Iter [ 26/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [157/200] Iter [ 51/391]\t\tLoss: 0.0036 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [ 76/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [101/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [126/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [151/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [176/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [201/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [226/391]\t\tLoss: 0.0116 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [251/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [276/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [301/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [326/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [351/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [157/200] Iter [376/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #157\t\t\tLoss: 0.1080 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #158, LR=0.0040\n",
      "| Epoch [158/200] Iter [  1/391]\t\tLoss: 0.0048 Acc@1: 100.000%\n",
      "| Epoch [158/200] Iter [ 26/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [158/200] Iter [ 51/391]\t\tLoss: 0.0023 Acc@1: 100.000%\n",
      "| Epoch [158/200] Iter [ 76/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [158/200] Iter [101/391]\t\tLoss: 0.0012 Acc@1: 100.000%\n",
      "| Epoch [158/200] Iter [126/391]\t\tLoss: 0.0030 Acc@1: 100.000%\n",
      "| Epoch [158/200] Iter [151/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [158/200] Iter [176/391]\t\tLoss: 0.0085 Acc@1: 99.000%\n",
      "| Epoch [158/200] Iter [201/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [158/200] Iter [226/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [158/200] Iter [251/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [158/200] Iter [276/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [158/200] Iter [301/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [158/200] Iter [326/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "| Epoch [158/200] Iter [351/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [158/200] Iter [376/391]\t\tLoss: 0.0057 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #158\t\t\tLoss: 0.1188 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #159, LR=0.0040\n",
      "| Epoch [159/200] Iter [  1/391]\t\tLoss: 0.0033 Acc@1: 100.000%\n",
      "| Epoch [159/200] Iter [ 26/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [ 51/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [ 76/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [101/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [126/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [151/391]\t\tLoss: 0.0039 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [176/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [201/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [226/391]\t\tLoss: 0.0034 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [251/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [276/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [301/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [326/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [351/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [159/200] Iter [376/391]\t\tLoss: 0.0189 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #159\t\t\tLoss: 0.1433 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #160, LR=0.0040\n",
      "| Epoch [160/200] Iter [  1/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [160/200] Iter [ 26/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [160/200] Iter [ 51/391]\t\tLoss: 0.0027 Acc@1: 100.000%\n",
      "| Epoch [160/200] Iter [ 76/391]\t\tLoss: 0.0036 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [101/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [126/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [151/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [176/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [201/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [226/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [251/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [276/391]\t\tLoss: 0.0054 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [301/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [326/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [351/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [160/200] Iter [376/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #160\t\t\tLoss: 0.1652 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #161, LR=0.0008\n",
      "| Epoch [161/200] Iter [  1/391]\t\tLoss: 0.0028 Acc@1: 100.000%\n",
      "| Epoch [161/200] Iter [ 26/391]\t\tLoss: 0.0038 Acc@1: 100.000%\n",
      "| Epoch [161/200] Iter [ 51/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [161/200] Iter [ 76/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [161/200] Iter [101/391]\t\tLoss: 0.0049 Acc@1: 100.000%\n",
      "| Epoch [161/200] Iter [126/391]\t\tLoss: 0.0050 Acc@1: 100.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [161/200] Iter [151/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [161/200] Iter [176/391]\t\tLoss: 0.0128 Acc@1: 99.000%\n",
      "| Epoch [161/200] Iter [201/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [161/200] Iter [226/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [161/200] Iter [251/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [161/200] Iter [276/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [161/200] Iter [301/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [161/200] Iter [326/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [161/200] Iter [351/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [161/200] Iter [376/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #161\t\t\tLoss: 0.1529 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #162, LR=0.0008\n",
      "| Epoch [162/200] Iter [  1/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [162/200] Iter [ 26/391]\t\tLoss: 0.0053 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [ 51/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [ 76/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [101/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [126/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [151/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [176/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [201/391]\t\tLoss: 0.0039 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [226/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [251/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [276/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [301/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [326/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [351/391]\t\tLoss: 0.0040 Acc@1: 99.000%\n",
      "| Epoch [162/200] Iter [376/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #162\t\t\tLoss: 0.1486 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #163, LR=0.0008\n",
      "| Epoch [163/200] Iter [  1/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [163/200] Iter [ 26/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [163/200] Iter [ 51/391]\t\tLoss: 0.0028 Acc@1: 100.000%\n",
      "| Epoch [163/200] Iter [ 76/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [101/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [126/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [151/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [176/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [201/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [226/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [251/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [276/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [301/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [326/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [351/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [163/200] Iter [376/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #163\t\t\tLoss: 0.1546 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #164, LR=0.0008\n",
      "| Epoch [164/200] Iter [  1/391]\t\tLoss: 0.0023 Acc@1: 100.000%\n",
      "| Epoch [164/200] Iter [ 26/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [ 51/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [ 76/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [101/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [126/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [151/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [176/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [201/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [226/391]\t\tLoss: 0.0046 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [251/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [276/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [301/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [326/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [351/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [164/200] Iter [376/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #164\t\t\tLoss: 0.1451 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #165, LR=0.0008\n",
      "| Epoch [165/200] Iter [  1/391]\t\tLoss: 0.0050 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [ 26/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [ 51/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [ 76/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [101/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [126/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [151/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [176/391]\t\tLoss: 0.0041 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [201/391]\t\tLoss: 0.0025 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [226/391]\t\tLoss: 0.0069 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [251/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [276/391]\t\tLoss: 0.0033 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [301/391]\t\tLoss: 0.0028 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [326/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [165/200] Iter [351/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [165/200] Iter [376/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #165\t\t\tLoss: 0.1707 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #166, LR=0.0008\n",
      "| Epoch [166/200] Iter [  1/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [166/200] Iter [ 26/391]\t\tLoss: 0.0022 Acc@1: 100.000%\n",
      "| Epoch [166/200] Iter [ 51/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [166/200] Iter [ 76/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [166/200] Iter [101/391]\t\tLoss: 0.0012 Acc@1: 100.000%\n",
      "| Epoch [166/200] Iter [126/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [166/200] Iter [151/391]\t\tLoss: 0.0038 Acc@1: 100.000%\n",
      "| Epoch [166/200] Iter [176/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [166/200] Iter [201/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [166/200] Iter [226/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [166/200] Iter [251/391]\t\tLoss: 0.0051 Acc@1: 99.000%\n",
      "| Epoch [166/200] Iter [276/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [166/200] Iter [301/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [166/200] Iter [326/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [166/200] Iter [351/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [166/200] Iter [376/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #166\t\t\tLoss: 0.1412 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #167, LR=0.0008\n",
      "| Epoch [167/200] Iter [  1/391]\t\tLoss: 0.0037 Acc@1: 100.000%\n",
      "| Epoch [167/200] Iter [ 26/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [167/200] Iter [ 51/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [ 76/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [101/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [126/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [151/391]\t\tLoss: 0.0057 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [176/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [201/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [226/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [251/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [276/391]\t\tLoss: 0.0009 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [301/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [326/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [351/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [167/200] Iter [376/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #167\t\t\tLoss: 0.1636 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #168, LR=0.0008\n",
      "| Epoch [168/200] Iter [  1/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [168/200] Iter [ 26/391]\t\tLoss: 0.0025 Acc@1: 100.000%\n",
      "| Epoch [168/200] Iter [ 51/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [168/200] Iter [ 76/391]\t\tLoss: 0.0047 Acc@1: 100.000%\n",
      "| Epoch [168/200] Iter [101/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [126/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [151/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [176/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [201/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [226/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [251/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [276/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [301/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [326/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [351/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [168/200] Iter [376/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Validation Epoch #168\t\t\tLoss: 0.1722 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #169, LR=0.0008\n",
      "| Epoch [169/200] Iter [  1/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [169/200] Iter [ 26/391]\t\tLoss: 0.0023 Acc@1: 100.000%\n",
      "| Epoch [169/200] Iter [ 51/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [169/200] Iter [ 76/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [169/200] Iter [101/391]\t\tLoss: 0.0051 Acc@1: 100.000%\n",
      "| Epoch [169/200] Iter [126/391]\t\tLoss: 0.0012 Acc@1: 100.000%\n",
      "| Epoch [169/200] Iter [151/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [169/200] Iter [176/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [169/200] Iter [201/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [169/200] Iter [226/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [169/200] Iter [251/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [169/200] Iter [276/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [169/200] Iter [301/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [169/200] Iter [326/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [169/200] Iter [351/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [169/200] Iter [376/391]\t\tLoss: 0.0050 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #169\t\t\tLoss: 0.1485 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #170, LR=0.0008\n",
      "| Epoch [170/200] Iter [  1/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [170/200] Iter [ 26/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [170/200] Iter [ 51/391]\t\tLoss: 0.0012 Acc@1: 100.000%\n",
      "| Epoch [170/200] Iter [ 76/391]\t\tLoss: 0.0028 Acc@1: 100.000%\n",
      "| Epoch [170/200] Iter [101/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [170/200] Iter [126/391]\t\tLoss: 0.0033 Acc@1: 100.000%\n",
      "| Epoch [170/200] Iter [151/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [170/200] Iter [176/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [170/200] Iter [201/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [170/200] Iter [226/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [170/200] Iter [251/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [170/200] Iter [276/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [170/200] Iter [301/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [170/200] Iter [326/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [170/200] Iter [351/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [170/200] Iter [376/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #170\t\t\tLoss: 0.1356 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #171, LR=0.0008\n",
      "| Epoch [171/200] Iter [  1/391]\t\tLoss: 0.0011 Acc@1: 100.000%\n",
      "| Epoch [171/200] Iter [ 26/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [171/200] Iter [ 51/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [171/200] Iter [ 76/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [171/200] Iter [101/391]\t\tLoss: 0.0012 Acc@1: 100.000%\n",
      "| Epoch [171/200] Iter [126/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [171/200] Iter [151/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [171/200] Iter [176/391]\t\tLoss: 0.0039 Acc@1: 100.000%\n",
      "| Epoch [171/200] Iter [201/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [171/200] Iter [226/391]\t\tLoss: 0.0054 Acc@1: 99.000%\n",
      "| Epoch [171/200] Iter [251/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [171/200] Iter [276/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [171/200] Iter [301/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [171/200] Iter [326/391]\t\tLoss: 0.0052 Acc@1: 99.000%\n",
      "| Epoch [171/200] Iter [351/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [171/200] Iter [376/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #171\t\t\tLoss: 0.1481 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #172, LR=0.0008\n",
      "| Epoch [172/200] Iter [  1/391]\t\tLoss: 0.0033 Acc@1: 100.000%\n",
      "| Epoch [172/200] Iter [ 26/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [172/200] Iter [ 51/391]\t\tLoss: 0.0025 Acc@1: 100.000%\n",
      "| Epoch [172/200] Iter [ 76/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [172/200] Iter [101/391]\t\tLoss: 0.0023 Acc@1: 100.000%\n",
      "| Epoch [172/200] Iter [126/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [172/200] Iter [151/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [172/200] Iter [176/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [172/200] Iter [201/391]\t\tLoss: 0.0037 Acc@1: 99.000%\n",
      "| Epoch [172/200] Iter [226/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [172/200] Iter [251/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [172/200] Iter [276/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [172/200] Iter [301/391]\t\tLoss: 0.0010 Acc@1: 99.000%\n",
      "| Epoch [172/200] Iter [326/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [172/200] Iter [351/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [172/200] Iter [376/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #172\t\t\tLoss: 0.1340 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #173, LR=0.0008\n",
      "| Epoch [173/200] Iter [  1/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [173/200] Iter [ 26/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [ 51/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [ 76/391]\t\tLoss: 0.0066 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [101/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [126/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [151/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [176/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [201/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [226/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [251/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [276/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [301/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [326/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [351/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [173/200] Iter [376/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #173\t\t\tLoss: 0.1425 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #174, LR=0.0008\n",
      "| Epoch [174/200] Iter [  1/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [174/200] Iter [ 26/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [ 51/391]\t\tLoss: 0.0055 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [ 76/391]\t\tLoss: 0.0038 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [101/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [126/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [151/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [176/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [201/391]\t\tLoss: 0.0039 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [226/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [251/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [276/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [301/391]\t\tLoss: 0.0043 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [326/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [351/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [174/200] Iter [376/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #174\t\t\tLoss: 0.1610 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #175, LR=0.0008\n",
      "| Epoch [175/200] Iter [  1/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [175/200] Iter [ 26/391]\t\tLoss: 0.0025 Acc@1: 100.000%\n",
      "| Epoch [175/200] Iter [ 51/391]\t\tLoss: 0.0023 Acc@1: 100.000%\n",
      "| Epoch [175/200] Iter [ 76/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [101/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [126/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [151/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [176/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [201/391]\t\tLoss: 0.0037 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [226/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [251/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [276/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [301/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [326/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [351/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [175/200] Iter [376/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #175\t\t\tLoss: 0.1286 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #176, LR=0.0008\n",
      "| Epoch [176/200] Iter [  1/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [176/200] Iter [ 26/391]\t\tLoss: 0.0042 Acc@1: 100.000%\n",
      "| Epoch [176/200] Iter [ 51/391]\t\tLoss: 0.0046 Acc@1: 100.000%\n",
      "| Epoch [176/200] Iter [ 76/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [176/200] Iter [101/391]\t\tLoss: 0.0027 Acc@1: 100.000%\n",
      "| Epoch [176/200] Iter [126/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [176/200] Iter [151/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [176/200] Iter [176/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [176/200] Iter [201/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [176/200] Iter [226/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [176/200] Iter [251/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [176/200] Iter [276/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [176/200] Iter [301/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [176/200] Iter [326/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [176/200] Iter [351/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [176/200] Iter [376/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #176\t\t\tLoss: 0.1517 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #177, LR=0.0008\n",
      "| Epoch [177/200] Iter [  1/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [177/200] Iter [ 26/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [ 51/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [ 76/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [101/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [126/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [151/391]\t\tLoss: 0.0054 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [176/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [201/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [226/391]\t\tLoss: 0.0038 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [251/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [276/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [301/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [326/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [351/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [177/200] Iter [376/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #177\t\t\tLoss: 0.1291 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #178, LR=0.0008\n",
      "| Epoch [178/200] Iter [  1/391]\t\tLoss: 0.0022 Acc@1: 100.000%\n",
      "| Epoch [178/200] Iter [ 26/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [178/200] Iter [ 51/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [178/200] Iter [ 76/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [178/200] Iter [101/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [178/200] Iter [126/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [178/200] Iter [151/391]\t\tLoss: 0.0029 Acc@1: 100.000%\n",
      "| Epoch [178/200] Iter [176/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [178/200] Iter [201/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [178/200] Iter [226/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [178/200] Iter [251/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [178/200] Iter [276/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [178/200] Iter [301/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [178/200] Iter [326/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [178/200] Iter [351/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [178/200] Iter [376/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #178\t\t\tLoss: 0.1178 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #179, LR=0.0008\n",
      "| Epoch [179/200] Iter [  1/391]\t\tLoss: 0.0012 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [ 26/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [ 51/391]\t\tLoss: 0.0011 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [ 76/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [101/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [126/391]\t\tLoss: 0.0012 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [151/391]\t\tLoss: 0.0034 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [176/391]\t\tLoss: 0.0011 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [201/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [226/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [251/391]\t\tLoss: 0.0012 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [276/391]\t\tLoss: 0.0023 Acc@1: 100.000%\n",
      "| Epoch [179/200] Iter [301/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [179/200] Iter [326/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [179/200] Iter [351/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [179/200] Iter [376/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #179\t\t\tLoss: 0.1763 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #180, LR=0.0008\n",
      "| Epoch [180/200] Iter [  1/391]\t\tLoss: 0.0098 Acc@1: 100.000%\n",
      "| Epoch [180/200] Iter [ 26/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [180/200] Iter [ 51/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [180/200] Iter [ 76/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [180/200] Iter [101/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [180/200] Iter [126/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [180/200] Iter [151/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [180/200] Iter [176/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [180/200] Iter [201/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [180/200] Iter [226/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [180/200] Iter [251/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [180/200] Iter [276/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [180/200] Iter [301/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [180/200] Iter [326/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [180/200] Iter [351/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [180/200] Iter [376/391]\t\tLoss: 0.0065 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #180\t\t\tLoss: 0.1217 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #181, LR=0.0008\n",
      "| Epoch [181/200] Iter [  1/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [181/200] Iter [ 26/391]\t\tLoss: 0.0023 Acc@1: 100.000%\n",
      "| Epoch [181/200] Iter [ 51/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [181/200] Iter [ 76/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [101/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [126/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [151/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [176/391]\t\tLoss: 0.0051 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [201/391]\t\tLoss: 0.0050 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [226/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [251/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [276/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [301/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [326/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [351/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [181/200] Iter [376/391]\t\tLoss: 0.0040 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #181\t\t\tLoss: 0.1476 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #182, LR=0.0008\n",
      "| Epoch [182/200] Iter [  1/391]\t\tLoss: 0.0028 Acc@1: 100.000%\n",
      "| Epoch [182/200] Iter [ 26/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [182/200] Iter [ 51/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [ 76/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [101/391]\t\tLoss: 0.0038 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [126/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [151/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [176/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [201/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [226/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [251/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [276/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [301/391]\t\tLoss: 0.0220 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [326/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [351/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [182/200] Iter [376/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #182\t\t\tLoss: 0.1390 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #183, LR=0.0008\n",
      "| Epoch [183/200] Iter [  1/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [183/200] Iter [ 26/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [ 51/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [ 76/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [101/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [126/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [151/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [176/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [201/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [226/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [251/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [276/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [301/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [326/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [351/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [183/200] Iter [376/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #183\t\t\tLoss: 0.1473 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #184, LR=0.0008\n",
      "| Epoch [184/200] Iter [  1/391]\t\tLoss: 0.0010 Acc@1: 100.000%\n",
      "| Epoch [184/200] Iter [ 26/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [184/200] Iter [ 51/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [ 76/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [101/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [126/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [151/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [176/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [201/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [226/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [251/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [276/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [301/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [326/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [351/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [184/200] Iter [376/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #184\t\t\tLoss: 0.1575 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #185, LR=0.0008\n",
      "| Epoch [185/200] Iter [  1/391]\t\tLoss: 0.0028 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [ 26/391]\t\tLoss: 0.0009 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [ 51/391]\t\tLoss: 0.0022 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [ 76/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [101/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [126/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [151/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [176/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [201/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [226/391]\t\tLoss: 0.0010 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [251/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [276/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [301/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [326/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [351/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [185/200] Iter [376/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "\n",
      "| Validation Epoch #185\t\t\tLoss: 0.1281 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #186, LR=0.0008\n",
      "| Epoch [186/200] Iter [  1/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [186/200] Iter [ 26/391]\t\tLoss: 0.0027 Acc@1: 100.000%\n",
      "| Epoch [186/200] Iter [ 51/391]\t\tLoss: 0.0036 Acc@1: 100.000%\n",
      "| Epoch [186/200] Iter [ 76/391]\t\tLoss: 0.0010 Acc@1: 100.000%\n",
      "| Epoch [186/200] Iter [101/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [186/200] Iter [126/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [186/200] Iter [151/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [186/200] Iter [176/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [186/200] Iter [201/391]\t\tLoss: 0.0033 Acc@1: 99.000%\n",
      "| Epoch [186/200] Iter [226/391]\t\tLoss: 0.0010 Acc@1: 99.000%\n",
      "| Epoch [186/200] Iter [251/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [186/200] Iter [276/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [186/200] Iter [301/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [186/200] Iter [326/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [186/200] Iter [351/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [186/200] Iter [376/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #186\t\t\tLoss: 0.1378 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #187, LR=0.0008\n",
      "| Epoch [187/200] Iter [  1/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [187/200] Iter [ 26/391]\t\tLoss: 0.0028 Acc@1: 100.000%\n",
      "| Epoch [187/200] Iter [ 51/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [187/200] Iter [ 76/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [187/200] Iter [101/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [126/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [151/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [176/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [201/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [226/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [251/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [276/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [301/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [326/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [351/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [187/200] Iter [376/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #187\t\t\tLoss: 0.1403 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #188, LR=0.0008\n",
      "| Epoch [188/200] Iter [  1/391]\t\tLoss: 0.0041 Acc@1: 100.000%\n",
      "| Epoch [188/200] Iter [ 26/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [ 51/391]\t\tLoss: 0.0035 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [ 76/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [101/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [126/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [151/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [176/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [201/391]\t\tLoss: 0.0037 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [226/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [251/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [276/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [301/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [326/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [351/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [188/200] Iter [376/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #188\t\t\tLoss: 0.1242 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #189, LR=0.0008\n",
      "| Epoch [189/200] Iter [  1/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [189/200] Iter [ 26/391]\t\tLoss: 0.0074 Acc@1: 100.000%\n",
      "| Epoch [189/200] Iter [ 51/391]\t\tLoss: 0.0011 Acc@1: 100.000%\n",
      "| Epoch [189/200] Iter [ 76/391]\t\tLoss: 0.0023 Acc@1: 100.000%\n",
      "| Epoch [189/200] Iter [101/391]\t\tLoss: 0.0027 Acc@1: 100.000%\n",
      "| Epoch [189/200] Iter [126/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [189/200] Iter [151/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [189/200] Iter [176/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [189/200] Iter [201/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [189/200] Iter [226/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [189/200] Iter [251/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [189/200] Iter [276/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [189/200] Iter [301/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [189/200] Iter [326/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [189/200] Iter [351/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [189/200] Iter [376/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #189\t\t\tLoss: 0.1254 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #190, LR=0.0008\n",
      "| Epoch [190/200] Iter [  1/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [190/200] Iter [ 26/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [ 51/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [ 76/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [101/391]\t\tLoss: 0.0010 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [126/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [151/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [176/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [201/391]\t\tLoss: 0.0044 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [226/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [251/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [276/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [301/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [326/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [351/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [190/200] Iter [376/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #190\t\t\tLoss: 0.1457 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #191, LR=0.0008\n",
      "| Epoch [191/200] Iter [  1/391]\t\tLoss: 0.0035 Acc@1: 100.000%\n",
      "| Epoch [191/200] Iter [ 26/391]\t\tLoss: 0.0032 Acc@1: 100.000%\n",
      "| Epoch [191/200] Iter [ 51/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [191/200] Iter [ 76/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [191/200] Iter [101/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [191/200] Iter [126/391]\t\tLoss: 0.0046 Acc@1: 100.000%\n",
      "| Epoch [191/200] Iter [151/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [191/200] Iter [176/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [191/200] Iter [201/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [191/200] Iter [226/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [191/200] Iter [251/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [191/200] Iter [276/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [191/200] Iter [301/391]\t\tLoss: 0.0033 Acc@1: 99.000%\n",
      "| Epoch [191/200] Iter [326/391]\t\tLoss: 0.0042 Acc@1: 99.000%\n",
      "| Epoch [191/200] Iter [351/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [191/200] Iter [376/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #191\t\t\tLoss: 0.1614 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #192, LR=0.0008\n",
      "| Epoch [192/200] Iter [  1/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [192/200] Iter [ 26/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [192/200] Iter [ 51/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [ 76/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [101/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [126/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [151/391]\t\tLoss: 0.0033 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [176/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [201/391]\t\tLoss: 0.0023 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [226/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [251/391]\t\tLoss: 0.0025 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [276/391]\t\tLoss: 0.0034 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [301/391]\t\tLoss: 0.0010 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [326/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [351/391]\t\tLoss: 0.0032 Acc@1: 99.000%\n",
      "| Epoch [192/200] Iter [376/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #192\t\t\tLoss: 0.1232 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #193, LR=0.0008\n",
      "| Epoch [193/200] Iter [  1/391]\t\tLoss: 0.0024 Acc@1: 100.000%\n",
      "| Epoch [193/200] Iter [ 26/391]\t\tLoss: 0.0028 Acc@1: 100.000%\n",
      "| Epoch [193/200] Iter [ 51/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [ 76/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [101/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [126/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [151/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [176/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [201/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [226/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [251/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [276/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [301/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [326/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [351/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [193/200] Iter [376/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #193\t\t\tLoss: 0.1675 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #194, LR=0.0008\n",
      "| Epoch [194/200] Iter [  1/391]\t\tLoss: 0.0025 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [ 26/391]\t\tLoss: 0.0028 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [ 51/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [ 76/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [101/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [126/391]\t\tLoss: 0.0034 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [151/391]\t\tLoss: 0.0025 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [176/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [201/391]\t\tLoss: 0.0025 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [226/391]\t\tLoss: 0.0027 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [251/391]\t\tLoss: 0.0033 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [276/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [301/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [194/200] Iter [326/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [194/200] Iter [351/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [194/200] Iter [376/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #194\t\t\tLoss: 0.1285 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #195, LR=0.0008\n",
      "| Epoch [195/200] Iter [  1/391]\t\tLoss: 0.0034 Acc@1: 100.000%\n",
      "| Epoch [195/200] Iter [ 26/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [195/200] Iter [ 51/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [195/200] Iter [ 76/391]\t\tLoss: 0.0033 Acc@1: 100.000%\n",
      "| Epoch [195/200] Iter [101/391]\t\tLoss: 0.0029 Acc@1: 100.000%\n",
      "| Epoch [195/200] Iter [126/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [195/200] Iter [151/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [195/200] Iter [176/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [195/200] Iter [201/391]\t\tLoss: 0.0029 Acc@1: 100.000%\n",
      "| Epoch [195/200] Iter [226/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [195/200] Iter [251/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [195/200] Iter [276/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [195/200] Iter [301/391]\t\tLoss: 0.0038 Acc@1: 99.000%\n",
      "| Epoch [195/200] Iter [326/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [195/200] Iter [351/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [195/200] Iter [376/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #195\t\t\tLoss: 0.1491 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #196, LR=0.0008\n",
      "| Epoch [196/200] Iter [  1/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [196/200] Iter [ 26/391]\t\tLoss: 0.0019 Acc@1: 100.000%\n",
      "| Epoch [196/200] Iter [ 51/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [196/200] Iter [ 76/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [101/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [126/391]\t\tLoss: 0.0033 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [151/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [176/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [201/391]\t\tLoss: 0.0029 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [226/391]\t\tLoss: 0.0011 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [251/391]\t\tLoss: 0.0012 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [276/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [301/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [326/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [351/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [196/200] Iter [376/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #196\t\t\tLoss: 0.1196 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #197, LR=0.0008\n",
      "| Epoch [197/200] Iter [  1/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [ 26/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [ 51/391]\t\tLoss: 0.0013 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [ 76/391]\t\tLoss: 0.0021 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [101/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [126/391]\t\tLoss: 0.0029 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [151/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [176/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [201/391]\t\tLoss: 0.0010 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [226/391]\t\tLoss: 0.0012 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [251/391]\t\tLoss: 0.0015 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [276/391]\t\tLoss: 0.0020 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [301/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [326/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [351/391]\t\tLoss: 0.0026 Acc@1: 100.000%\n",
      "| Epoch [197/200] Iter [376/391]\t\tLoss: 0.0017 Acc@1: 100.000%\n",
      "\n",
      "| Validation Epoch #197\t\t\tLoss: 0.1540 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #198, LR=0.0008\n",
      "| Epoch [198/200] Iter [  1/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [198/200] Iter [ 26/391]\t\tLoss: 0.0025 Acc@1: 100.000%\n",
      "| Epoch [198/200] Iter [ 51/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [ 76/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [101/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [126/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [151/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [176/391]\t\tLoss: 0.0034 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [201/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [226/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [251/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [276/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [301/391]\t\tLoss: 0.0047 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [326/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [351/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [198/200] Iter [376/391]\t\tLoss: 0.0030 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #198\t\t\tLoss: 0.1334 Acc@1: 94.00%\n",
      "\n",
      "=> Training Epoch #199, LR=0.0008\n",
      "| Epoch [199/200] Iter [  1/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [199/200] Iter [ 26/391]\t\tLoss: 0.0025 Acc@1: 100.000%\n",
      "| Epoch [199/200] Iter [ 51/391]\t\tLoss: 0.0018 Acc@1: 100.000%\n",
      "| Epoch [199/200] Iter [ 76/391]\t\tLoss: 0.0022 Acc@1: 99.000%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch [199/200] Iter [101/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [126/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [151/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [176/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [201/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [226/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [251/391]\t\tLoss: 0.0028 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [276/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [301/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [326/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [351/391]\t\tLoss: 0.0024 Acc@1: 99.000%\n",
      "| Epoch [199/200] Iter [376/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #199\t\t\tLoss: 0.1196 Acc@1: 95.00%\n",
      "\n",
      "=> Training Epoch #200, LR=0.0008\n",
      "| Epoch [200/200] Iter [  1/391]\t\tLoss: 0.0047 Acc@1: 100.000%\n",
      "| Epoch [200/200] Iter [ 26/391]\t\tLoss: 0.0016 Acc@1: 100.000%\n",
      "| Epoch [200/200] Iter [ 51/391]\t\tLoss: 0.0014 Acc@1: 100.000%\n",
      "| Epoch [200/200] Iter [ 76/391]\t\tLoss: 0.0014 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [101/391]\t\tLoss: 0.0026 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [126/391]\t\tLoss: 0.0031 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [151/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [176/391]\t\tLoss: 0.0021 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [201/391]\t\tLoss: 0.0015 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [226/391]\t\tLoss: 0.0018 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [251/391]\t\tLoss: 0.0013 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [276/391]\t\tLoss: 0.0020 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [301/391]\t\tLoss: 0.0027 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [326/391]\t\tLoss: 0.0019 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [351/391]\t\tLoss: 0.0017 Acc@1: 99.000%\n",
      "| Epoch [200/200] Iter [376/391]\t\tLoss: 0.0016 Acc@1: 99.000%\n",
      "\n",
      "| Validation Epoch #200\t\t\tLoss: 0.1298 Acc@1: 95.00%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+num_epochs):\n",
    "    net.cuda(device)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate(0.1, epoch), momentum=0.9, weight_decay=5e-4, nesterov=True)\n",
    "    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learning_rate(0.1, epoch)))\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.cuda(device), targets.cuda(device)\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.data.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        \n",
    "        if batch_idx % 25 == 0:\n",
    "            print('| Epoch [%3d/%3d] Iter [%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%' %(epoch, num_epochs, batch_idx+1,\n",
    "                                                                               (len(trainset)//batch_size)+1, loss.data.item(), 100.*correct/total))\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.cuda(device), targets.cuda(device)\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        test_loss += loss.data.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "    \n",
    "    acc = 100. * correct / total\n",
    "    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.data.item(), acc))\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n",
    "        state = {\n",
    "                'net':net.modules,\n",
    "                'acc':acc,\n",
    "                'epoch':epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        save_point = './checkpoint/'\n",
    "        if not os.path.isdir(save_point):\n",
    "            os.mkdir(save_point)\n",
    "        torch.save(state, save_point+file_name+'.t7')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
