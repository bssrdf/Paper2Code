{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse, parser\n",
    "from options.train_dicts import TrainOptions\n",
    "from data import create_dataset\n",
    "from easydict import EasyDict\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = EasyDict()\n",
    "params.dataroot = '/media/data2/dataset/maps'\n",
    "params.name = 'maps_pix2pix'\n",
    "params.model = 'pix2pix'\n",
    "params.direction = 'BtoA'\n",
    "params.gpu_ids = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 1                             \n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: /media/data2/dataset/maps     \n",
      "             dataset_mode: aligned                       \n",
      "                direction: BtoA                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: 1                             \n",
      "            display_ncols: 4                             \n",
      "             display_port: 8888                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 3                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \n",
      "                load_size: 286                           \n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \n",
      "                 n_epochs: 100                           \n",
      "           n_epochs_decay: 100                           \n",
      "               n_layers_D: 3                             \n",
      "                     name: maps_pix2pix                  \n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: True                          \n",
      "                  no_flip: True                          \n",
      "                  no_html: True                          \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: True                          \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: True                          \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                  verbose: True                          \n",
      "----------------- End -------------------\n"
     ]
    }
   ],
   "source": [
    "opt = TrainOptions().parse(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 2192\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(opt)\n",
    "dataset_size = len(dataset)\n",
    "print('The number of training images = %d' % dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n"
     ]
    }
   ],
   "source": [
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "DataParallel(\n",
      "  (module): UnetGenerator(\n",
      "    (model): UnetSkipConnectionBlock(\n",
      "      (model): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): UnetSkipConnectionBlock(\n",
      "          (model): Sequential(\n",
      "            (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): UnetSkipConnectionBlock(\n",
      "              (model): Sequential(\n",
      "                (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (3): UnetSkipConnectionBlock(\n",
      "                  (model): Sequential(\n",
      "                    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (3): UnetSkipConnectionBlock(\n",
      "                      (model): Sequential(\n",
      "                        (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                        (3): UnetSkipConnectionBlock(\n",
      "                          (model): Sequential(\n",
      "                            (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                            (3): UnetSkipConnectionBlock(\n",
      "                              (model): Sequential(\n",
      "                                (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                (3): UnetSkipConnectionBlock(\n",
      "                                  (model): Sequential(\n",
      "                                    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (2): ReLU(inplace=True)\n",
      "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                                  )\n",
      "                                )\n",
      "                                (4): ReLU(inplace=True)\n",
      "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                                (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                              )\n",
      "                            )\n",
      "                            (4): ReLU(inplace=True)\n",
      "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                            (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                          )\n",
      "                        )\n",
      "                        (4): ReLU(inplace=True)\n",
      "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      )\n",
      "                    )\n",
      "                    (4): ReLU(inplace=True)\n",
      "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  )\n",
      "                )\n",
      "                (4): ReLU(inplace=True)\n",
      "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (4): ReLU(inplace=True)\n",
      "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "        (4): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network G] Total number of parameters : 54.414 M\n",
      "DataParallel(\n",
      "  (module): NLayerDiscriminator(\n",
      "    (model): Sequential(\n",
      "      (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[Network D] Total number of parameters : 2.769 M\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.setup(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iters = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 1 / 200 \t Time Taken: 85 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 2 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 3, total_iters 5000)\n",
      "End of epoch 3 / 200 \t Time Taken: 84 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 4 / 200 \t Time Taken: 80 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 5, total_iters 10000)\n",
      "saving the model at the end of epoch 5, iters 10960\n",
      "End of epoch 5 / 200 \t Time Taken: 88 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 6 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 7, total_iters 15000)\n",
      "End of epoch 7 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 8 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 9 / 200 \t Time Taken: 84 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 10, total_iters 20000)\n",
      "saving the model at the end of epoch 10, iters 21920\n",
      "End of epoch 10 / 200 \t Time Taken: 85 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 11 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 12, total_iters 25000)\n",
      "End of epoch 12 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 13 / 200 \t Time Taken: 80 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 14, total_iters 30000)\n",
      "End of epoch 14 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 15, iters 32880\n",
      "End of epoch 15 / 200 \t Time Taken: 84 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 16, total_iters 35000)\n",
      "End of epoch 16 / 200 \t Time Taken: 82 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 17 / 200 \t Time Taken: 83 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 18 / 200 \t Time Taken: 85 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 19, total_iters 40000)\n",
      "End of epoch 19 / 200 \t Time Taken: 84 sec\n",
      "learning rate = 0.0002000\n",
      "saving the model at the end of epoch 20, iters 43840\n",
      "End of epoch 20 / 200 \t Time Taken: 84 sec\n",
      "learning rate = 0.0002000\n",
      "saving the latest model (epoch 21, total_iters 45000)\n",
      "End of epoch 21 / 200 \t Time Taken: 81 sec\n",
      "learning rate = 0.0002000\n",
      "End of epoch 22 / 200 \t Time Taken: 75 sec\n",
      "learning rate = 0.0002000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.epoch_count, opt.n_epochs + opt.n_epochs_decay + 1):    # outer loop for different epochs; we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>\n",
    "        epoch_start_time = time.time()  # timer for entire epoch\n",
    "        iter_data_time = time.time()    # timer for data loading per iteration\n",
    "        epoch_iter = 0                  # the number of training iterations in current epoch, reset to 0 every epoch\n",
    "\n",
    "        for i, data in enumerate(dataset):  # inner loop within one epoch\n",
    "            iter_start_time = time.time()  # timer for computation per iteration\n",
    "            if total_iters % opt.print_freq == 0:\n",
    "                t_data = iter_start_time - iter_data_time\n",
    "\n",
    "            total_iters += opt.batch_size\n",
    "            epoch_iter += opt.batch_size\n",
    "            model.set_input(data)         # unpack data from dataset and apply preprocessing\n",
    "            model.optimize_parameters()   # calculate loss functions, get gradients, update network weights\n",
    "\n",
    "            if total_iters % opt.display_freq == 0:   # display images on visdom and save images to a HTML file\n",
    "                save_result = total_iters % opt.update_html_freq == 0\n",
    "                model.compute_visuals()\n",
    "\n",
    "            if total_iters % opt.print_freq == 0:    # print training losses and save logging information to the disk\n",
    "                losses = model.get_current_losses()\n",
    "                t_comp = (time.time() - iter_start_time) / opt.batch_size\n",
    "\n",
    "            if total_iters % opt.save_latest_freq == 0:   # cache our latest model every <save_latest_freq> iterations\n",
    "                print('saving the latest model (epoch %d, total_iters %d)' % (epoch, total_iters))\n",
    "                save_suffix = 'iter_%d' % total_iters if opt.save_by_iter else 'latest'\n",
    "                model.save_networks(save_suffix)\n",
    "\n",
    "            iter_data_time = time.time()\n",
    "        if epoch % opt.save_epoch_freq == 0:              # cache our model every <save_epoch_freq> epochs\n",
    "            print('saving the model at the end of epoch %d, iters %d' % (epoch, total_iters))\n",
    "            model.save_networks('latest')\n",
    "            model.save_networks(epoch)\n",
    "\n",
    "        print('End of epoch %d / %d \\t Time Taken: %d sec' % (epoch, opt.n_epochs + opt.n_epochs_decay, time.time() - epoch_start_time))\n",
    "        model.update_learning_rate()                     # update learning rates at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
